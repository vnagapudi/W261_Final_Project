{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W261 Final Project - Clickthrough Rate Prediction\n",
    "\n",
    "Team 24   \n",
    "Vivian Lu, Siddhartha Jakkamreddy, Venky Nagapudi, Luca Garre   \n",
    "Summer 2019, sections 4 and 5   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* __Section 1__ - Question Formulation\n",
    "* __Section 2__ - Algorithm Explanation\n",
    "* __Section 3__ - EDA & Challenges\n",
    "* __Section 4__ - Algorithm Implementation\n",
    "* __Section 5__ - Course Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 1__ - Question Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Introduction__\n",
    "Online ad is a multibillion dollar industry fueled by large investments and ever increasing performance goals. Targeted advertisement based on users' browsing industry and demographic, ad features such as overall appearance, employed colors and text, and website features such as ad's relative placement in the webpage, sizes, etc., is receiving more and more interest due to its potential for revenue generation. In this context, machine learning is proving resourceful in the understanding of the features that mostly affect users' Click-Through Rates (CTR) and, based on this understanding, in informing the design of ads that maximize performance metrics such as click and convertion rates. Further, machine learning solutions can easily be deployed in a data pipeline enviroment in order to select and offer, on a user-specific basis, the ad which expectedly maximizes the user's interest. \n",
    "\n",
    "...\n",
    "\n",
    "## __Goal of the analysis__\n",
    "The purpose of the present analysis is to estimate whether a given ad will be clicked based on a set of features describing the ad. \n",
    "\n",
    "...\n",
    "\n",
    "## __Description of the dataset__\n",
    "The dataset is provided by __[put_reference_to_CriteoLabs]__ and is composed of three files, a `readme.txt`, a `train.txt` and a `test.txt` file, respectively. The readme file contains a brief description of the data. The `train.txt` and `test.txt` files contain the train and test data. Both files are formatted as tab separated value tables, and amount to 45840617 and 6042135 rows for the train and test data, respectively. Following the description of the data, each row represents an ad and contains the following fields (see commands below, these expect the data to be contained in a data folder inside the current working directory):\n",
    "\n",
    "- 1 binary field indicating whether the ad has been clicked (1) or not (0). This field is available only for the train data;\n",
    "- 13 fields containing integer features representing counts;\n",
    "- 26 categorical features. These are hashed as 32 bits keys for anonymization purposes;\n",
    "\n",
    "From a printout of the first rows of the data files it appears that the data contain no headers. This implies that, with the sole exception of the first binary field, it is not possible to characterize the various fields in terms of the features these represent. It is also noted that rows in the data can have missing values. This is again noticed when looking at the printed lines, as these have a number of entries which is lower than the number of fields specified in the `readme.txt` file. \n",
    "\n",
    "Further data discovery is covered in Section 3: EDA and Challenges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rows in the train data\n",
    "!wc -l data/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rows in the test data\n",
    "!wc -l data/test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row of the train data\n",
    "!head -1 data/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first row of the test data\n",
    "!head -1 data/test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 2__ - Algorithm Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "Logistic regression belongs to the family of so-called generalized linear models and is by far one of the most known and applied algorithms for the prediction of a target variable $Y$, which represents the possible occurrence of an event of interest $e$. This variable is binary, and usually is encoded such that $Y=1$ represents the occurrence of $e$. More specifically, given a set of explanatory features $X_i$, $i = 1,2, \\dots, n$, logistic regression characterizes the probability of occurrence of $e$, $\\pi[e] \\equiv \\pi$, as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\pi = \\frac{1}{1 + \\exp^{-z} }\n",
    "\\end{equation}\n",
    "\n",
    "where $z = \\beta_0 + \\sum_{i=1}^n \\beta_i X_i$ and $\\beta_i$ are model parameters. As can be seen from the equation above, and in compliance with probability rules, $\\pi \\in (0, 1)$ for any $\\beta_i$ and $X_i$, owing to the fact that the exponential function is strictly positive, and considering that the denominator is always higher than the numerator. After some algebraic manipulations an equivalent, and more compact, formulation of the above equation can be obtained as:\n",
    "\n",
    "\\begin{equation}\n",
    "log\\left( \\frac{\\pi}{1-\\pi} \\right) = \\beta_0 + \\sum_{i=1}^n \\beta_i X_i\n",
    "\\end{equation}\n",
    "\n",
    "where the left side is usually referred to as the logit function, $logit(\\pi)$, while the right side makes the linear nature of this model explicit. This becomes clearer when considering the decision boundary, i.e., the hypersurface that segments the feature space in positive versus vegative regions. For logistic regression, such boundary is associated with the locus of points in the feature space where $\\pi=0.5$, i.e., the model has no preference as to whether a point in this locus should be assigned to the positive or the negative class. Casting $\\pi=0.5$ in the left side of the equation above renders a linear equation of the decision boundary in the feature space, in compliance with the linear nature of this model.  \n",
    "\n",
    "## Log-loss function and parameter estimation\n",
    "\n",
    "In accordance with established practices in the fields of statistics and machine learning, the parameters $\\beta_i$ of the logistic regression model are estimated via maximization of the log-likelihood function. In essence, for a sample of $m$ data points $(x_{ij}, y_j)$, $i = 1,2,\\dots,n$, $j = 1,2,\\dots,m$, where $x_{ij}$ is the $j$-th record of the $i$-th feature, and $y_j$ is the $j$-th record of the target binary variable $Y$, the parameters $\\beta_i$ are estimated such that the log-likelihood function:\n",
    "\n",
    "\\begin{equation}\n",
    "log\\left[ L(\\beta_i|y_j) \\right] = \\frac{1}{m} log\\left( \\prod_{j = 1}^{m} \\pi_j^{y_j} \\left( 1-\\pi_j \\right)^{1-y_j} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "is maximized. The term in the multiplication corresponds to the likelihood function of the Bernoulli distribution for the (degenerate) case of one single trial and number of successes $y_j = 1$ and $y_j = 0$ for success and failure, respectively.\n",
    "\n",
    "Operationally, the above maximization is usually achieved taking the negative of the log-likelihood function and computing the parameters $\\beta_i$ as the argmin of the negated log-likelihood which, after some manipulations, can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{L} = -log\\left[ L(\\beta_i|y_j) \\right] = - \\frac{1}{m}\\sum_{j=1}^{m} \\left[ y_j \\cdot log(\\pi_j) + (1-y_j) \\cdot log(1-\\pi_j) \\right]\n",
    "\\end{equation}\n",
    "\n",
    "The right term of the equation, also called Cross-Entropy or log-loss, being a function $\\pi$, is ultimately a function of the parameters $\\beta_i$ and the features $X_i$ through the logistic regression relationship. The log-loss gives some insights as to the role of this function during estimation of the parameters. Let us assume that for a certain data point, $(x_{ij}, y_j)$, the target variable is equal to $1$. For this given data point, the right term of the equation simplifies to $-log(\\pi_j)$. Since this term needs to be minimized, the parameters $\\beta_i$ of the model need to be chosen such that $\\pi_j$ approaches $1$ as closely as possible. Conversely for an observation $y_j = 0$, minimization of the log-loss, $-log(1 - \\pi_j)$, requires $\\pi_j$ to approach $0$. This dual role of the log-loss function makes such that likelihood maximization in logistic regression aims to find the set of model parameters which best separate positive from negative observations in the space of the explanatory features $X_i$, in the sense of mapping as closely as possible positive targets to $\\pi = 1$ and negative targets to $\\pi = 0$. Another appealing property, which turns out to the be of paramount importance for the strategy outlined below, is that this log-loss function is convex, i.e., one and only one point of minimum exists in the space of parameters $\\beta_i$.\n",
    "\n",
    "## Gradient descent\n",
    "\n",
    "Finding the optimum set of parameters requires a suitable optimization framework. Among various approaches, gradient descent of $`hat{L}$ is a well-established approach for functions. For a certain point of the $n$-th dimensional space of parameters $\\beta_i$, the gradient of the log-loss function, $\\nabla \\hat{L}$ is computed, and thereafter a translation is performed in the parameter space along the gradient direction (the steepest descent).\n",
    "\n",
    "Gradient descent requires the computation of the gradient. In order to derive its formulation, it is convenient to consider the $i$-th component of $\\nabla \\hat{L}$, i.e.:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_i \\hat{L} = \\frac{\\partial}{\\partial \\beta_i} \\hat{L}\n",
    "\\end{equation}\n",
    "\n",
    "Taking the derivative inside the summation and operating on the logarithm yields:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_i \\hat{L} = - \\frac{1}{m} \\sum_{j=1}^{m} \\left( \\frac{y_j}{\\pi_j} - \\frac{1-y_j}{1-\\pi_j} \\right) \\frac{\\partial \\pi_j}{\\partial \\beta_i}\n",
    "\\end{equation}\n",
    "\n",
    "The derivative of the probability with respect to the parameter equates to (refer to the initial logistic regression formulation):\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\pi_j}{\\partial \\beta_i} = \\frac{\\exp^{-z_j}}{(1+\\exp^{-z_j})^2} \\frac{\\partial z_j} {\\partial \\beta_i} = \\frac{\\exp^{-z_j}}{1+\\exp^{-z_j}} \\frac{1}{1+\\exp^{-z_j}} \\frac{\\partial z_j} {\\partial \\beta_i} = (1-\\pi_j) \\pi_j \\frac{\\partial z_j} {\\partial \\beta_i}\n",
    "\\end{equation}\n",
    "\n",
    "The derivative of the linear combination term yields:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial z_j} {\\partial \\beta_i} = x_{ij}\n",
    "\\end{equation}\n",
    "\n",
    "Putting it all together, one finally obtains: \n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_i \\hat{L} = - \\frac{1}{m} \\sum_{j=1}^{m} \\left[ y_j (1-\\pi_j) - (1-y_j) \\pi_j \\right] x_{ij} = \\frac{1}{m}\\sum_{j=1}^{m} (\\pi_j-y_j) x_{ij}\n",
    "\\end{equation}\n",
    "\n",
    "for $i = 1,2,\\dots,n$. \n",
    "\n",
    "Assuming a certain starting point in the space of parameters, $\\beta_i^0$, gradient descent first computes the gradient $\\nabla \\hat{L}$ at this starting point, and shifts the point along the direction of this gradient by computing a new point $\\beta_i^1 = \\beta_i^0 - \\alpha \\cdot \\nabla \\hat{L}$, where $\\alpha$ is a learning rate. This is done iteratively until suitable stopping criteria are met.\n",
    "\n",
    "## Algorithm for scalable implementation of logistic regression\n",
    "\n",
    "- Assume starting values for logistic parameters $\\beta_i^0$\n",
    "- Set learning parameter $\\alpha$\n",
    "- For each iteration $k$:\n",
    "- Broadcast parameters $\\beta_i^{k}$ to all worker nodes\n",
    "- Map: emit key-value pairs. Key: index $j$, values: target variable $y_j$ and array of explanatory features $x_{ij}$, for $j = 1,2,\\dots,n$\n",
    "- Map: for every $j = 1,2,\\dots,n$ compute probability $\\pi_j$ and $\\left[ y_j (1-\\pi_j) - (1-y_j) \\pi_j \\right] x_{ij}$\n",
    "- Reduce: sum over $j$ and divide by $m$, for $i = 1,2,\\dots,n$\n",
    "- Update $\\beta_i^{k}$\n",
    "- Run next iteration\n",
    "\n",
    "__References:__\n",
    "\n",
    "Bilder, C.R. and Loughin, T.M. (2015). Analysis of Categorical Data with R. CRC Press. \n",
    "\n",
    "Kremonic, Z. (2017). Maximum likelihood and gradient descent demonstration. Blog post. Accessed on July 2019 at https://zlatankr.github.io/posts/2017/03/06/mle-gradient-descent.\n",
    "\n",
    "\n",
    "\n",
    "Additional resources:\n",
    "\n",
    "https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html\n",
    "\n",
    "https://ttic.uchicago.edu/~suriya/website-intromlss2018/course_material/Day3b.pdf \n",
    "\n",
    "http://www.holehouse.org/mlclass/06_Logistic_Regression.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 3__ - EDA & Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For EDA purposes and notebook display, we randomly sampled 5% of the Criteo labs data via code **[Sid: put reference here]**. \n",
    "* This sampled code has a total length of 2292037 records. \n",
    "* *****Delete or add as needed: address the potential of bias; we could address this via bootstrapping and making sure that our clickthrough rate was robust** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import *\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"final_project\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in sample training data and convert to dataframe\n",
    "\n",
    "#train_sample = sc.textFile('data/sample_training.txt',2)\\\n",
    "#                 .map(lambda x: x.split('\\t'))\\\n",
    "#                 .toDF().cache()\n",
    "\n",
    "train_sample = sqlContext.read.format(\"csv\") \\\n",
    "               .option(\"inferSchema\", \"true\") \\\n",
    "               .option(\"header\", \"false\") \\\n",
    "               .option(\"delimiter\", \"\\t\")\\\n",
    "               .load(\"data/sample_training.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+----+----+-----+----+---+---+---+----+----+----+----+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+----+----+--------+--------+--------+--------+----+----+\n",
      "|_c0| _c1|_c2| _c3| _c4|  _c5| _c6|_c7|_c8|_c9|_c10|_c11|_c12|_c13|    _c14|    _c15|    _c16|    _c17|    _c18|    _c19|    _c20|    _c21|    _c22|    _c23|    _c24|    _c25|    _c26|    _c27|    _c28|    _c29|    _c30|    _c31|_c32|_c33|    _c34|    _c35|    _c36|    _c37|_c38|_c39|\n",
      "+---+----+---+----+----+-----+----+---+---+---+----+----+----+----+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+----+----+--------+--------+--------+--------+----+----+\n",
      "|  0|   0|  1|null|   0|16597| 557|  3|  5|123|   0|   1|null|   1|8cf07265|7cd19acc|77f2f2e5|d16679b9|4cf72387|fbad5c96|8fb24933|0b153874|a73ee510|0095a535|3617b5f5|9f32b866|428332cf|b28479f6|83ebd498|31ca40b6|e5ba7672|d0e5eb07|null|null|dfcfc3fa|ad3062eb|32c7478e|aee52b6f|null|null|\n",
      "|  0|   1|  0|   1|null| 1427|   3| 16| 11| 50|   0|   2|   1|null|05db9164|26a88120|615e3e4e|2788fed8|4cf72387|7e0ccccf|3f4ec687|0b153874|a73ee510|0e9ead52|c4adf918|f5d19c1c|85dbe138|07d13a8f|24ff9452|1034ac0d|3486227d|b486119d|null|null|63580fba|    null|32c7478e|2a90c749|null|null|\n",
      "|  0|null|  1|null|null|23255|null|  0|  1| 73|null|   0|null|null|7e5c2ff4|d833535f|b00d1501|d16679b9|25c83c98|7e0ccccf|65c53f25|1f89b562|a73ee510|3b08e48b|ad2bc6f4|e0d76380|39ccb769|b28479f6|a733d362|1203a270|776ce399|281769c2|null|null|73d06dde|    null|32c7478e|aee52b6f|null|null|\n",
      "+---+----+---+----+----+-----+----+---+---+---+----+----+----+----+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+----+----+--------+--------+--------+--------+----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# head first three rows\n",
    "train_sample.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice immediately from the first three rows that column names are not provided. From the Kaggle contest description, however, we do know that the first column (denoted as `c0`) contains the y variable we are interested in; specifically, a 0 denotes an ad that was not clicked on and a 1 denotes an ad that was clicked on. The following 13 fields (denoted from `_c1` to `_c13`) are numerical features, and the remaining 26 columns (denoted from `_14` to `_39` are categorical features. \n",
    "\n",
    "For easier reference in columns, we will rename the following columns as such with the code provided below: \n",
    "* `_c0` as `CTR` to denote our y variable of interest (click-through rate). \n",
    "* Numerical columns `_1` to `_13` to be denoted as `Var1` to `Var13`. \n",
    "* Categorical columns `_1r` to `_39` to be denoted as `Var14` to `Var39`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Renaming of columns for easy reference \n",
    "#### \n",
    "train_sample = train_sample.withColumnRenamed(\"_c0\", \"CTR\") \\\n",
    "       .withColumnRenamed(\"_c1\", \"Var1\") \\\n",
    "       .withColumnRenamed(\"_c2\", \"Var2\") \\\n",
    "       .withColumnRenamed(\"_c3\", \"Var3\") \\\n",
    "       .withColumnRenamed(\"_c4\", \"Var4\") \\\n",
    "       .withColumnRenamed(\"_c5\", \"Var5\") \\\n",
    "       .withColumnRenamed(\"_c6\", \"Var6\") \\\n",
    "       .withColumnRenamed(\"_c7\", \"Var7\") \\\n",
    "       .withColumnRenamed(\"_c8\", \"Var8\") \\\n",
    "       .withColumnRenamed(\"_c9\", \"Var9\") \\\n",
    "       .withColumnRenamed(\"_c10\", \"Var10\") \\\n",
    "       .withColumnRenamed(\"_c11\", \"Var11\") \\\n",
    "       .withColumnRenamed(\"_c12\", \"Var12\") \\\n",
    "       .withColumnRenamed(\"_c13\", \"Var13\") \\\n",
    "        .withColumnRenamed(\"_c14\", \"Var14\") \\\n",
    "        .withColumnRenamed(\"_c15\", \"Var15\") \\\n",
    "        .withColumnRenamed(\"_c16\", \"Var16\") \\\n",
    "        .withColumnRenamed(\"_c17\", \"Var17\") \\\n",
    "        .withColumnRenamed(\"_c18\", \"Var18\") \\\n",
    "        .withColumnRenamed(\"_c19\", \"Var19\") \\\n",
    "        .withColumnRenamed(\"_c20\", \"Var20\") \\\n",
    "        .withColumnRenamed(\"_c21\", \"Var21\") \\\n",
    "        .withColumnRenamed(\"_c22\", \"Var22\") \\\n",
    "        .withColumnRenamed(\"_c23\", \"Var23\") \\\n",
    "        .withColumnRenamed(\"_c24\", \"Var24\") \\\n",
    "        .withColumnRenamed(\"_c25\", \"Var25\") \\\n",
    "        .withColumnRenamed(\"_c26\", \"Var26\") \\\n",
    "        .withColumnRenamed(\"_c27\", \"Var27\") \\\n",
    "        .withColumnRenamed(\"_c28\", \"Var28\") \\\n",
    "        .withColumnRenamed(\"_c29\", \"Var29\") \\\n",
    "        .withColumnRenamed(\"_c30\", \"Var30\") \\\n",
    "        .withColumnRenamed(\"_c31\", \"Var31\") \\\n",
    "        .withColumnRenamed(\"_c32\", \"Var32\") \\\n",
    "        .withColumnRenamed(\"_c33\", \"Var33\") \\\n",
    "        .withColumnRenamed(\"_c34\", \"Var34\") \\\n",
    "        .withColumnRenamed(\"_c35\", \"Var35\") \\\n",
    "        .withColumnRenamed(\"_c36\", \"Var36\") \\\n",
    "        .withColumnRenamed(\"_c37\", \"Var37\") \\\n",
    "        .withColumnRenamed(\"_c38\", \"Var38\") \\\n",
    "        .withColumnRenamed(\"_c39\", \"Var39\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+----+-----+----+----+----+----+-----+-----+-----+-----+\n",
      "|CTR|Var1|Var2|Var3|Var4| Var5|Var6|Var7|Var8|Var9|Var10|Var11|Var12|Var13|\n",
      "+---+----+----+----+----+-----+----+----+----+----+-----+-----+-----+-----+\n",
      "|  0|   0|   1|null|   0|16597| 557|   3|   5| 123|    0|    1| null|    1|\n",
      "|  0|   1|   0|   1|null| 1427|   3|  16|  11|  50|    0|    2|    1| null|\n",
      "|  0|null|   1|null|null|23255|null|   0|   1|  73| null|    0| null| null|\n",
      "|  0|   0|  37|  23|   9| 1635|  84|   2|  17| 109|    0|    2| null|   50|\n",
      "|  0|   2|   0|   9|   5|   44|   5|   2|   4|   5|    2|    2| null|    5|\n",
      "|  0|   0|   1|  14|   2|  120| 733|   0|  12| 606|    0|    0|   98|    2|\n",
      "|  0|null|   1|null|null| null|null|null|   0|null| null| null| null| null|\n",
      "|  0|   0|3295|null|   0| 4546| 149|  11|  30| 220|    0|    3| null|    2|\n",
      "|  0|   1|   1|   4|  17|  108|  22|   1|  24|  22|    1|    1| null|   22|\n",
      "|  0|null|  19|  32|   0| 1994|null|   0|  19|  26| null|    0| null|    3|\n",
      "|  0|null|  14|  28|  14|26324|  39|   3|  21|  32| null|    1| null|   14|\n",
      "|  0|null|  25|   1|null|17330|  62|   1|   3|  76| null|    1| null| null|\n",
      "|  0|null|   0|  31|   2|41016|null|   0|   9|  17| null|    0| null|    8|\n",
      "|  0|null| 164|   7|   2|10118| 259|  20|  11| 256| null|    5|    0|   30|\n",
      "|  0|   0|  35|null|   9|40556|null|   0|  41|  10|    0|    0| null|    9|\n",
      "|  0|null|   0|  21|   4|10121|null|   0|   7|  77| null|    0| null|    5|\n",
      "|  0|   0|  65|  29|   1| 7777| 566|   1|   1|  22|    0|    1| null|    1|\n",
      "|  0|   0|   4|null|null| 9092| 536|   1|  42| 146|    0|    1| null| null|\n",
      "|  1|   0|   0|   3|   1| 1516|   8|   3|   2|   4|    0|    3| null|    1|\n",
      "|  0|   3|  44|   1|   2|    1|   2|   3|   1|   2|    1|    1| null|    2|\n",
      "+---+----+----+----+----+-----+----+----+----+----+-----+-----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing top 20 rows of the numerical columns \n",
    "\n",
    "train_sample.select(\"CTR\", \"Var1\", \"Var2\", \"Var3\", \"Var4\", \"Var5\", \"Var6\", \"Var7\", \"Var8\", \"Var9\", \"Var10\", \"Var11\", \"Var12\", \"Var13\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|   Var14|   Var15|   Var16|   Var17|   Var18|   Var19|   Var20|   Var21|   Var22|   Var23|   Var24|   Var25|   Var26|   Var27|   Var28|   Var29|   Var30|   Var31|   Var32|   Var33|   Var34|   Var35|   Var36|   Var37|   Var38|   Var39|\n",
      "+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|8cf07265|7cd19acc|77f2f2e5|d16679b9|4cf72387|fbad5c96|8fb24933|0b153874|a73ee510|0095a535|3617b5f5|9f32b866|428332cf|b28479f6|83ebd498|31ca40b6|e5ba7672|d0e5eb07|    null|    null|dfcfc3fa|ad3062eb|32c7478e|aee52b6f|    null|    null|\n",
      "|05db9164|26a88120|615e3e4e|2788fed8|4cf72387|7e0ccccf|3f4ec687|0b153874|a73ee510|0e9ead52|c4adf918|f5d19c1c|85dbe138|07d13a8f|24ff9452|1034ac0d|3486227d|b486119d|    null|    null|63580fba|    null|32c7478e|2a90c749|    null|    null|\n",
      "|7e5c2ff4|d833535f|b00d1501|d16679b9|25c83c98|7e0ccccf|65c53f25|1f89b562|a73ee510|3b08e48b|ad2bc6f4|e0d76380|39ccb769|b28479f6|a733d362|1203a270|776ce399|281769c2|    null|    null|73d06dde|    null|32c7478e|aee52b6f|    null|    null|\n",
      "|05db9164|9b25e48b|2d9b2559|96302ef8|43b19349|fbad5c96|e64ca89e|5b392875|a73ee510|3b76bfa9|87bb382c|3d899a5a|d95a2a6d|8ceecbc8|8f3ef960|24352c5c|07c540c4|7d8c03aa|fbf39fb5|a458ea53|0c61029b|    null|32c7478e|216a829e|001f3601|abc00283|\n",
      "|5a9ed9b0|3e4b7926|e1266b28|09e3cd5a|384874ce|7e0ccccf|675e81f6|5b392875|a73ee510|d1ebaddf|4a77ddca|eb8ded57|dc1d72e4|07d13a8f|e6863a8e|3d9023a4|07c540c4|e261f8d8|21ddcdc9|b1252a9d|31b4af04|    null|32c7478e|8d653a3e|445bbe3b|32280082|\n",
      "|5a9ed9b0|097e9399|915bbd8f|26ac5cc6|f3474129|fe6b92e5|875679ca|37e4aa92|a73ee510|3b08e48b|bbd0e773|87408e45|79ae8b9a|1adce6ef|5c3dbd29|8759a2d9|8efede7f|97029569|21ddcdc9|b1252a9d|6ec2bcf7|    null|55dd3565|7f686ab3|2bf691b1|bebc2875|\n",
      "|68fd1e64|791f3f76|d032c263|c18be181|4cf72387|7e0ccccf|970f01b2|0b153874|7cc72ec2|3b08e48b|36bccca0|dfbb09fb|80467802|07d13a8f|876a7e78|84898b2a|2005abd1|0f4a15b0|    null|    null|0014c32a|    null|55dd3565|3b183c5c|    null|    null|\n",
      "|05db9164|4c2bc594|d032c263|c18be181|25c83c98|7e0ccccf|7956c2ff|0b153874|a73ee510|44ac3250|4b0929e2|dfbb09fb|c0ed8bfc|8ceecbc8|7ac43a46|84898b2a|e5ba7672|bc48b783|    null|    null|0014c32a|c9d4222a|55dd3565|3b183c5c|    null|    null|\n",
      "|05db9164|d833535f|77f2f2e5|d16679b9|4cf72387|7e0ccccf|def4a4d4|5b392875|a73ee510|0c70a731|4ba74619|9f32b866|879fa878|b28479f6|a66dcf27|31ca40b6|d4bb7bd8|7b49e3d2|    null|    null|dfcfc3fa|    null|423fab69|aee52b6f|    null|    null|\n",
      "|be589b51|38d50e09|4724f2c8|8510f416|4cf72387|7e0ccccf|38eb9cf4|0b153874|a73ee510|2462946f|7f8ffe57|f6fe1d50|46f42a63|b28479f6|42b3012c|ad774107|1e88c74f|582152eb|21ddcdc9|5840adea|fbaf98df|    null|32c7478e|e773f0cb|001f3601|1b0ebd59|\n",
      "|ae82ea21|4c2bc594|d032c263|c18be181|25c83c98|fe6b92e5|869243b9|5b392875|a73ee510|3b08e48b|6a77517a|dfbb09fb|e0230d57|1adce6ef|ae0c3875|84898b2a|27c07bd6|15a36060|    null|    null|0014c32a|    null|3a171ecb|3b183c5c|    null|    null|\n",
      "|05db9164|bce95927|f69c6d34|13508380|384874ce|fe6b92e5|4c5c7066|0b153874|a73ee510|d077d4d4|8924112e|0fd301b6|3cf672d1|07d13a8f|fec218c0|5c495dbe|07c540c4|04d863d5|21ddcdc9|b1252a9d|a3a82059|78e2e389|423fab69|45ab94c8|e8b83407|c84c4aec|\n",
      "|05db9164|38a947a1|    null|    null|25c83c98|3bf701e7|49042125|062b5529|7cc72ec2|4624c4e8|ba1ff80a|    null|b95f83fa|b28479f6|0cfbc5df|    null|1e88c74f|be457d6e|    null|    null|    null|    null|bcdee96c|    null|    null|    null|\n",
      "|39af2607|26a88120|b00d1501|d16679b9|25c83c98|fbad5c96|49b74ebc|1f89b562|a73ee510|7f79890b|c4adf918|e0d76380|85dbe138|b28479f6|2ebbf26a|1203a270|e5ba7672|b486119d|    null|    null|73d06dde|    null|32c7478e|aee52b6f|    null|    null|\n",
      "|68fd1e64|d833535f|b00d1501|d16679b9|25c83c98|fe6b92e5|01a0f3f6|0b153874|a73ee510|3b08e48b|f045731b|e0d76380|252ee845|b28479f6|a733d362|1203a270|e5ba7672|281769c2|    null|    null|73d06dde|    null|32c7478e|aee52b6f|    null|    null|\n",
      "|05db9164|71ca0a25|396df967|328b42c3|25c83c98|7e0ccccf|5c116cc3|0b153874|a73ee510|f62834dd|d02264a7|8481d649|14e6fd48|b28479f6|a67c19b7|b2f2a0c7|1e88c74f|9bf8ffef|21ddcdc9|5840adea|f0bb1194|    null|3a171ecb|a5ce2d0d|001f3601|984e0db0|\n",
      "|05db9164|09e68b86|aa8c1539|85dd697c|25c83c98|13718bbd|24db17b4|0b153874|a73ee510|eaaee8c6|d6ea7935|d8c29807|74838342|8ceecbc8|d2f03b75|c64d548f|d4bb7bd8|63cdbb21|cf99e5de|5840adea|5f957280|    null|3a171ecb|1793a828|e8b83407|b7d9c3bc|\n",
      "|39af2607|e18b1e61|    null|    null|43b19349|7e0ccccf|9e5b069d|0b153874|a73ee510|550727c0|6153cf57|    null|769a1844|b28479f6|972b922a|    null|d4bb7bd8|832bedbd|    null|    null|    null|    null|be7c41b4|    null|    null|    null|\n",
      "|5a9ed9b0|6887a43c|5d1ca1e5|196060ff|25c83c98|7e0ccccf|2b322b66|0b153874|a73ee510|99fe7a1f|24adbadc|71c32035|fc371461|051219e6|61f52294|cf393f9f|e5ba7672|1c130afa|21ddcdc9|b1252a9d|06c4ef72|ad3062eb|32c7478e|6bc2bf95|445bbe3b|dc39e0d1|\n",
      "|a86f8721|38a947a1|2ca5a244|eca41678|4cf72387|fe6b92e5|7fafef37|5b392875|a73ee510|5ba575e7|78f92234|5db0c556|9be66b48|1adce6ef|7fb3b951|f5f5bdfa|07c540c4|7e345426|    null|    null|82e27b23|    null|3a171ecb|f4cd3bc3|    null|    null|\n",
      "+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing top 20 rows of the categorical columns \n",
    "\n",
    "train_sample.select('Var14','Var15','Var16','Var17','Var18','Var19','Var20','Var21',\n",
    "                    'Var22','Var23','Var24','Var25','Var26','Var27','Var28','Var29','Var30',\n",
    "                   'Var31','Var32','Var33','Var34','Var35','Var36','Var37','Var38','Var39').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Brief Statistics and Coverage of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our code below, we depict brief statistics about our sampled data: \n",
    "* A total of 2,292,037 rows (~5% of the training data) have been sampled out. \n",
    "* Our sampled data shows a click through rate of approximately 25% \n",
    "* Coverage: For the most part, most of our columns show pretty good coverage (>95%). We do see, however, a troubling number of Null (missing) values for a couple columns. \n",
    "    * Var3, Var13, Var4, and Var6 have around 25% of their values as Null. \n",
    "    * Perhaps the most alarming: columns Var32, Var33, Var38, Var39, Var10, Var1, Var35, and Var12 have less than 50% of their values as non-Null. \n",
    "    \n",
    "A significant challenge for us will involve having to deal with high number of Null values in some of our columns. For numerical values, it is certainly possible to impute a number to fill in for Null values, but this challenge gets tricky with categorical variables. The handling of null values for categorical variables will be discussed in **[insert section here]**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2292037"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a count of the total number of rows in our sampled data. \n",
    "total_count = train_sample.count()\n",
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2564675003064959"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating approximate click through rate of our sampled training data \n",
    "\n",
    "train_sample.filter(train_sample.CTR==1).count()/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coverage_nonNull</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CTR</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var14</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var36</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var31</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var30</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var28</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var27</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var26</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var24</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var23</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var22</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var21</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var18</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var15</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var20</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var2</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var8</th>\n",
       "      <td>0.999496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var5</th>\n",
       "      <td>0.974168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var17</th>\n",
       "      <td>0.965857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var37</th>\n",
       "      <td>0.965857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var34</th>\n",
       "      <td>0.965857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var25</th>\n",
       "      <td>0.965857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var16</th>\n",
       "      <td>0.965857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var29</th>\n",
       "      <td>0.965857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var11</th>\n",
       "      <td>0.956850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var9</th>\n",
       "      <td>0.956850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var7</th>\n",
       "      <td>0.956850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var19</th>\n",
       "      <td>0.878906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var3</th>\n",
       "      <td>0.785205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var13</th>\n",
       "      <td>0.782994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var4</th>\n",
       "      <td>0.782994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var6</th>\n",
       "      <td>0.776426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var32</th>\n",
       "      <td>0.559533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var33</th>\n",
       "      <td>0.559533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var38</th>\n",
       "      <td>0.559533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var39</th>\n",
       "      <td>0.559533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var10</th>\n",
       "      <td>0.546833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var1</th>\n",
       "      <td>0.546833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var35</th>\n",
       "      <td>0.237235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var12</th>\n",
       "      <td>0.234542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coverage_nonNull\n",
       "CTR            1.000000\n",
       "Var14          1.000000\n",
       "Var36          1.000000\n",
       "Var31          1.000000\n",
       "Var30          1.000000\n",
       "Var28          1.000000\n",
       "Var27          1.000000\n",
       "Var26          1.000000\n",
       "Var24          1.000000\n",
       "Var23          1.000000\n",
       "Var22          1.000000\n",
       "Var21          1.000000\n",
       "Var18          1.000000\n",
       "Var15          1.000000\n",
       "Var20          1.000000\n",
       "Var2           1.000000\n",
       "Var8           0.999496\n",
       "Var5           0.974168\n",
       "Var17          0.965857\n",
       "Var37          0.965857\n",
       "Var34          0.965857\n",
       "Var25          0.965857\n",
       "Var16          0.965857\n",
       "Var29          0.965857\n",
       "Var11          0.956850\n",
       "Var9           0.956850\n",
       "Var7           0.956850\n",
       "Var19          0.878906\n",
       "Var3           0.785205\n",
       "Var13          0.782994\n",
       "Var4           0.782994\n",
       "Var6           0.776426\n",
       "Var32          0.559533\n",
       "Var33          0.559533\n",
       "Var38          0.559533\n",
       "Var39          0.559533\n",
       "Var10          0.546833\n",
       "Var1           0.546833\n",
       "Var35          0.237235\n",
       "Var12          0.234542"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating coverage: \n",
    "# The column \"Coverage_nonNull\" (expressed as percentage) depicts how many non-null values are in the column. \n",
    "# This gives a sense of how well a particular variable covers our entire dataset. \n",
    "\n",
    "from pyspark.sql.functions import col, count, isnan, stddev, lit, sum\n",
    "\n",
    "coverage = train_sample.agg(*[\n",
    "    (count(c)/total_count).alias(c)    # vertical (column-wise) operations in SQL ignore NULLs\n",
    "    for c in train_sample.columns\n",
    "]).toPandas()\n",
    "\n",
    "coverage_summary = coverage.T\n",
    "coverage_summary.columns = ['Coverage_nonNull']\n",
    "coverage_summary.sort_values(by='Coverage_nonNull', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Numerical Variables\n",
    "\n",
    "### 3.2.1 Basic Statistics\n",
    "* In Table 3.0, we calculate basic statistics to summarize our numerical variables: count of observations that have the variable, the mean of the variable, the standard deviation of the variable, and the min and max of the variable. \n",
    "    * We note that the range for each variable is different; although we do not know the exact definition of what each variable stands for, we can tell that the range of each variable can vary greatly, such as 0 to 8 for Var10 but 0 to 2,634,953 for Var5. \n",
    "    * Variable 2 has a minimum value of -2, which is odd given that the Kaggle criteo data description (https://www.kaggle.com/c/criteo-display-ad-challenge/data) specifically states that the numerical variables are mostly counts but there is no specification as to whether all numbers should be non-negative. This will be addressed in **[insert section]** on deciding how negative values are to be treated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var1</th>\n",
       "      <td>1253362</td>\n",
       "      <td>3.52458746954192</td>\n",
       "      <td>9.456074158477476</td>\n",
       "      <td>0</td>\n",
       "      <td>1575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var2</th>\n",
       "      <td>2292037</td>\n",
       "      <td>105.5236778463873</td>\n",
       "      <td>387.9460727424658</td>\n",
       "      <td>-2</td>\n",
       "      <td>19219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var3</th>\n",
       "      <td>1799718</td>\n",
       "      <td>27.030229180349366</td>\n",
       "      <td>402.6173876100675</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var4</th>\n",
       "      <td>1794652</td>\n",
       "      <td>7.327119129502544</td>\n",
       "      <td>8.845164661144699</td>\n",
       "      <td>0</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var5</th>\n",
       "      <td>2232828</td>\n",
       "      <td>18536.03390498507</td>\n",
       "      <td>69153.1755142129</td>\n",
       "      <td>0</td>\n",
       "      <td>2634953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var6</th>\n",
       "      <td>1779597</td>\n",
       "      <td>115.58777689555556</td>\n",
       "      <td>337.0288166711634</td>\n",
       "      <td>0</td>\n",
       "      <td>66619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var7</th>\n",
       "      <td>2193136</td>\n",
       "      <td>16.459486324605496</td>\n",
       "      <td>70.80815785839796</td>\n",
       "      <td>0</td>\n",
       "      <td>34536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var8</th>\n",
       "      <td>2290882</td>\n",
       "      <td>12.536948651218177</td>\n",
       "      <td>16.92910564553372</td>\n",
       "      <td>0</td>\n",
       "      <td>4513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var9</th>\n",
       "      <td>2193136</td>\n",
       "      <td>105.99417500784266</td>\n",
       "      <td>219.74396942043634</td>\n",
       "      <td>0</td>\n",
       "      <td>18345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var10</th>\n",
       "      <td>1253362</td>\n",
       "      <td>0.6180863948324586</td>\n",
       "      <td>0.6845344117066056</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var11</th>\n",
       "      <td>2193136</td>\n",
       "      <td>2.7380673154788395</td>\n",
       "      <td>5.22875057526333</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var12</th>\n",
       "      <td>537580</td>\n",
       "      <td>0.9924978607835113</td>\n",
       "      <td>6.08334075723253</td>\n",
       "      <td>0</td>\n",
       "      <td>1831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var13</th>\n",
       "      <td>1794652</td>\n",
       "      <td>8.217247689245603</td>\n",
       "      <td>15.876313370693108</td>\n",
       "      <td>0</td>\n",
       "      <td>4317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                   1                   2    3        4\n",
       "summary    count                mean              stddev  min      max\n",
       "Var1     1253362    3.52458746954192   9.456074158477476    0     1575\n",
       "Var2     2292037   105.5236778463873   387.9460727424658   -2    19219\n",
       "Var3     1799718  27.030229180349366   402.6173876100675    0    65535\n",
       "Var4     1794652   7.327119129502544   8.845164661144699    0      969\n",
       "Var5     2232828   18536.03390498507    69153.1755142129    0  2634953\n",
       "Var6     1779597  115.58777689555556   337.0288166711634    0    66619\n",
       "Var7     2193136  16.459486324605496   70.80815785839796    0    34536\n",
       "Var8     2290882  12.536948651218177   16.92910564553372    0     4513\n",
       "Var9     2193136  105.99417500784266  219.74396942043634    0    18345\n",
       "Var10    1253362  0.6180863948324586  0.6845344117066056    0        8\n",
       "Var11    2193136  2.7380673154788395    5.22875057526333    0      163\n",
       "Var12     537580  0.9924978607835113    6.08334075723253    0     1831\n",
       "Var13    1794652   8.217247689245603  15.876313370693108    0     4317"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########\n",
    "# Table 3.0: Basic statistics \n",
    "########\n",
    "\n",
    "numerical_cols = ['Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8','Var9','Var10','Var11','Var12','Var13']\n",
    "\n",
    "numerical_stats = train_sample.describe(numerical_cols).toPandas()\n",
    "numerical_stats.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below in Table 3.1, we also calculated the mean, standard deviation, count, min, and max of each numerical variable grouped by the click through rate (CTR) target variable. \n",
    "    * From here, we made a rough guess-timate of the 95% confidence interval of the mean of the numerical variables to see if we could distinguish enough difference between observations that had a successful or unsuccessful click through on an ad. We realize that the distribution of the numerical variables were not exactly normal, but given the high number of observations (>100,000 per group), a 95% confidence interval by the form of $(\\mu - 1.96*\\frac{\\sigma}{n_{group}}, \\mu +1.96*\\frac{\\sigma}{n_{group}})$ should give a rough estimate of the group means and their standard deviations. \n",
    "    * We can see that most of numerical variables show quite some difference between their group means. The columns `lowerCI_CTR0`, `upperCI_CTR0` depict the lower and upper confidence interval bounds for the observations under CTR = 0, while the columns `lowerCI_CTR1`, `upperCI_CTR1` depict the lower and upper confidence interval bounds for the observations under CTR = 1. Most of the confidence intervals between the 2 groups do not overlap; there appears to be enough information in our numerical variables such that they should all be included into our model to distinguish the difference between CTR=0 or CTR=1 prediction. That being said, it should be noted that Var4, Var8, and Var10 have the closest confidence interval boundaries compared to the other columns, and it is possible that these 3 columns might have smaller explaining power compared to the other numerical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>avg_CTR0</th>\n",
       "      <th>avg_CTR1</th>\n",
       "      <th>std_CTR0</th>\n",
       "      <th>std_CTR1</th>\n",
       "      <th>min_CTR0</th>\n",
       "      <th>min_CTR1</th>\n",
       "      <th>max_CTR0</th>\n",
       "      <th>max_CTR1</th>\n",
       "      <th>count_CTR0</th>\n",
       "      <th>count_CTR1</th>\n",
       "      <th>lowerCI_CTR0</th>\n",
       "      <th>upperCI_CTR0</th>\n",
       "      <th>lowerCI_CTR1</th>\n",
       "      <th>upperCI_CTR1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Var1</td>\n",
       "      <td>2.946473</td>\n",
       "      <td>4.790206</td>\n",
       "      <td>8.674151</td>\n",
       "      <td>10.868277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1575</td>\n",
       "      <td>908</td>\n",
       "      <td>860362</td>\n",
       "      <td>393000</td>\n",
       "      <td>2.928143</td>\n",
       "      <td>2.964802</td>\n",
       "      <td>4.756226</td>\n",
       "      <td>4.824186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Var2</td>\n",
       "      <td>95.612975</td>\n",
       "      <td>134.256090</td>\n",
       "      <td>361.190633</td>\n",
       "      <td>455.522574</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>19219</td>\n",
       "      <td>16956</td>\n",
       "      <td>1704204</td>\n",
       "      <td>587833</td>\n",
       "      <td>95.070685</td>\n",
       "      <td>96.155265</td>\n",
       "      <td>133.091591</td>\n",
       "      <td>135.420588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Var3</td>\n",
       "      <td>23.801411</td>\n",
       "      <td>37.103464</td>\n",
       "      <td>248.094061</td>\n",
       "      <td>689.683142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>65535</td>\n",
       "      <td>1362871</td>\n",
       "      <td>436847</td>\n",
       "      <td>23.384882</td>\n",
       "      <td>24.217940</td>\n",
       "      <td>35.058240</td>\n",
       "      <td>39.148689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Var4</td>\n",
       "      <td>7.601784</td>\n",
       "      <td>6.499002</td>\n",
       "      <td>9.112409</td>\n",
       "      <td>7.928093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969</td>\n",
       "      <td>295</td>\n",
       "      <td>1347666</td>\n",
       "      <td>446986</td>\n",
       "      <td>7.586399</td>\n",
       "      <td>7.617169</td>\n",
       "      <td>6.475760</td>\n",
       "      <td>6.522244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Var5</td>\n",
       "      <td>21823.328636</td>\n",
       "      <td>9209.995004</td>\n",
       "      <td>76456.296149</td>\n",
       "      <td>40591.419351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2634953</td>\n",
       "      <td>1906516</td>\n",
       "      <td>1650907</td>\n",
       "      <td>581921</td>\n",
       "      <td>21706.699242</td>\n",
       "      <td>21939.958031</td>\n",
       "      <td>9105.701252</td>\n",
       "      <td>9314.288757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Var6</td>\n",
       "      <td>136.768530</td>\n",
       "      <td>64.598590</td>\n",
       "      <td>377.688449</td>\n",
       "      <td>199.877834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66619</td>\n",
       "      <td>17917</td>\n",
       "      <td>1257313</td>\n",
       "      <td>522284</td>\n",
       "      <td>136.108342</td>\n",
       "      <td>137.428719</td>\n",
       "      <td>64.056505</td>\n",
       "      <td>65.140675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Var7</td>\n",
       "      <td>13.125326</td>\n",
       "      <td>25.870308</td>\n",
       "      <td>63.142022</td>\n",
       "      <td>88.273909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34536</td>\n",
       "      <td>11839</td>\n",
       "      <td>1619399</td>\n",
       "      <td>573737</td>\n",
       "      <td>13.028074</td>\n",
       "      <td>13.222577</td>\n",
       "      <td>25.641889</td>\n",
       "      <td>26.098727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Var8</td>\n",
       "      <td>12.799855</td>\n",
       "      <td>11.775066</td>\n",
       "      <td>18.047062</td>\n",
       "      <td>13.133923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4513</td>\n",
       "      <td>733</td>\n",
       "      <td>1703164</td>\n",
       "      <td>587718</td>\n",
       "      <td>12.772751</td>\n",
       "      <td>12.826959</td>\n",
       "      <td>11.741487</td>\n",
       "      <td>11.808644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Var9</td>\n",
       "      <td>103.372396</td>\n",
       "      <td>113.394268</td>\n",
       "      <td>214.584881</td>\n",
       "      <td>233.533582</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18345</td>\n",
       "      <td>11996</td>\n",
       "      <td>1619399</td>\n",
       "      <td>573737</td>\n",
       "      <td>103.041890</td>\n",
       "      <td>103.702901</td>\n",
       "      <td>112.789973</td>\n",
       "      <td>113.998563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Var10</td>\n",
       "      <td>0.537784</td>\n",
       "      <td>0.793885</td>\n",
       "      <td>0.642230</td>\n",
       "      <td>0.739217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>860362</td>\n",
       "      <td>393000</td>\n",
       "      <td>0.536427</td>\n",
       "      <td>0.539141</td>\n",
       "      <td>0.791574</td>\n",
       "      <td>0.796197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Var11</td>\n",
       "      <td>2.254756</td>\n",
       "      <td>4.102235</td>\n",
       "      <td>4.503326</td>\n",
       "      <td>6.689281</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>148</td>\n",
       "      <td>1619399</td>\n",
       "      <td>573737</td>\n",
       "      <td>2.247820</td>\n",
       "      <td>2.261692</td>\n",
       "      <td>4.084926</td>\n",
       "      <td>4.119544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Var12</td>\n",
       "      <td>0.685031</td>\n",
       "      <td>1.752763</td>\n",
       "      <td>5.412193</td>\n",
       "      <td>7.434564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1831</td>\n",
       "      <td>347</td>\n",
       "      <td>382777</td>\n",
       "      <td>154803</td>\n",
       "      <td>0.667885</td>\n",
       "      <td>0.702176</td>\n",
       "      <td>1.715727</td>\n",
       "      <td>1.789799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Var13</td>\n",
       "      <td>8.959959</td>\n",
       "      <td>5.977968</td>\n",
       "      <td>17.427552</td>\n",
       "      <td>9.466685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4317</td>\n",
       "      <td>629</td>\n",
       "      <td>1347666</td>\n",
       "      <td>446986</td>\n",
       "      <td>8.930535</td>\n",
       "      <td>8.989383</td>\n",
       "      <td>5.950215</td>\n",
       "      <td>6.005721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column      avg_CTR0     avg_CTR1      std_CTR0      std_CTR1  min_CTR0  \\\n",
       "0    Var1      2.946473     4.790206      8.674151     10.868277         0   \n",
       "1    Var2     95.612975   134.256090    361.190633    455.522574        -2   \n",
       "2    Var3     23.801411    37.103464    248.094061    689.683142         0   \n",
       "3    Var4      7.601784     6.499002      9.112409      7.928093         0   \n",
       "4    Var5  21823.328636  9209.995004  76456.296149  40591.419351         0   \n",
       "5    Var6    136.768530    64.598590    377.688449    199.877834         0   \n",
       "6    Var7     13.125326    25.870308     63.142022     88.273909         0   \n",
       "7    Var8     12.799855    11.775066     18.047062     13.133923         0   \n",
       "8    Var9    103.372396   113.394268    214.584881    233.533582         0   \n",
       "9   Var10      0.537784     0.793885      0.642230      0.739217         0   \n",
       "10  Var11      2.254756     4.102235      4.503326      6.689281         0   \n",
       "11  Var12      0.685031     1.752763      5.412193      7.434564         0   \n",
       "12  Var13      8.959959     5.977968     17.427552      9.466685         0   \n",
       "\n",
       "    min_CTR1  max_CTR0  max_CTR1  count_CTR0  count_CTR1  lowerCI_CTR0  \\\n",
       "0          0      1575       908      860362      393000      2.928143   \n",
       "1         -2     19219     16956     1704204      587833     95.070685   \n",
       "2          0     65535     65535     1362871      436847     23.384882   \n",
       "3          0       969       295     1347666      446986      7.586399   \n",
       "4          0   2634953   1906516     1650907      581921  21706.699242   \n",
       "5          0     66619     17917     1257313      522284    136.108342   \n",
       "6          0     34536     11839     1619399      573737     13.028074   \n",
       "7          0      4513       733     1703164      587718     12.772751   \n",
       "8          0     18345     11996     1619399      573737    103.041890   \n",
       "9          0         8         7      860362      393000      0.536427   \n",
       "10         0       163       148     1619399      573737      2.247820   \n",
       "11         0      1831       347      382777      154803      0.667885   \n",
       "12         0      4317       629     1347666      446986      8.930535   \n",
       "\n",
       "    upperCI_CTR0  lowerCI_CTR1  upperCI_CTR1  \n",
       "0       2.964802      4.756226      4.824186  \n",
       "1      96.155265    133.091591    135.420588  \n",
       "2      24.217940     35.058240     39.148689  \n",
       "3       7.617169      6.475760      6.522244  \n",
       "4   21939.958031   9105.701252   9314.288757  \n",
       "5     137.428719     64.056505     65.140675  \n",
       "6      13.222577     25.641889     26.098727  \n",
       "7      12.826959     11.741487     11.808644  \n",
       "8     103.702901    112.789973    113.998563  \n",
       "9       0.539141      0.791574      0.796197  \n",
       "10      2.261692      4.084926      4.119544  \n",
       "11      0.702176      1.715727      1.789799  \n",
       "12      8.989383      5.950215      6.005721  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########\n",
    "# Table 3.1 Basic Statistics by Group (click through rate == 0 vs click through rate == 1) in each column. \n",
    "########## \n",
    "\n",
    "grouped_CTR0 = []\n",
    "grouped_CTR1 = []\n",
    "\n",
    "for p in range(0, len(numerical_cols)): \n",
    "    g1_avg, g0_avg=train_sample.groupBy('CTR').agg({numerical_cols[p]:\"avg\"}).collect()\n",
    "    g1_std, g0_std=train_sample.groupBy('CTR').agg({numerical_cols[p]:\"stddev\"}).collect()\n",
    "    g1_count, g0_count = train_sample.groupBy('CTR').agg({numerical_cols[p]:\"count\"}).collect()\n",
    "    g1_min, g0_min = train_sample.groupBy('CTR').agg({numerical_cols[p]:\"min\"}).collect()\n",
    "    g1_max, g0_max = train_sample.groupBy('CTR').agg({numerical_cols[p]:\"max\"}).collect()\n",
    "    grouped_CTR1.append({'Column': numerical_cols[p], 'avg_CTR1': g1_avg[1], 'std_CTR1': g1_std[1], \n",
    "                       'count_CTR1': g1_count[1], 'min_CTR1': g1_min[1], 'max_CTR1': g1_max[1]})\n",
    "    grouped_CTR0.append({'Column': numerical_cols[p], 'avg_CTR0': g0_avg[1], 'std_CTR0': g0_std[1],\n",
    "                       'count_CTR0': g0_count[1], 'min_CTR0': g0_min[1], 'max_CTR0': g0_max[1]})\n",
    "\n",
    "CTR0_df = pd.DataFrame(grouped_CTR0)\n",
    "CTR1_df = pd.DataFrame(grouped_CTR1)\n",
    "merged_group_agg = CTR0_df.merge(CTR1_df, how='left', on='Column')[['Column','avg_CTR0','avg_CTR1','std_CTR0','std_CTR1','min_CTR0','min_CTR1','max_CTR0','max_CTR1','count_CTR0','count_CTR1']]\n",
    "merged_group_agg['lowerCI_CTR0']=merged_group_agg['avg_CTR0']-((1.96)*(merged_group_agg['std_CTR0']/np.sqrt(merged_group_agg['count_CTR0'])))\n",
    "merged_group_agg['upperCI_CTR0']=merged_group_agg['avg_CTR0']+((1.96)*(merged_group_agg['std_CTR0']/np.sqrt(merged_group_agg['count_CTR0'])))\n",
    "merged_group_agg['lowerCI_CTR1']=merged_group_agg['avg_CTR1']-((1.96)*(merged_group_agg['std_CTR1']/np.sqrt(merged_group_agg['count_CTR1'])))\n",
    "merged_group_agg['upperCI_CTR1']=merged_group_agg['avg_CTR1']+((1.96)*(merged_group_agg['std_CTR1']/np.sqrt(merged_group_agg['count_CTR1'])))\n",
    "merged_group_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Histograms \n",
    "* We also plot the histograms of each of the numerical variables to gain a sense of distribution. \n",
    "* We note that pretty much all of the numerical variables are skewed right; most of the observations generally are centered around the lower range of the values and the remaining higher values are tailed off to the right. \n",
    "* As the range of all variables varies widely across all variables, we plan to standardize the numerical variables by **[insert standardization method]** such that not one variable overpowers over the other numerical variables solely due to scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJUAAAJLCAYAAABe0Ke7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3X18VOWZ//HPSCDbKsEtJi4QdgXEC8Hark+UhaI/oFRqKmyrDT4gdKGtbdXaFFt9bYuKWKVFWXwo2qKiYAtoW6EUhI1WW9ZSrdYnSK8WCdsg1sSHptUuBpL8/jj3DJNkEmbITMjD9/165cWc+9znzDl5HSZz7nPd1xVrbGxEREREREREREQkE0cc7gMQEREREREREZGuR4NKIiIiIiIiIiKSMQ0qiYiIiIiIiIhIxjSoJCIiIiIiIiIiGdOgkoiIiIiIiIiIZEyDSiIiIiIiIiIikjENKomIiIiIiIiISMbyDvcB9ERmtgn4jbvPa9Y+FbgbKHb3/Rnu8/vAmcBw4D/cfXmWDle6sWxfi2Z2AvBd4N+AXsAzwBXu7tk7aumucnA9HgOsBUYQXY8VwFx3/5/sHbV0R7n4O520j5nAcuBz7r6svccq3VuOvjM2An8HGkPTKnefk43jle4tR9djL+B64D+AvsAO4P+5+1+yc9TSHeXgO+NHgY3Nmo8EznP3H7f3eLs7RSodHsuBGWYWa9Y+A3gww/8A8YHBF4AvAc9l5Qilp1hOdq/Fo4F1gAHHAk8T3dSLpGM52b0e3yH6kloI/COwEPhZ0uemSGuWk/2/05jZPwLXANuycZDSIywnB9ci8CF3Pyr8aEBJ0rWc7F+P1xM9jBwDFIR97W3/oUo3t5wsXovu/qukz8SjgBKi75GPZu2IuzF9sT48HgHuAj4K/BISXzRLgNFmdg6wABgG1AL3uPt1od9xQCUwB7gW2AWMd/c7w3p9CEsmsnotuvt4ooEkQp/FwDfNrL+7v9lB5yRdVy6uRw/rjwDqiQaXPgBUd9RJSZeU9b/TYb83AbcBn+mY05BuIFfXosihyOr1GKJKriQa5Pzf8B4vd9TJSJeW68/GmcDD7v5ujs+jW1Ck0mHg7v8HrAEuSWr+DPB7d38BeDesOxo4B/iimU1rtpszgROBj+f+iKW76oBrcTzwZw0oSTpydT2a2YtETz3XAcvcXQNK0qZcXItmdgZwGtGXYJG05PDv9C/N7M9m9pNwgyVyUDm4Hj8I7AfOC9fjH8zsyzk+DekGcnkPY2bvB84D7s/N0Xc/ilQ6fO4Hfm5ml4f/FJeENtz9iaR+L5rZj4gu+keS2q/TyKlkSU6uRTMrBu4EynJ14NItZf16dPeTzewfgH8H+uTy4KVbydq1GHKGfA+43N0bzKwjjl+6j2x/Lp4JbAXeT/Qkf72ZffhQ84RJj5PNz8ZioB9wAjCEKDfsY2b2B3f/75yfiXR1ubqf/jTwBvBkTo66G9Kg0mHi7lvMrAaYamZPA6cDnwIws9HAzcBJRDdA+cBDzXZR1YGHK91YLq5FMysENgPfc/cf5fDwpZvJ1Weju+8FfmRmFWb2fHiKJdKqLF+LXwJedPdf5/zApdvJ9ueiu/8yvKwzs68AfyV6Wv9Szk5Cuo0sX4//F/6dHwYFXjSzVcAnAA0qSZtyeD89E3jA3RtbWS/NaPrb4fUA0YjqDGCzu78e2n9INE1jsLv3IwqVb56ETBe5ZFPWrsUwn3kzsM7db8zpUUt3lcvPxt7A0Cweq3Rv2boWJwL/HqZ3/JkoKe0tZnZHTo9eupNcfi42pthGpC3Zuh5fTNEmkomsfjaa2WDgrLBfSZMilQ6vB4BvAicDX01q7wu85e57Qw6GC4lu0ltlZn2IBgljQO8w1aPO3RtycuTS3WTlWjSzAmAT8D/ufnUOj1e6t2xdjx8h+jv3NNALuIKoKuFvcnTc0v1k6+/0LOAfkpZ/AjwM3JPVo5XuLFufi6OIBtdfAt5HNP3tVaAiR8ct3VNWrkd3f8XMfgX8p5ldQfTQpxS4IGdHLt1N1u6ngxnAU+7+StaPtBtTpNJh5O67gKeAI4lGUuO+BMw3s78B84iSkB3MZqIQ0n8Dvh9eq8KHpCWL1+K/E4WeftbM3kn6+eccHLZ0U1m8HvOJ8nq9SXTT9AngHHffk+1jlu4pW9eiu//F3f8c/wHqgL+6e21ujly6myx+Lh4LrCaa8rYTOA4ocfd9WT5k6cayfA9zAfAvRH+rfw58y90fy+oBS7eV5WsRkvIySfpijY2KNhQRERERERERkcwoUklERERERERERDKmQSUREREREREREcmYBpVERERERERERCRjGlQSEREREREREZGM5R3uAxARERERERHp6szsbGAJ0AtY5u43N1ufDzwAnEpU8a40VDDDzK4BZgP1wBXuvqmtfZpZDFgAnB+2Werut+X6HEWa69SDSjU1f1NpOmlVYWHfWEe+n65HaUtHXo+6FqUtuhals9C1KJ2JrkfJtfr6egYOHMTixXdSVHQsc+ZcctPTT79w05AhQxN9ysq+wa23Lrzb3Y83s+nAQqDUzEYC04FRwECg3MxOCJvdCXwM2A08Y2br3H07MAsYDIxw9wYzK2p+TLoWpS3Z+lzU9DcRERERERGRdqio2EZx8WAGDSqmd+/eTJo0mS1bnmzSJyzfHxYfBiaGiKOpwCp3f8/dK4EdwBnhZ4e773T3OmBV6AvwRWC+uzcAuHt1jk9RJCUNKomIiIiIiIi0Q01NNUVFxyaWCwuLqKmpbtEHqAJw9/1ALdAfGBRvD3aHttbaAYYRRTn91sw2mtnwbJ6PSLo0qCQiIiIiIiLSDo0pJprFYrGD9gEagVTTkNpqB8gH9rr7acAPgHvTPVaRbNKgkoiIiIiIiEg7FBUVUV39emK5pqaaY44pbNGHKA8SZpYH9APeIopAGpzUtRjY00Y7Yd2Pw+ufAidn50xEMqNBJREREREREZF2GDFiJFVVVezZ8yr79u2jvHwzY8eOb9InLM8Mi+cBj7t7I7AOmG5m+WY2BBgOPA08Aww3syFm1ocomfe6sP0jwITw+kzgDzk8PZFWaVBJREREREREpB3y8vIoK7uKsrLLueii85gwYRJDhw5j2bK7Egm7S0qmAvQ3sx1AGXA1gLtvA9YA24FHgS+7e33Iu3QZsAmoANaEvgA3A582s5eAm4A5HXayIklija1M7OwMVAJR2tKRpWFB16O0TaWKpbPQtSidha5F6Ux0PUpnoWtROotsXYt52diJiIiIiIhIrmzd+hRLliyioaGBkpJpzJgxq8n6uro6Fiy4FvcKCgr6MX/+TQwYMBCAFSvu4+6779wB1ANXuPsmADM7G1gC9AKWufvNof0e4DSiJMl/AGa5+ztmlg88AJwKvAmUuvuunJ+8iEgnpulvIiIiIiLSadXX13PrrQtZtOg2Vq58iPLyTVRW7mzSZ/36tfTt25fVqx+htPRCli69HYDKyp2Ul28GGAWcDXzPzHqZWS/gTmAKMBK4wMxGht191d0/5O4nA38imn4EMBt4292PBxYDC3N64iIiXYAGlaRT2rr1KS644FOUlk5jxYrlLdbX1dVhZqvNbIeZ/cbMjouvM7NrQrub2ceT2u81s2ozezl5X2b2ATP7bzP7Y/j3H3N4aiIiIiKSgYqKbRQXD2bQoGJ69+7NpEmTEzlq4rZseZIpU0oAOOusiTz77NM0NjayZcuTTJo0GXd/z90rgR3AGeFnh7vvdPc6YBUwFcDd/wpgZjHgfRwo4T4VuD+8fhiYGPqIiPRYXXL62+m3/LLVdc98bXyr66RriD+NWrz4ToqKjmXOnEsYN248Q4YMTfRZv34thCdFZjad6ElRaXjCNJ3oadRAoNzMTnD3emA5cAdR2HKyq4HH3P1mM7s6LH8j3eNt7XrUtSgdTdeidBb6Oy2diT4bu76ammqKio5NLBcWFrF9+8ut9snLy+PII4+itraWmppqRo36YHLX3cCg8LqqWfvo+IKZ3Qd8gihx8tdC86D4Nu6+38xqgf7AG+mch65F6Sx0LUo2KVJJOp10n0aR+knRVGBViqdRuPsvgbdSvGXyU6f7gWnZPifp/NKJjps37xpKS6fxuc/N5LXX9iTWrVhxH61Ex50d2naEAct4+z1m9oKZvWhmD5vZUaE9v7UIPBERkZ4qVV2hWCyWRp/U7USRR6kijBK93f2zRA8oK4DS+C7b2kZEpCfSoJJ0OqmeRtXUVLfoQ9KTIiD+pCjxBClIfhrVmmPd/bWwr9eAovadgXQ1ytUgIiLSeRUVFVFd/XpiuaammmOOKWy1z/79+3n33XcoKOjXYlugGNhD9B1xcIr2hBDpvhr4dGhKbGNmeUA/Uj+wFBHpMTSoJJ3OoT6NIo2nTiKpKFeDiIhI5zVixEiqqqrYs+dV9u3bR3n5ZsaObTpNZ+zY8WzcuB6AJ554jFNOOZ1YLMbYseMpL98cjwYeAgwHngaeAYab2RAz60OUPmGdmcXM7HhI/J3+JPD78DbrgJnh9XnA4+6u75ki0qN1yZxK0r2l+zRq166dg4HdzZ4UHfSpUwqvm9kAd3/NzAYA1QfpL91Md8nVIN1fOiW1zWw1zcpdm9nHgJuBPkAdcJW7Pw5gZqcS5Zx7H7AB+Iq7N5rZB4ie0B8H7AI+4+5v5/4sRUSaysvLo6zsKsrKLqehoZ5zzjmXoUOHsWzZXYwYcSLjxp1JSclUbrhhHqWl0ygoKOC6674NwNChw5gwYRKvvPLH7cB+4MshAgkzuwzYBPQC7nX3bWZ2BHC/mRUQPax8AfhiOJR7gBVmtoPoe+f0jvw9iIh0RhpUkk4n+WlUYWER5eWbufbaBU36jB07nqef3joT+DVJT4rMbB3wQzO7lWgefPxpVFviT51uDv+uzfIpSSeXo1wNqSJBm+RqCFPkbifK1XAfirSTNrSniAHRwOQn3X2PmZ1EdBMVH/xcCnwe2Eo0qHQ2sJF2FjEQEcmmMWPGMWbMuCZtc+Zcmnidn5/PggWpZ43PnDmbuXOvHNa83d03EH3uJbc1AGNT7cfd9wLnZ3rsIiLdmaa/SaeT/DTqoovOY8KESYmnUfEpSSUlUwH6hydFZUQ3O7j7NmANUfTHozR9GvUjokEoM7PdZjY7vOXNwMfM7I9A/Gm+9CDK1SBdQXuKGLj779w9fv1tA/4hTAUZABS4+6/DFI4HOFCsQEUMRERERKRNilSSTimdp1HunvJJkbvfCNyYov2CVvq/CUxsz/FK15ZudNzGjes56aSTW+RquP76b3L33Xfm0zQ6LkbI1QC8ShQif2HIzzDM3Xe0kauhSQReB/wKpAtId5omB59C+Wngd+7+npkNIhrMjEuevtmkiIGZqYiBiIiIiDShSCUR6fHSjY6rra2ltHQaq1c/yKWXRgXb4rkaaBYdF6oSxnM1VABrQiRdjChXw0vAS8AAYH44lHtIEYEnAu0uYgCAmY0imhL3hfgu2uovIiIiItKWtCKVzOxsYAlRErtl7n5zs/X5RCHzzROD9icKvz8dWO7ul4X+7wceAoYB9cDP3F03TyJy2ChXg3R27SxigJkVAz8FLnH3V8Imu4mmZsYlT9NUEYMeIp0E8AsWXIt7BQUF/Zg//yYGDBgIwIoV97F+/VqOOOIIrrzyKkaPHpPY59y5VzjNvjuG6M1VwAeA54AZ7l7XxnfJi4Crkg7nZOAUd38+Z78QERERSdtBI5VCItk7gSnASOACMxvZrNtsQmJQYDHRU1CAvcC3gLkpdr3I3UcA/wqMNbMph3YKIiIi3V+6JbVJUe7azI4Gfg5c4+7/E+8fprf9zcw+EqZjXsKBYgXJpbNVxKCbiieAX7ToNlaufIjy8k1UVu5s0mf9+rX07duX1asfobT0QpYuvR2AysqdlJdvZsWKNdxyy+3ccsvN1NfXJ/ZJ6u+OC4HF7j4ceJvoOyS08l3S3R909w+7+4eBGcAuDSiJiIh0HulMfzsD2OHuO929jujp0tRmfZKTeSYnBn3X3bcQDS4luPvf3f0X4XUd0ZOq5CelIiIikqQ9RQyIpmIeD3zLzJ4PP/EcSV8ElgE7gFeIKr+Bihj0COkmgJ8ypQSAs86ayLPPPk1jYyNbtjzJpEmT6dOnDwMHDqK4eDAVFdsS+2z+3TEMXE4g+q4ITRPAp/wu2exwLwB+lO3fgYiIiBy6dKa/DSIk/Qx2A6Nb69NGYtCUwtPTTxJNrxMREZFWHGoRA3dfACxo3h7W/RY4KUW7ihj0AOkmgI/3ycvL48gjj6K2tpaammpGjfpgk21Dsvgm++TAd8f+wF9Czrl4ezwxfDrfJUtp+WBTREREDqN0IpXSSeJ5SIk+Q76HHwG3ufvOg/UXERERkew51ATwsVjr27aRML6t74ttfpc0s9HA39395RT9RERE5DBJZ1BpNzA4aTk5iWeLPs0Tgx7E94E/uvt/pdFXRERERLIo3QTw8T779+/n3XffoaCgX6vbNm/nwHfHN4Cjw3fF5HY4+HfJ6Wjqm4iISKeTzqDSM8BwMxtiZn2I/qiva9YnOZlnIjFoWzs1swVEXxiuzOyQRURERCQb0k0Av3HjegCeeOIxTjnldGKxGGPHjqe8fDN1dXXs2fMqVVVVnHjiqMQ+m393DN8Nf0H0XRGaJoBv9bukmR1BVBlzVe5+EyIiInIoDppTKcxrvwzYRFQW9l5332Zm84Hfuvs64B5gRUgM+hbRlwcAzGwXUAD0MbNpwGTgr8B/Ar8HnjMzgDvcfVkWz01ERERE2pCcAL6hoZ5zzjk3kQB+xIgTGTfuTEpKpnLDDfMoLZ1GQUEB1133bQCGDh3GhAmTuPji8+nVqxdlZV+nV69eAJSVXcVVV13Z5LtjeMtvAKvCw8XfEX2HhDa+SwLjgd1KlSAiItL5pJOoG3ffAGxo1jYv6fVeoidIqbY9rpXdppo7LyIiIiIdKJ0E8AsWLEy57cyZs5k5c3bKfbr7Cc3bw8DQGSna2/ou+QTwkbbOQURERA6PdKa/iYiIiIiIiIiINKFBJRERERERERERyZgGlUREREREREREJGMaVBIRERERERERkYxpUElERERERERERDKmQSUREREREREREcmYBpVERERERERERCRjGlQSEREREREREZGMaVBJREREREREREQypkElERERERERERHJmAaVREREREREREQkY3mH+wBEREREREREurqtW59iyZJFNDQ0UFIyjRkzZjVZX1dXh5mtBk4F3gRK3X0XgJldA8wG6oEr3H1TaD8bWAL0Apa5+82hfTlwJlAbdj/L3Z/P7RmKtKRBJREREREREZF2qK+v59ZbF7J48Z0UFR3LnDmXMG7ceIYMGZros379WoC33f14M5sOLARKzWwkMB0YBQwEys3shLDZncDHgN3AM2a2zt23h3VXufvDHXOGIqlp+puIiIiIiIhIO1RUbKO4eDCDBhXTu3dvJk2azJYtTzbpE5bvD4sPAxPNLAZMBVa5+3vuXgnsAM4IPzvcfae71wGrQl+RTkORSiIiIl1AOiH1CxZcy+OP//cOkkLqzaw/0RfX04Hl7n4ZgJn1BX6VtItiYKW7X2lms4DvAq+GdXe4+7Jcnp+IiEhXVlNTTVHRsYnlwsIitm9/uUUfoArA3febWS3QHxgEbE3quju0JfontY9OWr7RzOYBjwFXu/t7WTkZkQxoUElERKSTSzekvm/fvjQPqQf2At8CTgo/ALj734APx5fN7FngJ0lvuzo+ACUiIiJta2xs2RaLxQ7aB2gEYq20p5pZFN/LNcCfgT7A94FvAPPTO1qR7NH0NxERkU4u3ZD6KVNK4ouJkHp3f9fdtxANLqVkZsOBIppGLomIiEiaioqKqK5+PbFcU1PNMccUtugDDAYwszygH/AWUQTS4KSuxcCeNtpx99fcvTFEJ91HNFVOpMNpUElERKSTSxVSH0LoU/Zx9/1E1WD6p/kWFxBFJiU/Q/20mb1oZg+b2eDWNhQREREYMWIkVVVV7NnzKvv27aO8fDNjx45v0icszwyL5wGPh7+964DpZpZvZkOA4cDTwDPAcDMbYmZ9iJJ5rwMwswHh3xgwDWg6106kg2j6m4iISCfXzpD6dEwHZiQt/wz4kbu/Z2aXEiUVnZDmvkREsi7dvHLuFRQU9GP+/JsYMGAgACtW3Mfdd9+5g/RLtT8InAbsI7qx/4K77zOzs4C1QGV425+4u6YbCQB5eXmUlV1FWdnlNDTUc8455zJ06DCWLbuLESNOZNy4Mykpmcrixd/pb2Y7iCKUpgO4+zYzWwNsB/YDX3b3egAzuwzYRHSd3uvu28JbPmhmhURT554HLu3YMxaJaFBJRESkk0s3pL66+nVGjTq+eUh9m8zsQ0Ceuz8bb3P3N5O6/IAoP5OIyGGRSV651asfobx8E0uX3s78+TdRWbmT8vLNkFmp9geBi0OfHwJzgKVh+VfunphrLJJszJhxjBkzrknbnDkHxnry8/Nx9/NTbevuNwI3pmjfAGxI0a6HPdIpaPqbiIhIJ5duSP3Gjevji8kh9QdzAfCj5IZ4SH1wLlBx6EcvItI+meaVO+usiTz77NM0NjayZcuTTJo0mUxKtbv7hpCrppEoUqm4485WRKRrUaSSiAgKq5fOLd2Q+htumEfzkHoAM9sFFAB9zGwaMDk8jQf4DPCJZm95hZmdSxSC/xYwK7dnKCLSunRLtcf75OXlceSRR1FbW0tNTTWjRn0wuWu6pdoxs95EU4O/ktQ8xsxeIEqWPDdpKpKISI+kQSUR6fEUVi9dQToh9QsWLKSwsO/xzbd19+Na26+7D03Rdg1RqWIRkcPuUPPKxWJt5ptrq1R73PeAX7p7vDLmc8C/uPs7ZvYJ4BGihMoiIj2WBpVEpMdLDqsHEmH1yYNKW7Y8yX/8x+eBKKx+8eLvNAmr37Bh/XtAZYgSiZd03eHuOwHMLB5Wvz3MjSe0K6xeRA6r9kZqrl+/liOOOIIrr7yK0aPHJPY5d+4VTstIzSFE04w+QHSDPsPd68wsH3gAOBV4Eyh1911hm5OBu4mi7RqA0919b05/KdKpZJJXrqjoWPbv38+7775DQUG/FtuSVJKdVkq1A5jZtUAh8IV4m7v/Nen1BjP7npkd4+5vtP8sRUS6JuVUEpEeL9Ny7c3D6pO35UBY/SBahtUPSu6YFFb/aFLzGDN7wcw2mtmodp+ciEgb4pGaixbdxsqVD1FevonKyp1N+iRHapaWXsjSpbcDJCI1V6xYwy233M4tt9xMfX19Yp/AFGAkcIGZjQy7WwgsdvfhwNvA7NA+G3jb3Y8HFod+8aTzK4FL3X0UcBbR1GHpQTLNK/fEE49xyimnE4vFGDt2POXlm8mwVPsc4OPABe7eEH8PM/unUL4dMzuD6F4qubCBiEiPo0ElEenxchRWH2ulPVlrYfUfAm4nCqsXEcmZbCRA7tOnDwMHDqK4eDAVFdsS+2yeADncjE8AHg67vh+YFl5PDcuE9RND/8nAi+7+AkSVCeNltqXnSM4rd9FF5zFhwqREXrn49VpSMpXa2lpKS6exevWDXHrpZQAMHTqMCRMmQVSq/VFCqXZ33w/ES7VXAGuS8iPdBRwL/NrMnjezeaH9PODlkFPpNmB6mgURRES6LU1/E5EeT2H1ItJTZTMBcnKUZ4oIztFAf+Av4WY+3h6P4ExEd7r7fjOrDf1PABrNbBPRZ+Yqd/9OFk5duph088qlMnPmbObOvXJY8/Y2SrWnvEdy9zuAOzI6cBGRbk6RSiLS4ymsXkR6qmxHasZisUON4GxtXR4wDrgo/PvvZjYx5TuIiIhIh1OkknRK6SQNNbPVpE7oeQ1RboZ0y7tPBL5LdAP/DjDL3Xfk/iyls8ikXHtp6TQKCgq47rpvAwfC6l955Y/bicqvfzk+NcPM4mH1vYB7m4XV/y9RWD3AT9x9PlFY/RfNbD/wfyisXkRyLJuRmsnbthLB+QZwtJnlhWil5AjO3UTRnbtDHqV+wFuh/cl4xKaZbQBOAR7L1u9AREREDl1ag0qt3YwnrU9ZscPM+hPNiz8dWO7ulyVtcyqwHHgfUdjpV3TzJJB+eXdCQk8zm06U0LM0JAKdTmbl3ZcCU929wsy+BHwTmNUxZyudhcLqRaQnSo7ULCwsorx8M9deu6BJn3ik5kknndwiUvP6679JaelFvPFGDVVVVZx44igaGxupqqqKV3p7lejv8oXu3mhmvyAaQF8FzATWhrdZF5Z/HdY/HvpvAr5uZu8H6oAziRJ5i4iISCdw0OlvZtaL6GY8VQWPuJQVO4C9wLeAuSl2vRT4PNFUkeHA2YdyAtL9pJs0lNQJPacS5Vt4z90rgXh59zMI5d2Tk4aG7RuJyhRD9GQ0kfdGRESkO8tGAuSLLz6fr33tcsrKvk6vXr0S+yR1AuRvAGVmtoMoZ9I9of0eoH9oLwOuBnD3t4FbiaYUPw885+4/z/1vRkRERNKRTqRS4mYcwMziN+Pbk/pMBa4Lrx8G7jCzmLu/C2wxs+OTd2hmA4ACd/91WH6AqPrHxnaci3QT6SYNJXVCz0HA1qSuyUlAm5d3Hx1ezwE2mNn/AX8FPpKtcxEREens2hupOXPm7JT7dPcTmreH75NnpGjfC5yf6j3cfSWwss2TEBERkcMinUTdiWocQfJNeos+YY58/Aa/rX3uPsg+pYc61KShtJ0EtK3koF8FPuHuxcB9RE9ERURERERERKQN6QwqtXUznkmf9vSXHiTdpKGEcu0pEnqmKuOest3MCoEPuftvQvtq4N+yeDoiIiIiIiIi3VI6g0qt3aSn7NPsBr+tfRYfZJ/SQ6Vb3p0ooSckJfQkSvQ5PYPy7m8D/ZKSeX+MKP+DiIiIiIiIiLQhnUGl1m7Gk8UrdkDTG/yU3P014G9m9pGQXPkSDlT/kB4u3aShpE7ouQ1YQ5Tz61FCefcwLTNe3j2RNDS0fw74sZm9AMwArurQExYRERERERHpgg6aqDskQY7fjPcC7nX3bWY2H/itu68jqtixItzgv0U08ASAme0iqqzVx8ymAZNDGfcvAsuB9xEl6FaSbklIJ2mou7eW0PNG4MYU7a2Vd/8p8NN2HrIECoEbAAAgAElEQVSIiIiIiIhIj5JO9beUN+PuPi/pdVsVO45rpf23wEnpHqiIiIiIiIiIiHQe6Ux/ExERERERERERaUKDSiIiIiIiIiIikjENKomIiIiIiIiISMY0qCQiIiIiIiIiIhnToJKIiIiIiIiIiGQsrepvIiIicvht3foUS5YsoqGhgZKSacyYMavJ+rq6OsxsNXAq8CZQ6u67zKw/8DBwOrDc3S+Lb2NmTwADgP8LTZPdvdrM8oEHmu8rpycoIiIiIl2KIpVERES6gPr6em69dSGLFt3GypUPUV6+icrKnU36rF+/FuBtdz8eWAwsDKv2At8C5ray+4vc/cPhpzq0zW5lXyIiIiIigAaVREREuoSKim0UFw9m0KBievfuzaRJk9my5ckmfcLy/WHxYWCimcXc/V1330I0uJSuqan21b6zEBEREZHuRINKIiIiXUBNTTVFRccmlgsLi6ipqW7RB6gCcPf9QC3QP43d32dmz5vZt5IGjgYd4r5EREREpIfQoJKIiEgX0NjYsi0Wix20D5C69YCL3P2DwEfDz4z47g9hXyIiIiLSg2hQSUREpAsoKiqiuvr1xHJNTTXHHFPYog8wGMDM8oB+wFtt7dfdXw3//g34IXBGWLU7032JiIiISM+iQSUREZEuYMSIkVRVVbFnz6vs27eP8vLNjB07vkmfsDwzLJ4HPO7urUYXmVmemR0TXvcGSoCXw+p1mexLRERERHqevMN9ACIiInJweXl5lJVdRVnZ5TQ01HPOOecydOgwli27ixEjTmTcuDMpKZnK4sXf6W9mO4iiiqbHtzezXUAB0MfMpgGTgf8FNoUBpV5AOfCDsMk9wIpU+xIRERERAQ0qiYiIdBljxoxjzJhxTdrmzLk08To/Px93Pz/Vtu5+XCu7PbWV/nuBlPsSEREREQENKomIiIiIiIi029atT7FkySIaGhooKZnGjBmzmqyvq6vDzFYTPdB5Eyh1910AZnYNMBuoB65w902h/WxgCVFE8TJ3vzl5n2Z2O/BZdz8qpycn0grlVBIRERERERFph/r6em69dSGLFt3GypUPUV6+icrKnU36rF+/FuBtdz8eWAwsBDCzkUTTzEcBZwPfM7NeZtYLuBOYAowELgh9CdudBhyd+7MTaZ0GlURERERERETaoaJiG8XFgxk0qJjevXszadJktmx5skmfsHx/WHwYmGhmMWAqsMrd33P3SmAHUTXWM4Ad7r7T3euAVaEvYcDpu8DXO+D0RFql6W8iIiIiPVg60zUWLLgW9woKCvoxf/5NDBgwEIAVK+5j/fq1HHHEEVx55VWMHj0msc+5c69wmk3XMLMhRDdFHwCeA2a4e52Z5QMP0GxKiJkdB1QAHj9cdz+QSExEpJOoqammqOjYxHJhYRHbt7/cog9QBeDu+82sFugPDAK2JnXdHdoS/ZPaR4fXlwHr3P01M8veiYhkSJFKIiIiIj1UutM1+vbty+rVj1BaeiFLl94OQGXlTsrLN7NixRpuueV2brnlZurr6xP7JPV0jYXAYncfDrxNlD+E8G+LKSHBK+7+4fCjASUR6ZQaG1u2xWKxg/YBGoFYJu1mNpComMbtmR2lSPZpUElERESkh0p3usaUKSUAnHXWRJ599mkaGxvZsuVJJk2aTJ8+fRg4cBDFxYOpqNiW2Gfz6RphiscEoikfEE0BmRZeTyX1lBARIIp+u+CCT1FaOo0VK5a3WF9XV8e8eddQWjqNz31uJq+9tiexbsWK+zCzHWbmZvbxeLuZnR3adpjZ1UntD4b2l83sXjPrHdpjZnZb6P+imZ2S05OWLqWoqIjq6tcTyzU11RxzTGGLPsBgADPLA/oBbxFFIA1O6loM7Gmj/V+B44EdZrYLeL+Z7cjm+YikS4NKIiIiIj1UqukaYXpGyj55eXkceeRR1NbWtrpt83YOTOPoD/zF3fc3ayf8m5gSAsSnhAAMMbPfmdmTZvbRbJy3dC3ZiKgjswTIDwIjgA8C7wPmhPYpwPDw83lgae7OWrqaESNGUlVVxZ49r7Jv3z7Kyzczduz4Jn3C8syweB7wuLs3AuuA6WaWH6YJDweeBp4BhpvZEDPrQ5TMe527/9zd/8ndj3P344C/h0hPkQ6nQSURERGRHupQp2vEYq1vewjTO2hj3WvAP7v7vwJlwA/NrCDlO0i3lY2IukwSILv7BndvDDf7TxNFhxDWPxDWbQWONrMBHfArkC4gLy+PsrKrKCu7nIsuOo8JEyYxdOgwli27K3G9lpRMBegfoorKgKsB3H0bsAbYDjwKfNnd68Mg+2XAJqL8cmtCX5FOQ4m6RURof6Lau+++cwdQD1zh7psgCqsHltAyUe2DwGnAPqIvq19w931hqscS4BPA34FZ7v5c7s9eRHqqdKdrVFe/TlHRsezfv593332HgoJ+bW6b3M6B6RpvEN2E54UbpXg7HJjisTt5Ski4qX8PwN2fNbNXgBOA32btlyCdXroJkFuLqBs16oPJXdNJgAxAmPY2A/hKaBqUYptBRIOfIowZM44xY8Y1aZsz50AquPz8fNz9/FTbuvuNwI0p2jcAG9p6X3c/6lCOVyQbFKkkIj2ewupFpKdKd7rGxo3rAXjiicc45ZTTicVijB07nvLyzdTV1bFnz6tUVVVx4omjEvtMMV2jEfgF0ZQPiKaArA2v15FiSoiZFYbPU8xsKNHnY9MPaOn2sh1Rx8Ej5+K+B/zS3X8V32Ua24iI9CgaVBKRHk9h9SLSU6U7XaO2tpbS0mmsXv0gl156GQBDhw5jwoRJXHzx+Xzta5dTVvZ1evXqldgnqadrfAMoC1M/+gP3hPZ7SDElBBgPvGhmLxAl8L7U3d/K9e9FOpdMIuqANiPqOHgCZADM7FqgkOh6jGtzGxGRnkjT30Skx1NYvYj0ZOlM11iwYGHKbWfOnM3MmbNT7tPdT2je7u47iQbdm7fvJSqP3bz9x8CPD3oS0q0lR9QVFhZRXr6Za69d0KRPPKLupJNObhFRd/313+Tuu+/MBwZyIAFyjJAAGXiVKKLuQgAzmwN8HJjo7g1Jb7MOuMzMVhH9Ta91d/2NFpEeTZFKItLjKaxeRESk88pGRB2ZJUC+CzgW+LWZPW9m80L7BqLplzuAHwBf6ojzFxHpzBSpJCI9XjYT1dI0FD6dsPovJPVRWL2IiEgK7Y2omzv3ymHN21tLgOzuKe+RwrT1L2d04CIi3Vxag0qtVTBKWp8PPACcCrwJlLr7rrDuGmA2LasifZUoOW0j8BLw2RD6LCLSoRRWLyIiIiIikrmDTn87SAWjuNnA2+5+PLAYWBi2HUl0I9W8KtIg4ArgNHc/iWiwanp2TklEJDMKqxcREREREclcOpFKiQpGAOEJ+lSiG6i4qcB14fXDwB1mFgvtq9z9PaAyVPQ4A/hTeO/3mdk+4P1oioeIHEYKqxcREREREclMOom6W6tGlLJPeDpfS1QmNuW27v4qsIhocOk1oikemw/lBEREREREREREpOOlM6iUTjWi1vqkbDezfySKYhpClIPkSDO7OI1jERERERERERGRTiCd6W/pVCOK99ltZnlAP+CtNradBFS6ew2Amf0E+Ddg5SGcg4iISLe3detTLFmyiIaGBkpKpjFjxqwm6+vq6liw4Foef/y/d5BUNMPM+hNNTT8dWO7ulwGY2fuBh4BhRMU0fubuV4d1s4DvEiWZB7jD3Zfl/CRFREREpEtJJ1LpGUIFIzPrQ5RQe12zPuuAmeH1ecDjITfIOmC6meWHCkjxqkh/Aj5iZu8PuZcmEiWyFRERkWbq6+u59daFLFp0GytXPkR5+SYqK3c26bN+/Vr69u1L86IZwF7gW8DcFLte5O4jgH8FxprZlKR1q939w+FHA0oiIiIi0sJBB5Vaq2BkZvPN7NzQ7R6gf0jEXQZcHbbdBqyhZVWk3xA9NX0OeCkcx/ezemYiIiLdREXFNoqLBzNoUDG9e/dm0qTJicqEcVu2PMmUKSXxxYeBiWYWc/d33X0L0eBSgrv/3d1/EV7XEf1NLs75yYiIiIhIt5HO9LeUFYzcfV7S673A+a1seyNwY4r2a4FrMzlY6TnSmeZhZquBU0ma5gFgZtcAs4mmc1zh7ptC+9nAEqAXsMzdbw7tMWAB0TVcDyx199tyf5YiIumpqammqOjYxHJhYRHbt7/cah93329m8aIZbxxs/2Z2NPBJos/IuE+b2XjgD8BX3b0q5cYiIiIi0mOlM/1NpEOlO80DeLv5NA8zG0k0RXMUcDbwPTPrZWa9gDuBKcBI4ILQF2AWUe6vEe5+IrAq1+coIpKJxublMYBYLHbQPrQsrNFCyIX4I+A2d49/2P4MOM7dTwbKgfszOV4RERER6Rk0qCSdTrrTPDhwk5OY5kFUVXCVu7/n7pXADuCM8LPD3XeGaR6rQl+ALwLz3b0BwN2rc3yKIiIZKSoqorr69cRyTU01xxxT2GqfZkUzDub7wB/d/b/iDe7+pru/FxZ/QBQVKiIiIiLShAaVpNNJNc2jpqa6RR+gChJ5v+LTPAbF24Pdoa21dogqH5Wa2W/NbKOZDc/m+YiItNeIESOpqqpiz55X2bdvH+Xlmxk7dnyTPmPHjmfjxvXxxeSiGa0yswVEg09XNmsfkLR4LiqmISIiIiIppJVTSaQjtXOaR6yV9lQDqPG95AN73f00M/sUcC/w0XSPV0Qk1/Ly8igru4qysstpaKjnnHPOZejQYSxbdhcjRpzIuHFnUlIylRtumEcomvEW0VRgAMxsF1AA9DGzacBk4K/AfwK/B54zM4A7QqW3K0Ixjv1hX7M67mxFREREpKvQoJJ0OulO89i1a+dgYHezaR67ifIjxRUDe8Lr1tp3Az8Or38K3JedMxERyZ4xY8YxZsy4Jm1z5lyaeJ2fn8+CBQspLOx7fPNt3f24VnabaiAed78GuOaQD1ZEREREegRNf5NOJ91pHsDMsJg8zWMdMN3M8s1sCDAceBp4BhhuZkPMrA/RE/x1YftHgAnh9ZlElY5EREREREREpA0aVJJOJ3max0UXnceECZMS0zziCbtLSqYC9A/TPMqAqwHcfRuwBtgOPAp82d3rQ96ly4BNRLlB1oS+ADcTlc5+CbgJmNNhJysiIiIiIiLSRWn6m3RK6UzzcPfzU23r7jcCN6Zo3wBsSNH+F+Ccdh6yiIiIiIiISI+iSCUREREREREREcmYBpVERERERERERCRjGlQSEREREREREZGMaVBJREREREREREQypkTdIiIiIj3c1q1PsWTJIhoaGigpmcaMGbOarK+rq2PBgmtxr6CgoB/z59/EgAEDAVix4j7Wr1/LEUccwZVXXsXo0WMAMLOzgSVAL2CZu98c2ocAq4APAM8BM9y9zszygQeAU4E3gVJ33xU/BjP7Z6Lqrte5+6Lc/TZEREQkXYpUEhEREenB6uvrufXWhSxadBsrVz5EefkmKit3Numzfv1a+vbty+rVj1BaeiFLl94OQGXlTsrLN7NixRpuueV2brnlZurr66mvrwe4E5gCjAQuMLORYXcLgcXuPhx4G5gd2mcDb7v78cDi0C/ZYmBj1n8BIiIicsg0qCQiIiLSg1VUbKO4eDCDBhXTu3dvJk2azJYtTzbps2XLk0yZUgLAWWdN5Nlnn6axsZEtW55k0qTJ9OnTh4EDB1FcPJiKim1UVGwD2OHuO929jigyaaqZxYAJwMNh1/cD08LrqWGZsH5i6I+ZTQN2Atty9XsQERGRzGlQSURERKQHq6mppqjo2MRyYWERNTXVrfbJy8vjyCOPora2ttVtw/ZVSbvYDQwC+gN/cff9zdoJ/1YBhPW1QH8zOxL4BnB9ds5YREREskWDSiIiIiI9WGNjy7ZYLJZGn9a3TdUONAKxVtppY931RNPl3km5VxERETlslKhbREREpAcrKiqiuvr1xHJNTTXHHFOYsk9R0bHs37+fd999h4KCfgfbdnDSLoqBPcAbwNFmlheikeLtEEUtDQZ2m1ke0A94CxgNnGdm3wGOBhrMbK+735Gt34GISDakU/TAzFaToiCBmV1DlFuuHrjC3TeF9taKHtwDnEY0IP8HYJYG3+VwUKSSiIiISA82YsRIqqqq2LPnVfbt20d5+WbGjh3fpM/YsePZuHE9AE888RinnHI6sViMsWPHU16+mbq6OvbseZWqqipOPHEUI0aMBBhuZkPMrA8wHVjn7o3AL4Dzwq5nAmvD63VhmbD+cXdvdPePuvtx7n4c8F/AtzWgJCKdTbpFD0hRkCAUMpgOjALOBr5nZr3MrBetFz34qrt/yN1PBv4EXJb7sxRpSZFKIiIiIj1YXl4eZWVXUVZ2OQ0N9ZxzzrkMHTqMZcvuYsSIExk37kxKSqZyww3zKC2dRkFBAddd920Ahg4dxoQJk7j44vPp1asXZWVfp1evXvFdXwZsInq6fq+7x5NsfwNYZWYLgN8B94T2e4AVZraDKEJpesf8BkRE2i+56AGQKHowZMjQRJ9QBCG5IMEdoSDBVGCVu78HVIbPwTNCvx3uvhPAzFaFvtvd/a+hLQa8jwNTiUU6lAaVRERERHq4MWPGMWbMuCZtc+Zcmnidn5/PggULU247c+ZsZs6c3aLd3TcAG1K07+TAzVJy+17g/LaO092va2u9iMjhkqpwwfbtL7foQ1JBAjOrJSpgMAjYmtQ1uYhB86IHo+MLZnYf8AlgO/C1LJ2KSEY0/U1ERERERESkHQ616AFtFzFoq7gB7v5ZYCBQAZSmeagiWaVBJRERERER6dS2bn2KCy74FKWl01ixYnmL9XV1dcybdw2lpdP43Odm8tprexLrVqy4DzPbYWZuZh+Pt5vZ2aFth5ldndR+WWhrNLNjktrPMrNaM3s+/MzL2QlLl5Nu0QNCEYNmBQnihQri4kUMWmtPcPd6YDXw6eyciUhmNKgkIiIiIiKdVroJkPv27cvq1Y9QWnohS5feDkBl5U7KyzdDZgmQ/weYBPxvisP5lbt/OPzMz8X5SteUbtEDUhQkICpUMN3M8s1sCDAceBp4hhRFD8wsZmbHQyKn0ieB33fAaYq0oEElERH0BFRERKSzSk6A3Lt370QC5GRbtjzJlCklAJx11kSeffZpGhsb2bLlSSZNmoy7v+fulUA8AfIZhATI7l4HxBMg4+6/i5d5F0lXctGDiy46jwkTJiWKHsSv15KSqQD9QyLuMuBqgFDIYA1RbqRHgS+7e7277+dA0YMKYE3oGwPuN7OXgJeAAYAGOeWwUKJuEenx4k9AFy++k6KiY5kz5xLGjRvfpFpH8hPQ8vJNLF16O/Pn39T8CehAoNzMTgib3Ql8jCh0+RkzW+fu24megK4HnkhxOL9y95Lcna10ZVu3PsWSJYtoaGigpGQaM2bMarK+rq4OM1sNnAq8CZS6+y4z609UZeZ0YLm7J8oOm9mpwHKiyjEbgK+4e6OZfYAonP44YBfwGXd/O8enKCLSQroJkON98vLyOPLIo6itraWmpppRoz6Y3DWtBMhtGGNmLxBNQZqbVNVQJK2iB+6esiCBu98I3JiivUXRA3dvAMZm4ZBF2k2RSiLS4+kJqHQF6U7/AN529+OBxUC8XNde4FvA3BS7Xgp8nijUfjjR9BCInp4+5u7DgcfCsohIhzvUBMix2CElRm7Lc8C/uPuHgNuBRw7SX0Sk29Ogkoj0eKmegIaSryn7NH8CmrwtB56ADqLlE9BBHNwYM3vBzDaa2ahDOiHpltId/ATuD4sPAxPNLObu77r7FqLBpQQzGwAUuPuvQ06HB4BpYfXUpH3dn9QuItKh0k2AHO+zf/9+3n33HQoK+rXYlgwSIDfn7n9193fC6w1A7+Rp7CIiPVFag0qt5QVJWp9vZqvD+t+Y2XFJ665pJdfI0Wb2sJn93swqzGxMVs5IRCRDegIqXUG6g5+EwcyQh6EW6N/GbgcR3VjFJQ9+Huvur4V9vQYUte8MREQOTboJkDduXA/AE088ximnnE4sFmPs2PGUl2+O368cNAFyW8dhZv8UkiJjZmcQ3Uu9me3zFRHpSg46qHSQyghxs0kRbh/6TadZtYWwzRLgUXcfAXyIKPGYiEiH0xNQ6QoOdfCTtgczD2XwU0SkQ6WbALm2tpbS0mmsXv0gl14apY4bOnQYEyZMgvQTIGNmV5jZbqK/3S+a2bJwKOcBL4ecSrcB00OUp4hIj5VOou5EXhAAM4vnBdme1GcqcF14/TBwRxjFnwqscvf3gMqQ5f4MM9sGjAdmAYR8I3XtPhsRkUOQ/AS0sLCI8vLNXHvtgiZ94k9ATzrp5BZPQK+//pvcffed+USJuuNPQGOEJ6DAq0QD7Be2dRxm9k/A6yFJsp6AShPpDn7u2rVzMLDbzPKAfsBbbew2ftMUlzz4+bqZDXD318I0ueoWW4uIdJB0EiAvWLCw+WYAzJw5m7lzrxzWvD1VAuTQfhvRoFHz9juAOzI9dhGR7iyd6W/p5AVJ9GkWbt/atkOBGuA+M/udmS0zsyMP6QxERNpJT0ClK0h3+gcwMyyeBzze1jUUprX9zcw+Eh4GXQKsDavXJe1rZlK7iIiIiAiQXqRSOqHxrfVprT0POAW43N1/Y2ZLiKrKfCuN4xERyTo9AZXOLnnws6GhnnPOOTcx+DlixImMG3cmJSVTWbz4O/1DZPBbRBFyAJjZLqAA6GNm04DJ7r4d+CKwHHgfsDH8ANwMrDGz2cCfgJQlkEVERESk50pnUCmdvCDxPs3D7Vvbdjew291/E9ofRqWKRURE2pTO4Ke7pxz8cffjWmn/LXBSivY3gYntOFwRERER6ebSmf6WTmWE5BD55HD7dcD05tUW3P3PQJWZWdhmIk1zNImIiIiIiIiISCd20EGl1vKCmNl8Mzs3dLsHiIfblxGijkL+kDU0yzUStrkceNDMXgQ+DHw7e6clIiIiIiIiIiK5lM70t5R5Qdx9XtLrvbSSa8HdbwRuTNH+PHBaJgcrIiIiIiIiIiKdQzrT30RERERERERERJrQoJKIiIiIiIiIiGRMg0oiIiIiIiIiIpIxDSqJiIiIiIiIiEjGNKgkIiIiIiIiIiIZ06CSiIiIiIiIiIhkLO9wH4CIiIiIHF5btz7FkiWLaGhooKRkGjNmzGqyvq6ujgULrsW9goKCfsyffxMDBgwEYMWK+1i/fi1HHHEEV155FaNHjwHAzM4GlgC9gGXufnNoHwKsAj4APAfMcPc6M8sHHgBOBd4ESt19l5mdAXw/HEoMuM7df5rL34eIiIikR5FKIiIiIj1YfX09t966kEWLbmPlyocoL99EZeXOJn3Wr19L3//P3v2H2VXVh/5/j0mIFgkoZCgkuSVA+oGArUUB+SZfpCEiSEpoLzZBjKESrS2I3AgKfSpQCBV6gRgsoi1QIFATpFZyIxgaFWyqCKLWGtLPbUy4NyF8SfhhqlgJmcz3j73PeDI5k5yTmTlzZub9ep55cvbaa++91s46+8c668d++7F06VeYNet93HbbZwFYv34dK1c+wuLF93PTTZ/lppuup6Ojg46ODoBbgTOAycC5ETG53N0NwMLMnAS8DFxQhl8AvJyZRwILy3gAPwbenplvBU4HvhAR/jAqSVILsFJJkiRpGFuzZjXjx09g3LjxjBo1iunTT2PVqsd2irNq1WOcccYMAE455VSeeuoJOjs7WbXqMaZPP4199tmHQw8dx/jxE1izZjVr1qwGWJuZ6zJzG0XLpJkR0QZMAx4od303cHb5eWa5TLn+1Ihoy8xfZOb2Mvz1QGf/nAlJktQof+VRS6qnGX5ELKVbE3mAiLiC4tfODuDizFxRhtdshl8REZ8F/igz39ivmZMkqYVs2bKZ9vaDu5bHjm3n6ad/3GOckSNHsu++b2Tr1q1s2bKZY455y07bbtmyubK4oWoXG4ETgQOBn1ZVEm0ExpWfx1W2ycztEbG1jP9CRJwI3An8BkV3ue1IkqQBZ0sltZx6m+FTo4l82bR+NnAMRRP5z0XEiIgYQc/N8ImItwMH9H/uJElqLZ012v20tbXVEafnbWuFU7QwaushnN2ty8zvZuYxwPHAFRHx+ppHkCRJTWWlklpOvc3wqdFEnqLp/JLMfDUz1wNrgRPKv12a4QOUFU7/E/hEE7InSVJLaW9vZ/Pm57uWt2zZzEEHje0xzvbt23nllZ8zZsz+PW7b3t4OMKFqF+OBTcALwAFVYyJVwqFotTQBoFy/P/BSdToycw3wCnBsb/IsSZL6hpVKajm1muFXNaXvikNVE3mg0kS+q+l8qdKsvqdwgIuAZZn5XF/mQ5KkweCooyazYcMGNm16ltdee42VKx9hypSTd4ozZcrJPPzwcgAeffTrHHfc8bS1tTFlysmsXPkI27ZtY9OmZ9mwYQNHH30MRx01GWBSREyMiH0oWhEvy8xO4JvAOeWu5wIPlp+XlcuU67+RmZ3lPkYCRMRvAAE800+nQ5IkNcAxldRy9rYZPrtvVl+rArUzIg4F3guc0lAiJUkaIkaOHMn8+Zcxf/5H2bGjgzPPPIvDDz+C22//PEcddTRTp76TGTNmcu21VzJr1tmMGTOGq6/+SwAOP/wIpk2bzvvf/15GjBjB/PmfYMSIEZVdXwSsoBjL8M7MXF2GfxJYEhELgB8Ad5ThdwCLI2ItRQul2WX4VODyiHgN2AH8aWa+0L9nRZIk1cNKJbWcepvhP/PMugnAxm5N5Luazpeqm9XXCv8d4EhgbUQA/FpErC3HapIkaVg46aSpnHTS1J3C5s37SNfn0aNHs2DBDTW3nTv3AubOvWCX8Mx8CHioRvg6im7p3cN/SfFDT/fwxcDiPeVBkiQ1n93f1HLqbYZPjSbyFE3nZ0fE6IiYCEwCngCepHYz/K9m5q9n5mGZeRjwCyuUJEmSJEnaMyuV1HKqm+Gfd945TJs2vasZfmXA7hkzZgIcWDaRn1/SN5kAACAASURBVA9cDlA2rb8feBr4GnBhZnaU4y5VmuGvAe6vaoYvSZIkSZIaZPc3taR6muFn5i5N5AEy8zrguhrhNZvhd4vzxr1JryQ1w+OPf5tFi25kx44dzJhxNnPmnL/T+m3bthERS4G3AS8CszLzGYCIuAK4AOgALs7MFVH0+11atYvDgSsz8zMRcTXwIWBLue7PyuuoJEmSBFipJEnSoNDR0cHNN9/AwoW30t5+MPPmfYCpU09m4sTDu+IsX/4gwMuZeWREzAZuAGZFxGSKbr/HAIcCKyPiNzMzgbcCRMQI4FngH6sOuzAzb2xKBiVJkjTo2P1NkqRBYM2a1YwfP4Fx48YzatQopk8/ratLcEW5fHe5+ABwakS0ATOBJZn5amauB9ay60DJpwI/ycz/068ZkSRJ0pBhpZIkSYPAli2baW8/uGt57Nh2tmzZvEscYANAOZbcVuBAYFwlvLSxDKs2G/hit7CLIuJHEXFnRLypD7IhSZKkIcTub5IkDQKdnbuGtbW17TEO0Am09RAOQDkr5lnAFVXrbwOuLeNdC9wEfLCRNEuSNJz09diHZfjpwCJgBHB7Zl5fht8HvB14jWK26z/OzNf6P5fSzmypJEnSINDe3s7mzc93LW/ZspmDDhq7SxxgAkBEjAT2B16iaJk0oSrqeGBT1fIZwPczs+sAmfl8OXvmDuBv2bW7nCRJKlXGPrzxxlu4994vsXLlCtavX7dTnOqxD4GFFGMf0m3sw9OBz0XEiHK8w1sp7tOTgXPLuAD3AUcBbwHeAMzr7zxKtVipJEnSIHDUUZPZsGEDmzY9y2uvvcbKlY8wZcrJO8Upl+eWi+cA38jMTmAZMDsiRkfERGASxa+aFefSretbRBxStfj7wI/7NEOSJA0h/TT24QnA2sxcl5nbgCVlXDLzoczsLO/zT1D8YCQ1nd3fJEkaBEaOHMn8+Zcxf/5H2bGjgzPPPIvDDz+C22//PEcddTRTp76TGTNmsnDhXx0YEWspWijNBsjM1RFxP/A0sB24MDM7ACLi14B3AX/c7ZB/FRFvpej+9kyN9ZLUNPV0K1qw4Coy1zBmzP5cc82nOeSQQwFYvPjv+MIXbl1L/d2KLgIuAY4AxmbmC2V4Wxn/PcAvgPMz8/v9nnkNCrXGPnz66R/vEoeqsQ8jonrsw8erolaPfdh9TMQTq/cZEaOAOcDH+iIfUqOsVJIkfFjV4HDSSVM56aSpO4XNm/eRrs+jR48mM99ba9vMvA64rkb4LygeaLuHz+lteiWpL1S6FS1ceCvt7Qczb94HmDr1ZCZOPLwrzvLlD7LffvuxdOlXWLlyBbfd9lmuuebTrF+/jpUrH4GiW9GhwMqI+M1ys1spKtU3Ak9GxLLMfBr4F2A58Gi3pJxB0dJzEsWL/W10e8HX8NVPYx/W6lnUfS+fA76Vmf+851RKfc/ub5KGvXr7wFceVmfNeh+33fZZgO4Pq/X2gf8XYDrQfer26ofVD1M8rEqSNKzV263ojDNmAHDKKafy1FNP0NnZyapVjzF9+mk02K3oB5XBk7uZCdxTdjl6HDigW1dhDWP9NPbhbsdEjIirgLHA/L7LidQYK5UkDXs+rEqS1LpqdSsquxHVjDNy5Ej23feNbN26dZdt+VW3onHs2q1oHLu3N9tomOinsQ+fBCZFxMRyptbZZVwiYh7wbuDcclINaUDU1f2tpy4cVetHA/fQwNSI5boRwPeAZzNzRq9zI0l7od4+8D09rB5zzFuqo9bdB76Gnh5Wn6s/N5IkDS17262orW233Y3q6Va0yy73YhsNE/049uFFwAqKd/E7M3N1ecjPU7R6/05EAHw5M69paqYl6qhUqurCUau/ccUFlFMjRsRsiqkRZ3WbGrGrD3PlC0IxmNgaYEyf5UiSGuTDqiRJravebkWbNz9Pe/vBbN++nVde+Tljxuy/y7bs3H2ox25FPdhtVySpn8Y+fAh4qEa44yOrJdTT/a3HLhxVZtLY1IhExHjgTOD23mdDkvZeIw+rQL0Pq3vz4OnDqiRJ3dTbrejhh5cD8OijX+e4446nra2NKVNOZuXKR2ikW9FuLAM+EBFtEfEOYGtm2ppY0rBWT6VSPX2Hu+Jk5nagemrEnrb9DPAJwP6fkgaUD6uSJLWu6m5F5513DtOmTe/qVlQZA3HGjJls3bqVWbPOZunS+/jIRy4C4PDDj2DatOlQdCv6GmW3ovKdpdKtaA1wf6VbUURcHBEbKX7c+VFEVH4EfwhYR/FD+d8Cf9qkUyBJLaueJnP1dMfoKU7N8IiYAWzOzKci4pQ60iBJ/abePvDXXnsls2adzZgxY7j66r8EfvWw+pOf/EfdfeAj4mKKSvVfp3hYfSgz51E8rL6H4mH1F8AfNfdMSJLUmurpVrRgwQ01t5079wIuvfSSI7qH76Zb0S3ALTXCO4ELG027JA1l9VQq1dMdoxJnY51TI54FnBUR7wFeD4yJiHsz8/17lQtJ6iUfViVJkiSpMfVUKnV14QCepejC8b5ucZZRTI34HaqmRoyIZcDfR8TNFAN1TwKeyMzvAFcAlC2VLrVCSZIkSZIkafDY45hKPfU3johrIuKsMtodQGVqxPnA5eW2q4HK1IhdfZj7PhuSJEmSJElqprqmIazVhSMzr6z6/EugoakRq9Y/CjxaTzokSZIkSZLUGuqZ/U2SJEmSJEnaSV0tlSRJkjQ0Pf74t1m06EZ27NjBjBlnM2fO+Tut37ZtGwsWXEXmGsaM2Z9rrvk0hxxyKACLF/8dy5c/yOte9zouueQyTjzxpK59XnrpxUkx++XtmXk9QDlG5xLgzcD3gTmZuS0iRgP3AG8DXgRmZeYzEfEu4HpgH2AbcFlmfqO/z4kkSaqPLZUkSZKGqY6ODm6++QZuvPEW7r33S6xcuYL169ftFGf58gfZb7/9WLr0K8ya9T5uu+2zAKxfv46VKx9h8eL7uemmz3LTTdfT0dHRtU/gDGAycG5ETC53dwOwMDMnAS8DF5ThFwAvZ+aRwMIyHsALwO9l5lsoJoVZ3F/nQpIkNc5KJUmSpGFqzZrVjB8/gXHjxjNq1CimTz+NVase2ynOqlWPccYZMwA45ZRTeeqpJ+js7GTVqseYPv009tlnHw49dBzjx09gzZrVXfvMzHWZuY2iZdLMiGgDpgEPlLu+Gzi7/DyzXKZcf2pEtGXmDzJzUxm+Gnh92apJkiS1ACuVJEmShqktWzbT3n5w1/LYse1s2bK5xzgjR45k333fyNatW3vctns4sBEYBxwI/LScWbg6nPLfDdA18/DWMn61/w78IDNf7UWWJUlSH3JMJUmSpGGqs3PXsLa2tjri9Lztjh01VkAn0NZDOHtYR0QcQ9El7rRaO5ckSQPDlkqSJEnDVHt7O5s3P9+1vGXLZg46aGyPcbZv384rr/ycMWP273Hb7uHAeGATxfhIB0TEyG7hULRamgBQrt8feKlcHg/8I/CBzPxJn2RckiT1CSuVJEmShqmjjprMhg0b2LTpWV577TVWrnyEKVNO3inOlCkn8/DDywF49NGvc9xxx9PW1saUKSezcuUjbNu2jU2bnmXDhg0cffQxXfuMiIkRsQ8wG1iWmZ3AN4Fzyl3PBR4sPy8rlynXfyMzOyPiAOCrwBWZ+S/9eS4kSVLj7P4mSdIgUc/U7xGxlG7TsgNExBUUM2x1ABdn5ooy/BngZ2X49sx8exn+ZmApcBjwDPCHmfly/+ZQzTZy5Ejmz7+M+fM/yo4dHZx55lkcfvgR3H775znqqKOZOvWdzJgxk2uvvZJZs85mzJgxXH31XwJw+OFHMG3adN7//vcyYsQI5s//BCNGjABg/vzLuOyyS1YAI4A7M3N1echPAksiYgHwA+COMvwOYHFErKVooTS7DL8IOBL4VER8qgw7LTN3HvhJkiQNCCuVJEkaBCrTtC9ceCvt7Qczb94HmDr1ZCZOPLwrzvLlD0I5LXtEzKYYg2ZWOZ37bOAY4FBgZUT8ZmZ2lJv+bma+0O2QlwNfz8zrI+LycvmT/ZtLDYSTTprKSSdN3Sls3ryPdH0ePXo0CxbcUHPbuXMvYO7cC2ruMzN/s3t4Zq4DTqgR/kvgvTXCFwAL9pgJSZI0IOz+JknSIFDv1O/UmJadYrr2JZn5amauB9ZS48W+m+op3qunfpckSZIAK5UkSRoU6p36ndrTsndN116qnsq9E3gkIp6KiA9XxTk4M58r9/Uc0N6X+ZEkSdLgZ6WSJEmDwN5O/c6ep3KfkpnHAWcAF0bEyTXiSpIkSbuwUkmSpEGg3qnfqT0te9d07aWuqdwzs/LvZopp2yvd4p6PiEPKfR0CODCyJEmSdmKlkiRJg0C9U79TY1p2iunaZ0fE6IiYCEwCnoiIfSNiP4CI2Bc4DfhxuX31FO/VU79LkiRJgJVKkiQNCtVTv5933jlMmza9a+r3yoDdM2bMBDiwnJZ9PsWMbZTTud8PPA18DbiwnPntYGBVRPwr8ATw1cz8WnnI64F3RcR/AO8qlyVJkqQuIwc6AZIkqT71TP2embtMyw6QmdcB13ULWwf8dg/xXwRO7WWSJUmSNITZUkmSJEmSJEkNs1JJkiRJkiRJDbP7m1rS449/m0WLbmTHjh3MmHE2c+acv9P6bdu2ERFLgbcBLwKzMvMZgIi4ArgA6AAuzswVZfjpwCJgBHB7Zl5fht8HvB14jWJMkT/OzNf6P5eSJEmSJA1etlRSy+no6ODmm2/gxhtv4d57v8TKlStYv37dTnGWL38Q4OXMPBJYCNwAEBGTgdnAMcDpwOciYkREjABuBc4AJgPnlnEB7gOOAt4CvAGY1995lCRJkiRpsLOlklrOmjWrGT9+AuPGjQdg+vTTWLXqMSZOPLwrTjnT0d3l4gPAX0dEGzATWJKZrwLryxmQTijjrS0HpSUilpRxn87Mhyr7jYgngPH9mT9JkiRJkoYCWyqp5WzZspn29oO7lseObWfLls27xAE2AGTmdmArcCAwrhJe2liG9RTeJSJGAXMoptuWJEmSJEm7YaWSWk5n565hbW1te4wDdAJtDYZX+xzwrcz85z2nUpIkSZKk4c1KJbWc9vZ2Nm9+vmt5y5bNHHTQ2F3iABMAImIksD/wEkULpAlVUccDm3YTTrmPq4CxwPy+y4kkSZIkSUOXlUpqOUcdNZkNGzawadOzvPbaa6xc+QhTppy8U5xyeW65eA7wjczsBJYBsyNidERMBCZRzOj2JDApIiZGxD4Ug3kvA4iIecC7gXMzc0cTsihJkiRpiHn88W9z7rl/wKxZZ7N48V27rK/MYB0RayPiuxFxWGVdRFxRhmdEvLsq/PQybG1EXF4VflEZ1hkRB/Vz1qQeWamkljNy5Ejmz7+M+fM/ynnnncO0adM5/PAjuP32z1cG6GbGjJkAB5YDcc8HLgfIzNXA/cDTFGMjXZiZHeW4SxcBK4A1wP1lXIDPAwcD34mIH0bElc3LrSRJkvaknpf1K6+8glmzzuZDH5rLc891NUhn8eK/o8GX9YnlC/9/lBUA+5Th50fElvJ58YflD5MSMCAzWP8LMB34P/2fO6lnzv6mlnTSSVM56aSpO4XNm/eRrs+jR48mM99ba9vMvA64rkb4Q8BDNcL9HojHH/82ixbdyI4dO5gx42zmzDl/p/Xbtm1jwYKryFzDmDH7c801n+aQQw4FiofVL3zh1rVAB3BxZq6A4mEVWASMAG7PzOvL8InAEuDNwPeBOZm5LSLOB/4n8Gx52L/OzNv7N+eSJLW2ysv6woW30t5+MPPmfYCpU0/eaWbg5csfZL/99mPp0q+wcuUKbrvts1xzzadZv34dK1c+AsXL+qHAyoj4zXKzW4F3UQyT8GRELMvMpyle9Bdm5pKI+DxwAXBbuc3SzLyoOTnXYDIAM1j/oAzr97xJu1NXS6WeavGr1o9upBlfREyIiG9GxJqIWB0RH+uzHElSg+r9ZanysDpr1vu47bbPAnR/WK33l6XKw+ok4GWKh9WKpZn51vLPCiVJ0rBX/bI+atSorpf1aqtWPcYZZ8wA4JRTTuWpp56gs7OTVaseY/r008jMVzNzPVB5WT+B8mU9M7dR/Ngzs3zBn0bxwg9FBcDZzcmpBrOBmsFaGmh7rFTaw4tRxQU00IwP2A58PDOPBt4BXFhjn5LUFD6sSpLUuup9Wa/EGTlyJPvu+0a2bt26y7bs+WX9QOCn5Qt/dXjFf4+IH0XEAxFRPQmMhrkBnMFaGlD1tFSq+WLULc5Mdm7Gd2r3ZnzVL1uZ+Vxmfh8gM39GMcaNNa6SBoQPq5Ikta69fVlva+vzl/j/BRyWmb8FrORX7z/SgMxgLbWCeiqV6mly1xWnzmZ8Xcqucr8DfLeBdEtSn/FhVZKk1lXvy3olzvbt23nllZ8zZsz+u2zLnl/WXwAOKF/4q8PJzBfLMW8A/hZ4W9/kUENBs2ewllpFPZVK9TS526vmehHxRuAfgEsy8z/rSIsk9TkfViVJal31vqw//PByAB599Oscd9zxtLW1MWXKyaxc+Qj1vqyXL/jfpHjhh6IC4EGAiDik6pBnUfS2kIDmz2AdERdHxEaKZ8kfRYRjcWpA1DPrVT1N7ipxNtbZjI+IGEVRoXRfZn55r1IvSX2g+mF17Nh2Vq58hKuuWrBTnMrD6rHH/tYuD6t/8Rd/zhe+cOtoilllKg+rbZQPqxSzuc0G3peZnRFReVhdQreH1cx8rjykD6uSmqK3s18uX/4gr3vd67jkkss48cSTuvZ56aUXJ/XPfjkauIeiMv1FYFZmPhMRB1IMrXA8cJezbg1P1S/rO3Z0cOaZZ3W9rB911NFMnfpOZsyYybXXXsmsWWczZswYrr76LwE4/PAjmDZtOj/5yX88TTGu64WZ2QEQEZWX9RHAnZWXdeCTwJKIWAD8ALijDL84Is4q9/MScH6TToEGiSbPYH0LcEsvkyz1Wj2VSl21+FS9GHWLs4zixeg7VDXji4hlwN9HxM1UvWyV4y3dAazJzJv7JiuStHd8WJU0XPXFVO2LF9/PCy9s4ZJL/pQvfrH4nfDmm2+AYpKXeqdq75r0JSJml/FmAb8EPgUcW/5pmKrnZX3Bghtqbjt37gVceuklR3QP383L+jp+NZ17dfgVwBWNpl2ShrI9Vipl5vZaL0YRcQ3wvcxcRvFCtLhsxvcSRcUTZbxKM76ul62ImArMAf4tIn5YHurPygu7JDWdD6uShqPq2S+BrtkvqyuVVq16jA9+8MNAMfvlwoV/tdPsl/vssw+HHjqO8eMnsGZNUXc+fvwEvvnNb6wDiIjK7JdrKGa/rPw4eTdwNUWl0szyMxQtk/46Itoy8xVgVUQc2Y+nQZIk7aV6WirVfDHKzCurPv8SqLsZX2auovZ4S5IkSWqSWrNfPv30j3uM0332y2OOectO21ZmzqwxK+aJ7H72y50mfYmIyqQvL/RNTiVJUn+oq1JJkiQNvHrGvomIpXQblwYgIq6g6GLUAVycmSsiYgLFODa/DuwA/iYzF5XxrwY+BGwpd2+L4iGor2e/bGtrY8eOmtNi7mkCl3omhpEkSS2mntnfJEnSAKuMfXPjjbdw771fYuXKFaxfv26nOMuXPwjluDTAQopxaYiIyRRd048BTgc+FxEjKLqmfzwzjwbeAVxYxq1YmJlvLf+sUBqC+nL2y8q2u5kVs8fZL6ma3KXbpC+SJKmFWakkSdIgUD32zahRo7rGvqlWLt9dLj4AnFpOjjETWJKZr2bmemAtcEJmPpeZ3wfIzJ9RzDg4Dg0bfTFV+7Zt29i06Vk2bNjA0Ucf07XPRqZq51eTvkDVpC/9m3tJktRbVipJkjQI1Br7pjJ+TXUcqsalASrj0nSNV1OqHssGgIg4DPgd4LtVwRdFxI8i4s6IeFNf5UWto3r2y/POO4dp06Z3zX5ZqbScMWMmW7duZdass1m69D4+8pGLgF/Nfvn+97+Xj3/8o8yf/wlGjBjRtU+KSV7WAPd3m/1yfjm5y4H8avbLO4ADy/D5wOWVNEbEM8DNwPkRsbFbazpJkjSAHFNJkqRBYG/HvmHPY9kQEW8E/gG4JDP/swy+Dbi2jHctcBPwwUbTrdbX29kv5869oOY+M/M3u4fvZvbL3U36cthuMyBJkgaMLZUkSRoE6h37htrj0nSNV1PqGssmIkZRVCjdl5lfrkTIzOczsyMzdwB/S42KAEmSJA1vVipJkjQI1Dv2DbXHpVkGzI6I0RExEZgEPFGOt3QHsCYzb67eV0QcUrX4+8DO88xLkiRp2LNSSZKkQaDesW+oMS5NOZ7N/cDTwNeACzOzA5gCzAGmRcQPy7/3lIf8q4j4t4j4EfC7wP9oYnYlSZI0CDimkiRJg0Q9Y99kZk/j0lwHXNctbBW1x1siM+f0Nr2SJEka2mypJEmSJEmSpIZZqSRJkiRJkqSGWakkSZIkSZKkhlmpJEmSJEmSpIZZqSRJkiRJkqSGWakkSZIkSZKkhlmpJEmSJEmSpIZZqSRJkiRJkqSGWakkSZIkSZKkhlmpJEmSJEmSpIZZqSRJkiRJkqSGWakkSZIkSZKkhlmpJEmSJEmSpIZZqSRJkiRJkqSGWakkSZIkSZKkhlmpJEmSJEmSpIZZqSRJkiRJkqSGWakkSZIkSZKkhlmpJEmSJEmSpIaNrCdSRJwOLAJGALdn5vXd1o8G7gHeBrwIzMrMZ8p1VwAXAB3AxZm5op59anh7/PFvs2jRjezYsYMZM85mzpzzd1q/bds2ImIpfVDmImIisAR4M/B9YE5mbuttHo6/6Vs1w5/8+Mm93bX6QT1lbsGCq8hcw5gx+3PNNZ/mkEMOBWDx4r/jC1+4dS29LHO7u5ZKMDSujWpNvb0GLl/+IK973eu45JLLOPHEk4C+vQb2VH57w/v04OJ9WoOB92kNR3tsqRQRI4BbgTOAycC5ETG5W7QLgJcz80hgIXBDue1kYDZwDHA68LmIGFHnPjVMdXR0cPPNN3Djjbdw771fYuXKFaxfv26nOMuXPwh9V+ZuABZm5iTgZYryrGGk3jK33377sXTpV5g1633cdttnAVi/fh0rVz4CfVPmal5LJfDaqP7TF9fAxYvv56abPstNN11PR0cHHR0d0EfXwJ7Kb7+dELUc79MaDLxPa7iqp/vbCcDazFxX1nwuAWZ2izMTuLv8/ABwakS0leFLMvPVzFwPrC33V88+NUytWbOa8eMnMG7ceEaNGsX06aexatVjO8Upl3td5sptppX7qOzz7P7M3/E3favmnwZOvWXujDNmAHDKKafy1FNP0NnZyapVjzF9+mn0UZnr6VoqDflrowZOX1wD99lnHw49dBzjx09gzZrVrFmzGvruGthT+e0X3qdbj/dpDQbepzVc1dP9bRywoWp5I3BiT3Eyc3tEbAUOLMMf77btuPLznva5V2zKPPht2bKZ9vaDu5bHjm3n6ad/vEsc+qbMHQj8NDO314jfVJbdgVNvmavEGTlyJPvu+0a2bt3Kli2bOeaYt1RH7U2Z6+la+kKvM6lBb6hcG73WtZ6+vAaOHdteKYfQd9fA3ZXfptmbiiXLdd/wPq3BYKjcp6VG1VOpVKv2vbPOOD2F12oh1X2fjB27X82a/2euP7NWsIaIT33q8vcC777ppr+aB7BgwVVzgBM+/ekFH63EWb9+3eoam+5NmaunfAOWx6Gs3jL3B39w5rszcyPApk3P/mTGjOknANd8+ctf+s773z+repd7W+bqKo+WxeGpFa+NlsWhoY+ugfcCfPWry+746leXPURRtt7d7VB7ew3cY3nsqSyC5XEo8D6twcD7tIarerq/bQQmVC2PBzb1FCciRgL7Ay/tZtt69qnhq5ll7gXggHIfPR1LQ1+rlLmejiFB65RTDT2tUrYaPYaGj1YvoxK0TjmVmqqeSqUngUkRMTEi9qEYQGxZtzjLgLnl53OAb2RmZxk+OyJGl6PTTwKeqHOfGr6aVubKbb5Z7oNynw/2Y97UmlqlzPV0DAlap5xq6GmVstXoMTR8tHoZlaB1yqnUVHusVCr7aV4ErADWAPdn5uqIuCYiziqj3QEcGBFrgfnA5eW2q4H7gaeBrwEXZmZHT/vs26xpsBqAMvdJYH65rwPLfWsYaaEyV/MYErRUOdUQ00Jlq6Fj9M/ZUCtq9TIqQUuVU6mp2jo7B1flekScDiwCRgC3Z+b1A5CGZ4CfAR3A9sx8e0S8GVgKHAY8A/xhZr5cjsy/CHgP8Avg/Mz8fh+n505gBrA5M48twxpOT0TMBf683O2CzLybXuohbVcDHwK2lNH+LDMfKtddQTEdZgdwcWauKMMH/P+9u1ZMU2/0dzmKiLcBdwFvAB4CPtZKv+5FxATgHuDXgR3A32TmosFyDvq7PLby+Yliut3vAc9m5ozyF74lwJuB7wNzMnNbRIwu8/A24EVgVmY+U+6jT689EXEAcDtwLMUYBx8EcqDPVTMMtWtjT1rtWaC/tfKzxm7S3NSyOFD30d6Wu4G8vg/l70w179Gtc48ezvfniv4sj630PtFq34uIeD3wLWA0xdjWD2TmVQP9negL9XR/axnlRelW4AxgMnBuREweoOT8bma+NTPfXi5fDnw9MycBX+dXv1ycQdF8cRLwYeC2fkjLXcDp3cIaSk/55bqKYjaBE4CrIuJN/ZQ2gIXl+XtrVYXSZIomnceU23wuIka02P870HJlsa/cRf+Wo9vKuJXtapWLgbQd+HhmHg28A7iw/D9t+XPQpPLYyufnYxS/3lXcQHGNmQS8THHTpfz35cw8ElhYxuuva88i4GuZeRTw22X6WuFc9ashem3cnVZ6Fuhvd9G6zxq7GKCyeBcDcx/tbbkbyOv7UP7OAN6jab179LC8P1c0oTzeReu8T7Ta9+JVYFpm/jbwVuD0iHgHA/+d6LVBValE8Z+4NjPXZeY2ihq9mQOcpoqZQOXXP3QLkQAAIABJREFUtruBs6vC78nMzsx8nGJAtUP68sCZ+S12HSSw0fS8G/inzHwpM18G/ok+uAj2kLaezASWZOarmbkeWEvxf96K/++tmKZe6c9yVK4bk5nfKWvv76naV0vIzOcqv0Zk5s8oHjLGMTjOQb+Xx1Y9PxExHjiT4ldHyl+ZpgEP9JCmSlofAE4t4/fptScixgAnUzZDz8xtmfnTgT5XTTLkro0NGrBngf7Wys8aPWh6WRzA+2ivyt0AX9+H7HemivfoFrlHD/P7c0W/lsdWep9ote9Fud+fl4ujyr9OBvi5tS8MtkqlccCGquWNZVizdQKPRMRTEfHhMuzgzHwOigIMtJfhA5XmRtPT7HReFBE/iog7q2p6WyVt9WjFNPWHvipH48rP3cNbUkQcBvwO8F0GxzloanlssfPzGeATFM2aoRhT4KdZjEHQfT9dxy7Xby3j9/W153CK7r1/FxE/iIjbI2JfBv5cNcNwuTbC4HgW6G+t/KzRKue8Gd/7Pit3A3B9Hw7fGe/RrXOPHs7354qB+G4N+Pltle9F2aLoh8BmisqpnzDwz629NtgqldpqhA1EH9UpmXkcRdOyCyPi5N3EbZU0V/SUnmam8zbgCIpmf88BN5XhrZC2erVimpqp0f+rQXO+IuKNwD8Al2Tmf+4maiudg6ad31Y6PxFR6bP/VB3HbUqaSiOB44DbMvN3gFfY/WCurVSWequV09bXBvOzQH9rhbLb6ue8Gd/7hrZppev7Xm7TqrxH7/m4TUkTw/v+XNFKaWzK+W2l70UWg6+/FRhP0bLo6N3sY9CUv8FWqbQRmFC1PB7Y1OxEZOam8t/NwD9SFIjnK81yy383l9EHKs2Npqdp6czM58sv1A7gbynOX0ukrQGtmKb+0FflaGP5uXt4S4mIURQ3nfsy88tl8GA4B00pjy14fqYAZ0UxYPISiubDn6Forjyyxn66jl2u35+iiXZfX3s2Ahsz87vl8gMUD7GDoSz11nC5Ng6WZ4H+1rLPGk0+1u4043vf63I3gNf34fCd8R7dOvfo4Xx/rhiI79aAnd8W/F4AUHa7fJRirKeBfm7ttcFWqfQkMCkiJkbEPhQDVC1rZgIiYt+I2K/yGTgN+HGZjrlltLnAg+XnZcAHIqKtHIhra6W5XT9rND0rgNMi4k1ld7TTyrA+161P/O9TnL9K2mZHxOgoRsGfBDxBC/y/19CKaeoPfVKOynU/i4h3lH2BP1C1r5ZQpusOYE1m3ly1ajCcg34vj614fjLziswcn5mHUeT5G5l5HvBN4Jwe0lRJ6zll/E76+NqTmf8fsCEiogw6lWKK4MFQlnprWFwbB9GzQH9r2WcNWqcsNuN736tyN8DX9+HwnfEe3SL36GF+f64YiGvjgJzfVvteRMTYKGYfJCLeAEynGOdpQJ9b+8LIPUdpHZm5PSIuoviPHQHcmZmrm5yMg4F/LK9FI4G/z8yvRcSTwP0RcQHwf4H3lvEfopiWcC3F1IR/1NcJiogvAqcAB0XERorR6a9vJD2Z+VJEXEtRGAGuycx6B9huNG2nRMRbKZrjPQP8cZmG1RFxP8XFfTtwYWZ2lPsZ6P/3nbRIWexTTShHf8Kvptx8uPxrJVOAOcC/RdHXGeDPGATnoEnlcTCdn08CSyJiAfADygE5y38XR8Rail96Zpdp6o9rz0eB+8qb+jqK/L+O1jtXfWooXht70HLPAv2tlZ81ahmIsjiA99GGjlHDQF7fe5v2luc9ehcDfY8elvfniv4ujy32PtFq34tDgLujmKXtdcD9mbk8Ip5m4J9be6Wts7PVunlKkiRJkiSp1Q227m+SJEmSJElqAVYqSZIkSZIkqWFWKkmSJEmSJKlhVipJkiRJkiSpYVYqSZIkSZIkqWFWKkmSJEmSJKlhVipJkiRJkiSpYVYqSZIkSZIkqWFWKkmSJEmSJKlhVipJkiRJkiSpYVYqSZIkSZIkqWFWKkmSJEmSJKlhVipJkiRJkiSpYVYqSZIkSZIkqWFWKkmSJEmSJKlhVipJkiRJkiSpYVYqSZIkSZIkqWFWKkmSJEmSJKlhVipJkiRJkiSpYVYqSZIkSZIkqWFWKkmSJEmSJKlhVipJkiRJkiSpYSMHOgHDUUSsAL6bmVd2C58JfAEYn5nbG9znNOBG4EjgBeD6zPybPkqyhqh+Kou/B3waOAz4ETAvM5/umxRrKOmn8vc3wDuBScAHM/Oubuv/B/BJ4A3APwB/kpmv7nUmNCQ0uyxGxLHATcDbgAMzs613OdBQMgDlcS5wcbnuP4G/B/6s0WNo6BmAsjgb+Avg14FXgYeBj2bmf/YmH5L6ly2VBsZdwJyI6P4QOQe4r5GLc0SMjIhRwD9SXNz3B2YBN0fEb/dRejV03UXflsVJwH3AR4ADgP8FLIsIK7BVy130YfkrP/4r8KfA92vEeTdwOXAqRaXn4RQPr9JdNLEsAq8B9wMXNJ5UDQN30dzy+GvAJcBBwIkU18hLG0yzhqa7aG5Z/BdgSmbuT3GPHgksaDTRkprLF72B8RXg88D/C3wLICLeBMwAToyIMykuoEcAW4E7MvPqMt5hwHpgHnAV8AzwXmAMsDgzO4EnI2INMJniwi31pK/L4v3AP2fmqjLODcCVFL9Ifb1JedLg0dfl7+TMvLVc/8sax5tb7mN1GedaikrQy/sldxpMmloWMzOBjIgj+zNTGrSaXR5vq1p8NiLuA363H/KlwafZZXFDt6AOil4YklqYLZUGQGb+F8XL9weqgv8Q+PfM/FfglXLdAcCZwJ9ExNnddvNO4Gjg3Zn5PPBF4I8iYkREnAT8BrCqf3Oiwa6vyyLQVv5VVJaP7ZcMaFDrh/K3J8ewc0X7vwIHR8SBe5cDDRUDUBalHrVAeTwZWL0X22mIGYiyGBFTI2Ir8DPgvwOf6VUmJPU7WyoNnLuBr0bER8sL9gfKMDLz0ap4P4qIL1JckL9SFX51Zr5StfxF4HZgUbn8JzVq+6Va+qwsRsQ/AddHxCnAtynGrtmHomm9VEtfXwt3540Uv6RWVD7vB7y4F2nX0NLMsijtyYCUx4j4I+DtFK1LJGhyWSxbu+8fEeOAD1G0cJLUwqxUGiCZuSoitgAzI+IJ4HjgDwAi4kTgeorWHfsAo4EvddtFV4VRRBwFLAV+H/gnioHvlkfEpsz8an/nRYNbX5bFzPz3csDPvwYOAe4FngY29nc+NDj1Zfmrw88pugpXVD7/bC+SriGmyWVR2q2BKI9lC5PrgemZ+UIvkq8hZKCujZn5bER8DVgCHLeXyZfUBHZ/G1j3UNT2zwEeKbuxQTHrxjJgQjlQ3efZuUsRQGfV52MphmhYkZk7yrEavgqc0a+p11DSV2WRzHwgM4/NzAMp+tD/BvBkfyZeg16flb89WA1UT2Dw28DzmWkrJVU0qyxK9WhaeYyI04G/BX4vM/+tV6nWUDRQ18aRFOM1SWphtlQaWPcAfw78FvA/qsL3A17KzF9GxAnA+4BHdrOfHwCTImIa8E2K2RJmADf0S6o1FPVVWSQi3gb8EHgzRYul/5WZ/94vqdZQ0Zflbx+KH0zagFER8XpgW2buKI9zVzkI7XPlMe/q47xocGtKWSxnUhpN8cs+5brOzHy1rzOkQa1Z5XEaxaQFv5+ZT/RDPjT4Nassngf8M0Xrpv8GXIcTvUgtz5ZKAygzn6EYd2Zfilr+ij8FromIn1HMnHX/HvbzE+CDwC3AfwKPAf8A3NH3qdZQ1FdlsbQI+CmQ5b8f6tPEasjp4/L3CPBfwP8D/E35+eTyOF8D/oqi8v3/lH9X9UkmNCQ0qyxStOD8L341GPJ/UVwzpS5NLI+fAvYHHoqIn5d/D/dJJjQkNLEsTi6P83PgXyiuiz5HSi2urbPT1tqSJEmSJElqjC2VJEmSJEmS1DDHVJIkaYgqB99dBIwAbs/M67utPxn4DMU4GbMz84Ey/K3AbRQz5HUA12Xm0mamXZKk4Soi7qQYI3dzZh5bY30bxf39PcAvgPMz8/vNTaVUsKWSJElDUESMAG6lmAl0MnBuREzuFu3/AudTzOBT7RfABzLzGOB04DMRcUD/pliSJJXuorj/9uQMYFL592GKH4KkAWGlkiRJQ9MJwNrMXJeZ24AlwMzqCJn5TGb+CNjRLfx/Z+Z/lJ83AZuBsc1JtiRJw1tmfgt4aTdRZgL3ZGZnZj4OHBARhzQnddLOWrr725YtP3MUcfVo7Nj92pp5PMujdqeZ5dGyqN2pKovjKKZlrtgInNjo/sppovcBftJ9nWVRu+N1Ua3E8qhW0UdlsdY9fhzwXHUky6J2p6+uiy1dqSRJkvZarQeFhh4uy189FwNzM3PHnuJLkqSm6PU9Xuordn+TJGlo2ghMqFoeD2yqd+OIGAN8Ffjzsmm9JElqDb26x0t9yZZKkiQNTU8CkyJiIvAsMBt4Xz0bRsQ+wD9SjNfwpf5LoiRJ2gvLgIsiYglF1/atmfncHraR+oWVSpIkDUGZuT0iLgJWACOAOzNzdURcA3wvM5dFxPEUlUdvAn4vIv6inPHtD4GTgQMj4vxyl+dn5g+bnxNJkoaXiPgicApwUERsBK4CRgFk5ueBh4D3AGspZmz9o4FJqQRtnZ2t2/XSgcW0Ow7UrVbiAKBqFZZFtQrLolqJ5VGtwrKoVtFXZdExlSRJkiRJktQwu79JUhNExJ3ADGBzZh5bY/15wCfLxZ8Df5KZ/9rEJEqSJElSQ2ypJEnNcRdw+m7WrwfemZm/BVwL/E0zEiVJkiRJe8uWSpLUBJn5rYg4bDfrv121+DjF1LCSJEmS1LJsqSRJrecC4OGBToQkSZIk7Y4tlSSphUTE71JUKk0d6LRIkiRJ0u4Mykql42/6Vo/rnvz4yU1MidRzebQsqlER8VvA7cAZmflio9tbFtUqvE+rlXhtVKuwLEoaiuz+JkktICL+G/BlYE5m/u+BTo8kSZIk7cmgbKkkSYNNRHwROAU4KCI2AlcBowAy8/PAlcCBwOciAmB7Zr59YFIrSZIkSXtmpZIkNUFmnruH9fOAeU1KjiRJkiT1mt3fJEmSJEmS1DArlSRJkiRJktQwK5UkSZIkSZLUMCuVJEmSJEmS1DArlSRJkiRJktQwK5UkSZIkSZLUMCuVJEmSJEmS1DArlSRJkiRJktQwK5UkSZIkSZLUsJEDnQCplscf/zaLFt3Ijh07mDHjbObMOX+n9du2bSMilgJvA14EZmXmMwARcQVwAdABXJyZK8rwO4EZwObMPLayr4h4M7AUOAx4BvjDzHy5XzMoSZIkSdIgZ0sltZyOjg5uvvkGbrzxFu6990usXLmC9evX7RRn+fIHAV7OzCOBhcANABExGZgNHAOcDnwuIkaUm91VhnV3OfD1zJwEfL1cliRJkiRJu2GlklrOmjWrGT9+AuPGjWfUqFFMn34aq1Y9tlOccvnucvEB4NSIaANmAksy89XMXA+sBU4AyMxvAS/VOOTMqn3dDZzd13mSJEmSJGmosfubWs6WLZtpbz+4a3ns2HaefvrHu8QBNgBk5vaI2AocCIwDHq+KurEM252DM/O5cl/PRUR7b/MgDQbH3/StHtc9+fGTm5gSSUNFdff1Z5/deHlmXl+9PiJGA/fQrft6RBxI8SPR8cBdmXlR1TZvo2ht/AbgIeBjmdnZnBxJkqTdsaWSWk5njcfEtra2PcYBOoG2HsIlSVI/6t59HTi37JZe7QJqdF8Hfgl8Cri0xq5vAz4MTCr/anVllyRJA8BKJbWc9vZ2Nm9+vmt5y5bNHHTQ2F3iABMAImIksD9F17aNlfDSeGDTHg75fEQcUu7rEGBz73IgSdLw0737OrCEoot5teou513d1zPzlcxcRVG51KW8L4/JzO+UrZPuwW7qkiS1jLoqlSLi9IjIiFgbEbsMYhwRoyNiabn+uxFxWNW6K8rwjIh3d9tuRET8ICKW9zonGjKOOmoyGzZsYNOmZ3nttddYufIRpkzZuStOuTy3XDwH+Eb5sLkMmF2WyYkUv2g+sYdDLqva11zgwT7KiiRJw0b37uvU7oI+jqru60Cl+3pPxpX72d0+JUnSANljpVI5c9atwBnAZBpoyryHmbgAPgas6W0mNLSMHDmS+fMvY/78j3Leeecwbdp0Dj/8CG6//fNdA3bPmDET4MCIWAvMp5yxLTNXA/cDTwNfAy7MzA6AiPgi8J3iY2yMiAvKQ14PvCsi/gN4V7ksSZIasJuu6dUa7aZut3ZJklpYPQN1nwCszcx1ABFRacr8dFWcmcDV5ecHgL/uPhMXsL6sADgB+E5EjAfOBK6jqBSQupx00lROOmnqTmHz5n2k6/Po0aPJzPfW2jYzr6MoV93Dz+0h/ovAqb1JryRJw1337uvU7oJe6aa+sVv39Z5sLPezu31KkqQBUk/3t65myqVGmjLvbtvPAJ8AdjScakmSJLWU7t3XKVqrL+sWrbrLeXX39ZrK2Vl/FhHvKH+w/AB2U5ckqWXU01KpnmbHPcWpGR4RM4DNmflURJxSRxokSZLUwqq7r+/Y0QFwf2aujohrgO9l5jLgDmBx2Xr9JYqKJwAi4hlgDLBPRJwNnJaZTwN/AtwFvAF4uPyTJEktoJ5KpXpm0+qpKXNP254FnBUR7wFeD4yJiHsz8/17lQtJkiQNuOru62PH7ncdQGZeWVmfmb8Eeuq+flgP4d8Dju3rtEqSpN6rp1LpSWBSOZPWsxS/KL2vW5xKU+bvUNWUOSKWAX8fETcDh1LOxJWZ3wGuAChbKl1qhZIkSZIkSdLgscdKpczcHhEXASuAEcCd9TZlLuNVZuLaTtVMXJIkqX9FxOnAIor79+2ZeX239SdTjHH4W8DszHygat1c4M/LxQWZeXdzUi1JkqTBop6WSmTmQ8BD3cLqbcpccyauqvWPAo/Wkw5JklSfiBgB3Aq8i6I7+pMRsawco6bi/wLnA5d22/bNwFXA2ynGSHyq3PblZqRdkiRJg0M9s79JkqTB5wRgbWauy8xtwBJgZnWEzHwmM3/ErjOxvhv4p8x8qaxI+ifg9GYkWpIkSYNHXS2VJEnSoDMO2FC1vBE4sRfbjuujdElSUzz++LdZtOhGduzYwbPPbry8Rhfg0cA9wNuAF4FZmflMue4K4AKgA7g4M1dUbTcC+B7wbGbOaE5uJKk12VJJkqShqa1GWGcTtpWkAdfR0cHNN9/AjTfewr33fgng3IiY3C3aBcDLmXkksBC4AaCMNxs4hqKV5ufKiqSKjwFr+jsPkjQYWKkkSdLQtBGYULU8HtjUhG0lacCtWbOa8eMnMG7ceEaNGgU1ugCXy5VJCB4ATo2ItjJ8SWa+mpnrgbUUXYqJiPHAmcDtTciGJLU8K5UkSRqangQmRcTEiNiH4lf3ZXVuuwI4LSLeFBFvAk4rwyRpUNiyZTPt7QdXB9XqxtvV1TcztwNbgQPZfRfgzwCfYNex6CRpWLJSSZKkIah8QbqIojJoDXB/Zq6OiGsi4iyAiDg+IjZSzOD6hYhYXW77EnAtRcXUk8A1ZZgkDQqdtTvsdg/tqatvzfCImAFszsynepc6SRo6HKhbkqQhKjMfAh7qFnZl1ecnKbq21dr2TuDOfk2gJPWT9vZ2Nm9+vjqoVjfeSlffjRExEtgfeImeuwCfBZwVEe8BXg+MiYh7M/P9/ZMLDVcRcTqwCBgB3F5jkPn/RtF184AyzuXlPV9qOlsqSVKTRMSdEbE5In7cw/q2iLglItZGxI8i4rhmp1GSpKHgqKMms2HDBjZtepbXXnsNancBXgbMLT+fA3wjMzvL8NkRMToiJgKTgCcy84rMHJ+Zh5X7+4YVSupr5aDwtwJnAJOpPcj8n1O0QP4dirL4ueamUvoVWypJUvPcBfw1xfTFtZxB8eA6iWLq99uofwp4SZJUGjlyJPPnX8b8+R9lx//f3v2Hy1mWh77/pkmIvxAsrIWapDVIvDG4rVQM5pCDCMEdNCex14aSoAg2eGoPP2pjbaHtVjY11wFNg7HijzZY+aFGQK3rsCOxFMGTSiSIP0n2va/shGMSvEwERKmFJGvl/PG+azmZzMqayZqZNbPy/VwXFzPPPDO531nvvPPO/T7Pcw/0Q8UUYODhzOwDbgZui4gtFCOUFgOU/e4ANgH7gMszs39stkRHoNnAlszcChARg4vMb6rosx94cXn7GCymoTFkUkmS2iQzvxURrzhEl0XAreVV0g0RcWxEvCwzf9qeCCVJGj/mzJnLnDlzAejpOXo5HDQF+FmKNeUOkpnLgeXDvXZm3g/c37xopSG1Foqvvsh4LfCNiLgSeCEwrz2hSQdz+pskdY5DVZuRJEnS+DfcAvKVlgCfy8xpwFspRtz5215jwh1PkjpHPScRkiRJGr+GWyi+0lLgDoDMfJBi4fjj2xKdVMWkkiR1jnpOIiRJkjR+bQRmRsSMiDiK2ovM/wQ4ByAiXk2RVNrd1iilkkklSeocfcC7yipwbwSedj0lSZKkI0dm7gOuANYBm6lYZD4iFpbd3g+8JyJ+AHwRuLRck1NqOxfqlqQ2iYgvAmcBx0fEDuBDwGSAzPw0sJZiXvwW4NfAu8cmUkmSJI2VzFxLcV5Y2Va5yPwm4Ix2xyXVYlJJktokM5eM8Ph+4PI2hSNJkiRJo+L0N0mSJEmSJDXMpJIkSZIkSZIaZlJJkiRJkiRJDTOpJEmSJEmSpIaZVJIkSZIkSVLDTCpJkiRJkiSpYSaVJEmSJEmS1DCTSpIkSZIkSWqYSSVJkiRJkiQ1zKSSJEmSJEmSGmZSSZIkSZIkSQ0zqSRJkiRJkqSGmVSSJEmSJElSwyaNdQBSLRs2fJtVq1YwMDDAggVv5+KLLz3g8T179hARXwJeDzwBXJiZjwFExDXAUqAfuCoz15Xt84FVwERgdWZeX7afA3yUIsn6DHBpZm5p/VZKkiRJktS9HKmkjtPf38/KlTewYsXHuf32O7n33nVs27b1gD533/01gKcy8yTgRuAGgIiYBSwGTgHmA5+MiIkRMRG4CTgPmAUsKfsCfAp4R2a+DvgC8Dct30hJkiRJkrqcI5XUcTZvfpRp06Yzdeo0AObNewvr1z/AjBknDvVZv/4BgFvKu3cBn4iICcAiYE1mPgdsi4gtwOyy35bM3AoQEWvKvpuA/cCLyz7HAI+3cPMkSRq3Kkca79y54+rBUcGDImIKcCuNjTT+M+Ayiu/rHwHvzsxn27VNkiRpeI5UUsfZvXsXvb0nDN3v6ell9+5dB/UBtgNk5j7gaeA4YOpge2lH2TZcOxQnqmsjYgdwMXDACbAkSRpZ9UhjDhwVPGgpjY00ngpcBZyWma+hmMK+uD1bJEmSRmJSSR1n//6D2yZMmDBiH4ormBMabAf4M+CtmTkN+CdgZb2xSpKkQuVI48mTJwMMjgqutIgDRxqfUz3SODO3AZUjjScBz4+IScALcESxJEkdw6SSOk5vby+7dv1s6P7u3bs4/vieg/oA0wHKk8xjgCcpRiBNr+g6jeLks2Z7RPQAv5eZ3ynbvwT8b03cHEmSjgjVI405cFTwoKGRw/WMNM7MncAK4CfAT4GnM/MbLdkASZLUMJNK6jgnnzyL7du38/jjO9m7dy/33vsNzjjjzAP6lPcvKe+eD9yXmfuBPmBxREyJiBnATOAhYCMwMyJmRMRRFEPn+4CngGMi4lXla50LbG7xJkqSNO4cYhRxpYZGFEfESyhGMc0AXg68MCLeOYowJUlSE5lUUseZNGkSy5Z9gGXLruQd7zifs8+ex4knvpLVqz89uEA3CxYsAjiuXIh7GXA1QGY+CtxBsQD3PcDlmdlfXg29AlhHkTS6IzMfLdvfA3w5In5AsabSB9q6wZIkjQPVI435zWjhSkMjh+scaTwP2JaZuzNzL/AVHFEsSVLHsPqbOtKcOXOZM2fuAW2XXfbeodtTpkwhMy+o9dzMXA4sr9G+Flhbo/2rwFdHGbIkSUe0ypHGPT29UIwKvqiqWx/FSOMHqRhpHBF9wBciYiXFiKTBkcYDwBsj4gXAfwDnAA+3ZYMkSdKITCpJkiRp1CpHGg8M9EM5KjgirgMezsw+4GbgtnKk8ZOUldzKfoMjjfdRjjQGvhMRdwGPlO3fA/6h7RsnSZJqMqkkSdI4FRHzgVUUZdhXZ+b1VY9PAW4FXg88AVyYmY9FxGRgNfD7FOcKt2bm/93W4NWVKkca9/QcvRwgMz84+HhmPgs0OtL4Q8CHWhGvJEkaHddUkiRpHIqIicBNwHnALGBJRMyq6rYUeCozTwJuBG4o2y8ApmTmf6JIOP1xRLyiLYFLkiSpa5hUkiRpfJoNbMnMrZm5B1hDUUWr0iLglvL2XcA5ETGBohrXC8uFlJ8P7AF+2Z6wJUmS1C1MKkmSND5NBbZX3N9RttXsU1bDfBo4jiLB9O/AT4GfACsy88lWByxJkqTuYlJJkqTxaUKNtv119pkN9FNU4ZoBvD8iTmxueJIkSep2dS3UfbgLfZaPXUOxZkM/cFVmrouI5wHfAqaUMdxVLsIoSZKaYwcwveL+NODxYfrsKKe6HUNRkesi4J7M3Avsioh/A04DtrY8akmSJHWNEUcqjWahz7LfYuAUYD7wyfL1ngPOzszfA14HzI+INzZnkyRJErARmBkRMyLiKIrv476qPn3AJeXt84H7MnM/xZS3syNiQkS8EHgj8D/aFLckSZK6RD0jlYYW+gSIiMGFPjdV9FkEXFvevgv4RLnQ5yJgTWY+B2yLiC3A7Mx8EHim7D+5/K96SL4kjSt1jPr8HYpFk48t+1ydmWvbHqjGhczcFxFXAOso9qfPZuajEXEd8HBm9gE3A7eV389PUiSeoLiY9E/AjymmyP1TZv6w7RshSZKkjlZPUqnWQp+nD9enPIkdXOhzKrCh6rlTYWgE1HeBk4CbMvM7h7MBktQNKkZ9nktxLNwYEX2ZWZmg/xvgjsw1H9wlAAAgAElEQVT8VDnScy3wirYHq3GjTEqurWr7YMXtZ4ELajzvmVrtkiRJUqV6FuoezUKfwz43M/sz83UUazzMjojX1BGLJHWresq77wdeXN4+hoPXv5EkSZKkjlFPUqmRhT6pWuhzxOdm5i+A+ynWXJKk8aqe8u7XAu+MiB0Uo0uubE9okiRJktS4epJKo1nosw9YHBFTImIGMBN4KCJ6IuJYgIh4PjAPFwCVNL7VM+pzCfC5zJwGvJVirZt6jtOSJEmS1HYjrqk0moU+y353UCzqvQ+4PDP7I+JlwC3lGiO/RbGGyN2t2EBJ6hD1jPpcSjlqMzMfjIjnAccDu9oSoSRJ48iGDd9m1aoVDAwMsHPnjqtrFMiYAtwKvB54ArgwMx8rH7uG4nu5H7gqM9eV38vfAqZQ/I66KzM/1L4tkqTOU89C3Ye90Gf52HJgeVXbD4FTGw1WkrrY0KhPYCdF8v2iqj4/Ac4BPhcRrwaeB+xua5SSJI0D/f39rFx5AzfeeBO9vSfw5jfPWVKjQMZS4KnMPCkiFgM3ABeWxTIWA6cALwfujYhXAc8BZ2fmMxExGVgfEV/PzA1I0hHKaRWS1AaZuQ8YHPW5mWKE5qMRcV1ELCy7vR94T0T8APgicGk5lViSJDVg8+ZHmTZtOlOnTmPy5MlQu0DGIuCW8vZdwDkRMaFsX5OZz2XmNmALMDsz95fVMQEml//5PS3piFbXSCVJ0ujVMepzE3BGu+OSJGm82b17F729J1Q27QBOr+o2VESjXPLjaeC4sn1D1XOnApTLd3wXOAm4KTO/05INkKQu4UglSZIkSePK/trjh6pbhyuiMWxxjczsz8zXUayNODsiXjOKMCWp6zlSSZIkSdK40tvby65dP6tsqlUgY7CIxo6ImAQcQ1F0aMTiGpn5i4i4n6LAxo+bGryOeBExH1hFUShrdfUi82WfPwSupUh4/iAzq9fqlNrCkUqSJEmSxpWTT57F9u3befzxnezduxeKhbf7qrr1AZeUt88H7ivXMuwDFkfElLLAxkzgoYjoiYhjASLi+cA84H+0YXN0BCmnWN4EnAfMApaUi8dX9pkJXAOckZmnAO9re6BSyZFKkiRJksaVSZMmsWzZB1i27EoGBvqhokAG8HBm9gE3A7dFxBaKEUqLAcp+dwCbgH3A5ZnZHxEvA24pf/T/Vvmad4/B5ml8mw1sycytABExuMh8ZeXC91Cs6fUUQGbuanuUUsmkkiRJkqRxZ86cucyZMxeAnp6jl8NBBTKeBS6o9dzMXA4sr2r7IXBqq+KVSkMLyJdqLTL/KoCI+DeKKXLXZuY97QlPOpDT3yRJkiRJ6gzDLhRfYRLFtMyzgCXA6sGpmVK7mVSSJEmSJKkzjLhQfNnna5m5NzO3AUmRZJLazqSSJEmSJEmdYSMwMyJmRMRR1F5k/p+BNwNExPEU0+G2tjVKqWRSSZIkSZKkDpCZ+4ArgHXAZioWmY+IhWW3dcATEbEJ+Cbwgcx8Ymwi1pHOhbolSZIkSeoQmbkWWFvVVrnI/H5gWfmfNKYcqSRJkiRJkqSGmVSSJEmSJElSw0wqSZIkSZIkqWEmlSRJkiRJktQwk0qSJEmSJElqmEklSZIkSZIkNcykkiRJkiRJkhpmUkmSJEmSJEkNmzTWAUi1bNjwbVatWsHAwAALFrydiy++9IDH9+zZQ0R8CXg98ARwYWY+BhAR1wBLgX7gqsxcV7bPB1YBE4HVmXl92T4B+DBwQfmcT2Xmx1u/lZIkSZIkdS+TSuo4/f39rFx5AzfeeBO9vSdw2WXvYu7cM5kx48ShPnff/TWApzLzpIhYDNwAXBgRs4DFwCnAy4F7I+JV5dNuAs4FdgAbI6IvMzcBlwLTgZMzcyAietu0qZIkjSuVF4V27txx9eAFnEERMQW4lcYuCh0LrAZeA+wH/igzH2zXNkmSpOE5/U0dZ/PmR5k2bTpTp05j8uTJzJv3Ftavf+CAPuX9W8q7dwHnlCOOFgFrMvO5zNwGbAFml/9tycytmbkHWFP2BfgT4LrMHADIzF0t3kRJksadwYtCK1Z8nNtvvxNgSXmxp9JSyotCwI0UF4Wouig0H/hkREwsn7MKuCczTwZ+D9jc+q2RJEn1MKmkjrN79y56e08Yut/T08vu3bsO6gNsB8jMfcDTwHHA1MH20o6ybbh2gFdSjHJ6OCK+HhEzm7k9kiQdCaovCnHgBZxBi2jgolBEvBg4E7gZIDP3ZOYv2rA5kiSpDiaV1HH27z+4bcKECSP2oRgSP6HBdoApwLOZeRrwj8Bn641VkiQVqi8KceAFnEFDF3nqvCh0IrAb+KeI+F5ErI6IF7ZmCyRJUqNMKqnj9Pb2smvXz4bu7969i+OP7zmoD8U6SETEJOAY4EmKk9DpFV2nAY8fop3ysS+Xt78KvLY5WyJJ0pHjEBd8KjV68WcS8PsURTROBf4duPrwo5QkSc1kUkkd5+STZ7F9+3Yef3wne/fu5d57v8EZZ5x5QJ/y/iXl3fOB+zJzP9AHLI6IKRExA5gJPARsBGZGxIyIOIpi3Ya+8vn/DJxd3n4T8D9buHmSJI1L1ReFOPACzqChizwNXBTakZnfKdvvokgySZKkDmD1N3WcSZMmsWzZB1i27EoGBvp529sWcuKJr2T16k9z8smvZu7cN7FgwSJuvPEjx0XEFoqT0cUAmfloRNwBbAL2AZdnZj9ARFwBrAMmAp/NzEfLf/J64PMR8WfAM8Bl7d1iSWqNiJhPscjxRGB1g5W4Xgt8BngxMAC8ITOfbV/06jaVF4V6enqh+G6+qKpbH8VFoQepuCgUEX3AFyJiJUX11pnAQ5nZHxHbIyIyM4FzKL7jJUlSBzCppI40Z85c5syZe0DbZZe9d+j2lClTyMwLaj03M5cDy2u0rwXW1mj/BfC2UYYsSR2lrJx1E3AuxWiPjRHRl5mVP8iHKnFFxGKKSlwXliNIbgcuzswfRMRxwN42b4K6TPVFIeCO8mLPdcDDmdlHseD2bY1cFAKupLj4cxSwFXh3e7dMkiQNx6SSJEnj02xgS2ZuBYiIwUpclUmlRcC15e27gE+UlbjeAvwwM38AkJlPtCtodbfKi0I9PUcvB8jMDw4+Xo52a/Si0PeB01oRryRJGh3XVJIkaXwarppWzT5VlbheBeyPiHUR8UhE/EUb4pUkSVKXMakkSdL4NFw1rXr6TALmAu8o//8HEXFOc8OTJElSt3P6myS1yUiLJpd9/pBiOtJ+4AeZWb3IrVSv4app1eqzo0Ylrgcy8+cAEbGWouLWv7Y6aEmSJHUPRypJUhtULJp8HjALWBIRs6r6zASuAc7IzFOA97U9UI0nG4GZETGjXOB4MUXlrUqDlbigohIXRaXM10bEC8pk05uw4pYkSZKqmFSSpPYYWjQ5M/cAg4smV3oPcFNmPgWQmbvaHKPGkXKNpCsoEkSbqajEFRELy243A8eVlbiWAVeXz30KWEmRmPo+8Ehm/vd2b4MkSZI6m9PfJKk9ai2afHpVn1cBRMS/UUyRuzYz72lPeBqPMnMtsLaqrd5KXLcDt7c0QEmSJHU1RypJUnvUs2jyJGAmcBawBFgdEce2OC5JkiRJOiwmlSSpPepdNPlrmbk3M7cBSZFkkiRJkqSOY1JJktqjnkWT/xl4M0BEHE8xHW5rW6OUJEmSpDqZVJKkNqhz0eR1wBMRsQn4JvCBzHxibCKWJEmSpENzoW5JapM6Fk3eT1GBa1mbQ5MkSZKkhjlSSZIkSZIkSQ0zqSRJkiRJkqSGmVSSJEmSJElSw0wqSZIkSZIkqWF1LdQdEfOBVcBEYHVmXl/1+BTgVuD1wBPAhZn5WPnYNcBSoB+4KjPXRcT0sv9LgQHgHzJzVVO2SJIkSZIkSS034kiliJgI3AScB8wClkTErKpuS4GnMvMk4EbghvK5s4DFwCnAfOCT5evtA96fma8G3ghcXuM1JUmSJEmS1KHqmf42G9iSmVszcw+wBlhU1WcRcEt5+y7gnIiYULavycznMnMbsAWYnZk/zcxHADLzV8BmYOroN0eSJEmSJEntUE9SaSqwveL+Dg5OAA31ycx9wNPAcfU8NyJeAZwKfKeBuCVJkiRJkjSG6llTaUKNtv119jnkcyPiRcCXgfdl5i/riEWSJEmSRrRhw7dZtWoFAwMD7Ny542rXhZWk5qtnpNIOYHrF/WnA48P1iYhJwDHAk4d6bkRMpkgofT4zv3I4wUuSJElStf7+flauvIEVKz7O7bffCa4LK0ktUU9SaSMwMyJmRMRRFAfYvqo+fcAl5e3zgfsyc3/ZvjgipkTEDGAm8FC53tLNwObMXNmMDZEkSZIkgM2bH2XatOlMnTqNyZMng+vCSlJLjJhUKtdIugJYR3HgvCMzH42I6yJiYdntZuC4iNgCLAOuLp/7KHAHsAm4B7g8M/uBM4CLgbMj4vvlf29t8rZJkiRJOgLt3r2L3t4TKptcF1ZdIyLmR0RGxJaIuPoQ/c6PiP0RcVo745Mq1bOmEpm5Flhb1fbBitvPAhcM89zlwPKqtvXUXm9JkiRJkkZlf/UKsGVz1X3XhVXHKada3gScS5HQ3BgRfZm5qarf0cBVmNjUGKtn+pskSZIkdY3e3l527fpZZZPrwqpbzAa2ZObWzNxD7ambAH8LfAR4tp3BSdVMKkmSJEkaV04+eRbbt2/n8cd3snfvXnBdWHWPeqZfngpMz8y72xmYVEtd098kSZIkqVtMmjSJZcs+wLJlVzIw0A8V68ICD2dmH0WC6LZyXdgnKRJPlP0G14XdR7kubETMpVgX9kcR8f3yn/qrcqkQqVlGmn75WxTVCi9tV0DSoZhUkiRJkjTuzJkzlzlz5gLQ03P0cnBdWHWFYadflo4GXgPcHxEALwX6ImJhZj7ctiilkkklSZIkSZI6w0ZgZjn1cifFCLqLBh/MzKeB4wfvR8T9wJ+bUNJYcU0lSZIkSZI6QGbuA64A1gGbqZi6GRELxzY66WCOVJIkSZIkqUOU63StrWr74DB9z2pHTNJwHKkkSZIkSZKkhplUkiRJkiRJUsOc/qaOtGHDt1m1agUDAwMsWPB2Lr740gMe37NnDxHxJeD1wBPAhZn5GEBEXAMsBfqBqzJzXdk+H1gFTARWZ+b1la8ZEX8PvDszX9TSjZMkSZIkaRxwpJI6Tn9/PytX3sCKFR/n9tvv5N5717Ft29YD+tx999cAnsrMk4AbgRsAImIWRYWEU4D5wCcjYmJETARuAs4DZgFLyr6UzzsNOLb1WydJkiRJ0vjgSCV1nM2bH2XatOlMnToNgHnz3sL69Q8wY8aJQ33Wr38A4Jby7l3AJyJiArAIWJOZzwHbImILMLvstyUztwJExJqy76Yy4fRRilKdf9Dq7ZMkabyqHGm8c+eOq2uMCp4C3EoDI43LxyYCDwM7M3NBe7ZGkiSNxJFK6ji7d++it/eEofs9Pb3s3r3roD7Adhgqu/k0cBwwdbC9tKNsG64dipKdfZn502ZuhyRJR5LqkcZUjQouLaWBkcYVz/tTitLakiSpg5hUUsfZv//gtgkTJozYB9gPTGikPSJeDlwA/H1jUUqSpEqVI40nT54MMDgquNIiDhxpfE71SOPM3AYMjTSOiGnA24DVbdgMSZLUAJNK6ji9vb3s2vWzofu7d+/i+ON7DuoDTAeIiEnAMcCTFCOQpld0nQY8foj2U4GTgC0R8RjwgnLKnCRJakD1SGMOHBU8aGjkcJ0jjQE+BvwFMND8qCVJ0mi4ppI6zsknz2L79u08/vhOenp6uffeb/ChD334gD5nnHEmDz204RLgQeB84L7M3B8RfcAXImIl8HJgJvAQxUilmRExA9hJMcT+osx8FHjp4OtGxDPlkHxJ6np1VL0cdn2b8vHfATYB12bminbFre50iFHElRodUbwA2JWZ342Is0YVoCRJajpHKqnjTJo0iWXLPsCyZVfyjnecz9lnz+PEE1/J6tWfHlygmwULFgEcV44qWgZcDVAmie6g+BF0D3B5ZvaXV0OvANZRrMlwR9lXksalkapelmqub1PhRuDrrY5V40P1SGN+Myq40tDI4TpHGp8BLCxHE68Bzo6I21sQviRJOgyOVFJHmjNnLnPmzD2g7bLL3jt0e8qUKWTmBbWem5nLgeU12tcCaw/172bmiw4nXknqQLMZpuplRZ9FwLXl7aFKmuXIz7cDW4F/b1/I6mbVI40pRwVXdesD6h5pnJkPAtcAlCOV/jwz39mWDZIkSSMyqSRJbTLSVKSKfucDdwJvyMyH2xiixpdaa9ScPlyfzNwXEU9TjAL9D+AvgXOBP29DrBoHKkcaDwz0QzkqOCKuAx7OzD7gZuC2cqTxkxSJJ8p+gyON91GONB6bLZEkSfUyqSRJbVAxFelcih/3GyOiLzM3VfU7GrgK+E77o9Q4M9zaNfX0+W/AjZn5TEQ0PTCNX5UjjXt6jl4OkJkfHHw8M5+lqLp6kOFGGlc8fj9wf/OilSRJo+WaSpLUHkNTkTJzD7VLbQP8LfAR4Nl2Bqdxabg1amr2qVrf5nTgI+U6Nu8D/ioirmhxvJIkSeoyjlSSpPYYcSpSRJwKTM/MuyPCKUcarY3UqHpZ1afm+jbA/z7YISKuBZ7JzE+0I2hJkiR1D0cqSVJ7HHIqUkT8FkWlrfe3LSKNa8NVvYyI6yJiYdntZmpU0pQkSZLq4UglSWqPkaYiHQ28Bri/XMPmpUBfRCx0sW4drlpVL+td36aiz7UtCU6SJEldz6SSJLXHIaciZebTwPGD9yPiforS2SaUJEmSJHUkp79JUhvUORVJkiRJkrqGI5UkqU1GmopU1X5WO2KSJEmSpMPlSCVJkiRJkiQ1zKSSJEmSJEmSGmZSSZIkSZIkSQ0zqSRJkiRJkqSGmVSSJEmSJElSw0wqSZIkSZIkqWEmlSRJkiRJktQwk0qSJEmSJElqmEklSZIkSZIkNcykkiRJkiRJkhpmUkmSJEmSJEkNM6kkSZIkSZKkhplUkiRJkiRJUsNMKkmSJEmSJKlhJpUkSZIkSZLUMJNKkiRJkiRJaphJJUmSJEmSJDVsUj2dImI+sAqYCKzOzOurHp8C3Aq8HngCuDAzHysfuwZYCvQDV2XmurL9s8ACYFdmvqYpWyNJkiRJkqS2GHGkUkRMBG4CzgNmAUsiYlZVt6XAU5l5EnAjcEP53FnAYuAUYD7wyfL1AD5XtkmSJEmSJKnL1DNSaTawJTO3AkTEGmARsKmizyLg2vL2XcAnImJC2b4mM58DtkXElvL1HszMb0XEK5qyFZIkSZJUYcOGb7Nq1QoGBgbYuXPH1c62kKTmq2dNpanA9or7O8q2mn0ycx/wNHBcnc+VJEmSpKbp7+9n5cobWLHi49x++53gbAt1kYiYHxEZEVsi4uoajy+LiE0R8cOI+NeI+N2xiFOC+pJKE2q07a+zTz3PlSRJkqSm2bz5UaZNm87UqdOYPHkywOBsi0qLgFvK23cB51TPtsjMbcDgbAsy81vAk+3YBh2Z6lx+5nvAaZn5Wop99yPtjVL6jXqSSjuA6RX3pwGPD9cnIiYBx1AcbOt5riRJkiQ1ze7du+jtPaGyydkW6hZDy89k5h5qJEQz85uZ+evy7gaK39nSmKgnqbQRmBkRMyLiKIqhoH1VffqAS8rb5wP3Zeb+sn1xREyJiBnATOCh5oQuSZIkSQfbX3tuhLMt1A0aTWouBb7e0oikQxgxqVRm7a8A1gGbgTsy89GIuC4iFpbdbgaOKxfiXgZcXT73UeAOikW97wEuz8x+gIj4IvBgcTN2RMTS5m6aJEmSpCNRb28vu3b9rLLJ2RbqFnUnNSPincBpwEdbGpF0CPVUfyMz1wJrq9o+WHH7WeCCYZ67HFheo31JQ5FKkiRJUh1OPnkW27dv5/HHd9LT0wvFbIuLqroNzrZ4kIrZFhHRB3whIlYCL8fZFmqvupKaETEP+GvgTWW1dWlM1JVUktqtsgTsggVv5+KLLz3g8T179hARX6KxErDzgVXARGD1YFnZiPg8RYZ/L8UJwx9n5t7Wb6UkSZJaYdKkSSxb9gGWLbuSgYF+qJhtATycmX0Usy1uK2dbPEmReKLsNzjbYh8Hz7Y4Czg+InYAH8rMm9u9fRrXhpafAXZSIyEaEacCnwHmZ+au9oco/YZJJXWcwRKwN954E729J3DZZe9i7twzmTHjxKE+d9/9NShLwEbEYooSsBdWlYB9OXBvRLyqfNpNwLkU2f+NEdGXmZuAzwPvLPt8AbgM+FTrt1SSpPGl8qLQzp07rh68gDMoIqYAt1LnRaGImF72fykwAPxDZq5q3xapm82ZM5c5c+YC0NNz9HJwtoU6X2bui4jB5WcmAp+tkRD9KPAi4M6IAPhJZi4c9kWlFjKppI5TWQIWYN68t7B+/QMHJJXWr38ADiwB+4nqErDAtvLK0+yy35bM3AoQEYNVFDaV0zsp2x/C6gmSJDWs+qLQm988Z0nFBZxBS2nsotA+4P2Z+UhEHA18NyL+peo1JWlcqWP5mXltD0oahkkldZzqErA9Pb1s2vTjg/pQUQI2IipLwG6o6FpZLaG6isLpla8ZEZOBi4E/bcZ2SNJYG27ab8XjNUeNRMS5wPXAUcAe4AOZeV9bg1fXqb4oxG/KYFcmgBYB15a3R7wolJkPAj8FyMxfRcRmiu91k0qSJHWAEau/Se1WqwTshAkTRuzDoUvA1lNF4ZPAtzLz/x05SqlxETE/IjIitkTE1TUeXxYRmyLihxHxrxHxu2MRp8aHiJhIMe33PGAWsKQcDVJpaNQIcCPFqBGAnwP/R2b+J4pFbG9rT9TqZtUXhahdBnuoVHZZYbjyotAhS2hHxCuAU4HvNDNuSZJ0+EwqqeNUl4DdvXsXxx/fc1AfGisBe8gqChHxIaAHWNa8LZF+o84f+N8DTsvM11Jcwf9Ie6PUODObctpvZu7hN6NGKi3iwKnE50TEhMz8XmYOHiMfBZ5XjmqShnWICz6VDuviT0S8CPgy8L7M/OVhhihJkprMpJI6TmUJ2L1793Lvvd/gjDPOPKBPef+S8u5QCViK0rCLI2JKWTFhsATsUBWFiDiKYt2GPoCIuAz4z8CSzBxowybqyDTiD/zM/GZm/rq8uwHX99LojDjyg+FHjVT6L8D3LFeskVRfFKJ2Geyhizx1XhQanJ7+ZeDzmfmVlgQvSZIOi0kldZzKErDveMf5nH32PE488ZWsXv3pwQW6WbBgEcBx5ZoLy4CroSgBCwyWgL2HsgRs+WNpsIrCZsqysuU/+WngBODBiPh+RHwQqfnq+YFfaSnw9ZZGpPGunmm/I40OOYViStwfNzEujVPVF4WouIBToY8GLgqV6y3dDGzOzJVt2RBJklQ3F+pWR6osATvossveO3R7ypQpZGajJWAPqqJQtvs5UDvU8wMfgIh4J3Aa8KaWRqTx7pDTfqv67KgaNUJETAO+CrwrM/9X68NVt6u8KDQw0A/lBZyqMtg3A7eVF4WepEg8UfYbvCi0j/KiUETMpSii8aOI+H75T/1VZeVWSZI0dvwxLUntUc8PfCJiHvDXwJucbqRRGpr2C+yk+PF+UVWfwVEjD1IxaiQijgX+O3BNZv5bG2NWl6u8KNTTc/RyOKgM9rNA3ReFMnM9tZPykiSpA5hUkqT2GPEHfkScCnwGmJ+Zu9ofosaTzNwXEYPTficCn6131AjFdOGTgP8aEf+1bHuL+6UkSZIqmVSSpDao8wf+R4EXAXdGBMBPMnPhmAWtrldr2m89o0Yy88PAh1seoCRJkrqaSSVJapM6fuDPa3tQkiRJknSYrP4mSZIkSZKkhplUkiRJkiRJUsOc/iZJGrU3/N23arZvfP+ZbY5EkiRJUrs4UkmSJEmSJEkNM6kkSZIkSZKkhplUkiRJkiRJUsNMKkmSJEmSJKlhJpUkSZIkSZLUMJNKkiRJkiRJaphJJUmSJEmSJDXMpJIkSZIkSZIaZlJJkiRJkiRJDTOpJEmSJEmSpIaZVJIkSZIkSVLDTCpJkiRJkiSpYSaVJEmSJEmS1DCTSpIkSZIkSWqYSSVJkiRJkiQ1zKSSJEmSJEmSGmZSSZIkSZIkSQ0zqSRJkiRJkqSGmVSSJEmSJElSw0wqSZIkSZIkqWGTxjoASZJ05HjD332rZvvG95/Z5kgkSZI0Wo5UkiRJkiRJUsNMKkmSJEmSJKlhJpUkSZIkSZLUMJNKkiRJkiRJaphJJUmSJEmSJDXM6m+SpLYbrgIYWAVMkiRJ6haOVJIkSZIkSVLD6hqpFBHzgVXARGB1Zl5f9fgU4Fbg9cATwIWZ+Vj52DXAUqAfuCoz19XzmjqybdjwbVatWsHAwAALFrydiy++9IDH9+zZQ0R8iSbscxExA1gD/DbwCHBxZu5p/VbqSDOaY6l0OFrx/d0qw41ec+Rad6n8/t65c8fVnjNqLLk/qlt5zqhuMuJIpYiYCNwEnAfMApZExKyqbkuBpzLzJOBG4IbyubOAxcApwHzgkxExsc7X1BGqv7+flStvYMWKj3P77Xdy773r2LZt6wF97r77a9C8fe4G4MbMnAk8RbE/j9ob/u5bNf/TkWk0x1LpcLTi+7tdsas7VX9/4zmjxpD7o7qV54zqNvWMVJoNbMnMrQARsQZYBGyq6LMIuLa8fRfwiYiYULavyczngG0RsaV8Pep4TR2hNm9+lGnTpjN16jQA5s17C+vXP8CMGScO9Vm//gGAW8q7h73PRcRm4GzgorLPLRT78qdat4U6Qh32sTQz97cz0G7jCJdhteL7+8E2xT7Ev2/3qP7+phgF7DmjxoT7o7qY54zqKvUklaYC2yvu7wBOH65PZu6LiKeB48r2DVXPnVreHuk16ek5ekKtgB67/m11hK1u9d73/tH5wPyenqMvA/jMZ266GDh92bKrrhjs89BDG35Mc/a54wrDJNoAAAqISURBVIBfZOa+Gv0P4P6oURrNsfTnlZ2atS82c9/tpn/7CNKq7+8hHhdVqfr7G7iYMT5nBPfHI1Un7o/ui6pTy88ZpWaqZ6HuWjtidQZ0uD6NtkvQ3n3OfVHtMpr9WjocrTiWSofiOaM6ifujupXnjOoq9SSVdgDTK+5PAx4frk9ETAKOAZ48xHPreU0dudq5z/0cOLZ8jeH+LakZRrNfS4ejFcdS6VA8Z1QncX9Ut/KcUV2lnulvG4GZZYWsnRSL1l1U1acPuIRirYXzgfsyc39E9AFfiIiVwMuBmcBDFJnVkV5TR6627XPlc75Zvsaa8jW/1uoN1BHpsPfrtkap8aQVx1LpUDxnVCdxf1S38pxRXWXEpFI5R/MKYB1FScPPZuajEXEd8HBm9gE3A7eVi9g9SbHjU/a7g2JRsX3A5ZnZD1DrNesJuNvKeEbEdIpyjy8FBoB/yMxVEfHbwJeAVwCPAX+YmU+ViwOuAt4K/Bq4NDMfKV/rEuBvypf+cGbeQgcoKxQ8DOzMzAXlAXAN8NvAI8DFmbmnkbKtQDv3ub8E1kTEh4Hvla9dz3Z31b7YiIj4LLAA2JWZrynbmrbPRsTrgc8BzwfWAn863r8IR3MsrdaJZWaHO9ZV9TmLImm7rWz6SmZe18q4Kv7tx4BfURxj9mXmaVWPD7sftziuoPhcDToR+GBmfqyiz1kcxvvWqu/vOrapY46Ntf7uwx3LWhxHU46pbYrrWuA9wO6y219l5trysZol1gd5zjg2Wv2d3a06aX/s5n3xSPgtU6kVv2uqj5UjaWDf/UZE7KH4u3y8xra0LMaqf2ek89JlwGUUn6XdwB9l5v9XPtYP/Kjs+pPMXNjCOC4FPkqRqAP4RGauLh9r2r5ZRxw3Am8u774A6M3MY8vHmvJ+1PpeqHq8qZ/TCfv3d8/vuPJD/j+BcymG/G0ElmRmx1ZciIiXAS/LzEci4mjgu8DbgUuBJzPz+oi4GnhJZv5lRLwVuJLiD3w6sCozTy8P3A8Dp1HMl/0u8PpWnwjXozxQnAa8uDz43kHxo2dNRHwa+EFmfioi/i/gtZn53ohYDPxBZl4YRYnML1JUOng5cC/wqnp/wIyFbtwXGxERZwLPALdWnKB+hCbtsxHxEPCnFItgrgU+nplfb/NmdqV69r3hPmstjqvmsa4qrrOAP8/MBa2MZZj4HgNOy8yfD/N4zf24bQEy9LfdCZw+eLJVtp/FGL1vjeq0Y2Otv/twx7IWxzHqY2ob47oWeCYzV1T17arv6k7bF1up1d/ZY7BJ40q374tHwm+ZSt3yu2Y054PNjLHOON4MfCczfx0RfwKcNXheGhHPZOaLDuMtOJw4LqU4J7ii6rlN2zcb/bxHxJXAqZn5R+X9Zr0fB30vVD3e1M9pPWsqdZKh8oqZuYfflAbtWJn508GsX2b+CthMsVr/Iory9ZT/f3t5exHFH39/Zm6gWO/nZcB/Bv4lM58s/6j/Asxv46bUFBHTgLcBg1neCcDZFKUt4eBtG9zmu4Bzoqpsa2ZuAyrLtnaqrtsXG5GZ3+LgedlN2WfLx16cmQ9mMTrp1orX0sjq2feG+6y1zCGOdd1iuP24nc4B/ldlQqkLdcOxcbhjWcs06ZjarriG023f1d2wLzZFK7+zWx/9EaGr98Xx/lumUpf9rhnN+WAzYxwxjsz8Zmb+ury7gWKNqGYbzeesmftmo3EsoUjwNVUd3+9N/Zx2W1KpVnnFrvnREhGvAE4FvgOckJk/heJgDfSW3Ybbxk7d9o8Bf0Ex7BKKUpa/yMx95f3KOA8ofQlUlm3txG07lG6MebSatc9OLW9Xt6s+9ex7w33W2qLqWFdtTkT8ICK+HhGntCsmiqst34iI70bE/1nj8U74TC9m+BOLsXrfGtUJ72OlWn/34Y5l7dboMbWdroiIH0bEZyPiJR0UVyO6Ld5mGy/nmePBuHlvx+lvmUrd9LtmNOeDzYyx0ddaClTOTnheRDwcERsiYjQXeeqN47+U3293RTG1s5HnNjMOIuJ3gRnAfRXNzXo/RtLUz2m3JZW6tnRiRLwI+DLwvsz85SG6dk0J04gYnKf53YrmQ8XZNdtWh26MuVUsx9teHV1mdoRj3SPA72bm7wF/D/xzO2IqnZGZvw+cB1xeDguuNKb7ZUQcBSwE7qzx8Fi+b43qtM/3SH/3TjTW7+GngFcCrwN+Cvxd2T7WcTWq2+JtF7+b229cvLfj8bdMpS78XTOa88Fmxlj3a0XEOymmVX20ovl3sljn8iLgYxHxyhbG8f8Ar8jM11JM+RscxTUm7wfFxcS7qqYdNuv9GElT941uSyp1ZRnPiJhMcRD+fGZ+pWz+2eBw9vL/u8r2biphegawsFyzYg3F8NCPUQyfG1wEvjLO8VS6uhtjHq1m7bM7OHDY65Hw3jVTx5aZHeZYNyQzf5mZz5S31wKTI+L4VsdV/nuPl//fBXyVg4d5j/Vn+jzgkcz8WfUDY/m+HYaxfh8PMMzffbhjWbs1ekxti8z8WWb2Z+YA8I/85rPSUX/bOnRbvM02Hs4zx4uuf2/H8W+ZSt32u2Y054PNjLGu14qIecBfAwsz87nB9orv6a3A/RQj4VoSR2Y+UfFv/yPFAuZ1b0Oz4qhw0Aj1Jr4fI2nq57TbkkpD5RXLq7qLKcopdqxy3urNwObMXFnx0GAZSDiwjH0f8K6ImBARbwSeLoeUrgPeEhEvKYeiv6VsGzOZeU1mTsvMV1D8Le7LzHcA36QobQkHb9vgNleWvuwDFkfElCgqLHRD6equ2xeboCn7bPnYryLijeXn410Vr6WR1bPvDfdZa5lDHOsq+7x0cG2niJhN8R30RCvjKv+tF0axuCgR8UKKffHHVd2G24/bZdg59WP1vh2mjjk2HuLvPtyxrN0aPaa2RdX6TX/Abz4r3fZd3TH74hjp+vPMcaSr98Xx/FumUhf+rhnN+WAzYxwxjog4FfgMRUJpV0X7S6KoUEd5sewMioqLrYqj8vttIcX6YNDcfbOuz3tEBPAS4MGKtma+HyNp6ud00kgdOkkOU15xjMMayRnAxcCPIuL7ZdtfAdcDd0TEUuAnwAXlY2spVmHfQlHe790AmflkRPwtxY4KcF1mtnzkwWH6S2BNRHwY+B7FFxG0oHT1WOnSfbFuEfFF4Czg+IjYAXyI5u6zfwJ8Dng+xbxqK7/Vabh9L+ookdxiwx3rfqeM+9MUJzR/EhH7gP8AFrc62VU6Afhq8f3NJOALmXlPRLy3Iraa+3E7RMQLKKqE/HFFW2VsY/W+NazDjo3D/d03UvtY1jLNOKa2Ma6zIuJ1FMPdH6PcL7vtu7rD9sWWasN3tkZhHOyLR+JvmUod+btmNOeDzYyxzjg+CrwIuLP8Tv5JZi4EXg18JiIGKC6YXZ+HWRWxzjiuioiF5TY/SVHBsKn7Zp1xQHExcU3V+VzT3o9hvhcmlzEOe957uO/FhP37O/K8VJIkSZIkSR2s26a/SZIkSZIkqQOYVJIkSZIkSVLDTCpJkiRJkiSpYSaVJEmSJEmS1DCTSpIkSZIkSWqYSSVJkiRJkiQ1zKSSJEmSJEmSGmZSSZIkSZIkSQ37/wEQG8/u8YFR9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x720 with 14 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########\n",
    "# Histogram of numerical variables \n",
    "########\n",
    "\n",
    "# Note that the last chart is empty as we only have 13 numerical variables. \n",
    "\n",
    "import seaborn as sns \n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "numerical_cols = ['Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8','Var9','Var10','Var11','Var12','Var13']\n",
    "\n",
    "fig, axs = plt.subplots(2,7, figsize=(20,10))\n",
    "axs = axs.ravel()\n",
    "for p in range(0,len(numerical_cols)): \n",
    "    list_values = train_sample.select(numerical_cols[p]).rdd.flatMap(lambda x: x).collect()\n",
    "    cleaned_list = [x for x in list_values if x is not None]\n",
    "    axs[p].hist(cleaned_list, bins=20, density=True)\n",
    "    axs[p].set_title(numerical_cols[p])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Categorical Variables and Cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are a total of 26 categorical columns that are also included within this dataset. \n",
    "* In Table 3.2, we immediately notice the high dimensionality when we take note of the number of distinct values in each categorical column. Some (ex: Var33 and Var22) have fewer than 5 distinct values while others (ex: Var16 and Var25) have over 100,000 distinct values. We explore our methods of preprocessing and reducing dimensionality in **[insert section]**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>count_distinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Var16</td>\n",
       "      <td>753315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Var25</td>\n",
       "      <td>661596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Var34</td>\n",
       "      <td>588319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Var29</td>\n",
       "      <td>489035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Var17</td>\n",
       "      <td>258094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Var37</td>\n",
       "      <td>69117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Var39</td>\n",
       "      <td>47492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Var23</td>\n",
       "      <td>42422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Var20</td>\n",
       "      <td>11741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Var28</td>\n",
       "      <td>10943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Var24</td>\n",
       "      <td>5126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Var31</td>\n",
       "      <td>4479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Var26</td>\n",
       "      <td>3169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Var32</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Var14</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Var21</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Var15</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Var18</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Var38</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Var27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Var19</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Var35</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Var36</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Var30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Var33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Var22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column  count_distinct\n",
       "2   Var16          753315\n",
       "11  Var25          661596\n",
       "20  Var34          588319\n",
       "15  Var29          489035\n",
       "3   Var17          258094\n",
       "23  Var37           69117\n",
       "25  Var39           47492\n",
       "9   Var23           42422\n",
       "6   Var20           11741\n",
       "14  Var28           10943\n",
       "10  Var24            5126\n",
       "17  Var31            4479\n",
       "12  Var26            3169\n",
       "18  Var32            1959\n",
       "0   Var14            1407\n",
       "7   Var21             614\n",
       "1   Var15             555\n",
       "4   Var18             300\n",
       "24  Var38              83\n",
       "13  Var27              26\n",
       "5   Var19              16\n",
       "21  Var35              15\n",
       "22  Var36              15\n",
       "16  Var30              10\n",
       "19  Var33               4\n",
       "8   Var22               3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = ['Var14','Var15','Var16','Var17','Var18','Var19','Var20','Var21','Var22',\n",
    "                    'Var23','Var24','Var25','Var26','Var27','Var28','Var29','Var30','Var31',\n",
    "                   'Var32','Var33','Var34','Var35','Var36','Var37','Var38','Var39']\n",
    "\n",
    "###########\n",
    "# Table 3.2: Count distinct values in each categorical column \n",
    "###########\n",
    "\n",
    "distinct_temp = []\n",
    "for column in categorical_cols: \n",
    "    distinct_temp.append({'Column':column, 'count_distinct': train_sample.select(column).distinct().count()})\n",
    "    \n",
    "distinct_df = pd.DataFrame(distinct_temp)\n",
    "distinct_df.sort_values(by='count_distinct', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the high dimensionality of our categorical columns if we were to one hot encode so many categorical features, we wanted to know if there were certain values within the categorical variables that were more common than others, and thus would be more predictive of the final click through rate label of 1 or 0. \n",
    "* It is likely that certain values of a categorical column may be rare and therefore may not contribute much predictive power. If we were to tally up the counts of each distinct value in a categorical column (split by CTR group, or CTR == 0 vs CTR == 1) and calculate a cumulative summation of the number of observations observed per distinct value, we could distinguish just how many of the individual values within a categorical variable can cover the majority of the dataset. By further breaking down the top most frequent values in each CTR == 0 and CTR == 1 group, we can also observe which values are more telling of whether an ad will be clicked on or not. \n",
    "    * It should be noted that we defined 'majority' here as 95% of the observations within each group (CTR==0, CTR==1). \n",
    "* Furthermore, we would like to observe a sense of \"correlation\" between the labelled variable (CTR == 0, CTR==1) and our categorical features to see if there is any sort of association between the two variables. Pearson's Correlation unfortunately will not suffice, as we would be comparing a categorical variable (with no particular ordering) against a binary output variable that simply labels a successful/unsuccessful ad click. \n",
    "    * One particular workaround is the Cramer's V statistic (https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V): Based on the chi-squared statistic, Cramer's V is a measure of association between two nominal variables and gives an output number between 0 and 1 to quantify the strength of the association between two nominal variables. We therefore calculate Cramer's V statistic between successful/unsuccessful ad clicks (CTR==0, CTR==1) against the categorical values in each column to measure (if any) the strength of association between the two variables. \n",
    "\n",
    "\n",
    "* **TO CONSIDER: What to do if 'null' is one of the top values for a categorical variable?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# Cumulative Summation \n",
    "# Intent: In each column, we want to know which values contribute the most in terms of frequency for CTR=1. \n",
    "##########\n",
    "\n",
    "from pyspark.sql.functions import col, desc\n",
    "from pyspark.sql import window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "count_1 = train_sample.filter(col(\"CTR\")==1).count()\n",
    "count_0 = train_sample.filter(col(\"CTR\")==0).count()\n",
    "\n",
    "# Set aside a subset \n",
    "subset_CTR1=train_sample.filter(col(\"CTR\")==1)[categorical_cols]\n",
    "subset_CTR0=train_sample.filter(col(\"CTR\")==0)[categorical_cols]\n",
    "\n",
    "win_spec = (window.Window\n",
    "                  .partitionBy()\n",
    "                  .rowsBetween(window.Window.unboundedPreceding, 0))\n",
    "\n",
    "top_cumsum_ctr1 = []\n",
    "all_cumsum_ctr1 = []\n",
    "top_cumsum_ctr0 = []\n",
    "all_cumsum_ctr0 = []\n",
    "summary_cumsum = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    # --- Calculate cumulative summation for CTR==1 \n",
    "    tempdf = subset_CTR1.groupBy([col]).count().sort(desc('count')).cache()\n",
    "    tempdf = tempdf.withColumn('count_frequ', tempdf['count']/count_1).cache()\n",
    "    tempdf = tempdf.withColumn('cumsum',F.sum(tempdf.count_frequ).over(win_spec))\n",
    "    all_cumsum_ctr1.append(tempdf)\n",
    "    temp_pd_CTR1 = tempdf.where(tempdf.cumsum<=0.95).toPandas()\n",
    "    top_cumsum_ctr1.append(temp_pd_CTR1)\n",
    "    \n",
    "    # --- Calculate cumulative summation for CTR==0 \n",
    "    tempdf = subset_CTR0.groupBy([col]).count().sort(desc('count')).cache()\n",
    "    tempdf = tempdf.withColumn('count_frequ', tempdf['count']/count_0).cache()\n",
    "    tempdf = tempdf.withColumn('cumsum',F.sum(tempdf.count_frequ).over(win_spec))\n",
    "    all_cumsum_ctr0.append(tempdf)\n",
    "    temp_pd_CTR0 = tempdf.where(tempdf.cumsum<=0.95).toPandas()\n",
    "    top_cumsum_ctr0.append(temp_pd_CTR0)\n",
    "    \n",
    "    # Summary stats: \n",
    "    # For each column: count up the number of distinct values that are needed to cover 95% of the observations in each group\n",
    "    summary_cumsum.append({'Column': col, 'top_freq_CTR0_count': len(temp_pd_CTR0), 'top_freq_CTR1_count': len(temp_pd_CTR1)})\n",
    "\n",
    "summary_cumsum_df = pd.DataFrame(summary_cumsum)\n",
    "\n",
    "############\n",
    "# Save the top values for each CTR group out for each categorical column \n",
    "# DO NOT run this part of the code unless you want to save out the individual CSVs. \n",
    "# These CSVs can be used for broadcasting later on. \n",
    "############ \n",
    "\n",
    "#for i in range(0, 26): \n",
    "#    filename = 'CTR0_'+str(categorical_cols[i])+'.csv'\n",
    "#    all_cumsum_ctr0[i].toPandas().to_csv(filename, index=False)\n",
    "#    filename = 'CTR1_'+str(categorical_cols[i])+'.csv'\n",
    "#    all_cumsum_ctr1[i].toPandas().to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# Cramer's V \n",
    "###### \n",
    "\n",
    "# Cramer's Value \n",
    "# referenced from https://stackoverflow.com/questions/20892799/using-pandas-calculate-cram%C3%A9rs-coefficient-matrix\n",
    "# and https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V\n",
    "\n",
    "def cramers_corrected_stat(confusion_matrix): \n",
    "    \"\"\"\n",
    "    This function calculates the Cramer's coefficient matrix given a contingency table. \n",
    "    It has been discussed before that cramer's V can be over-optimistic in estimating association between between categories. \n",
    "    Therefore, a correction for bias has been implemented in this function as well. \n",
    "    \"\"\"\n",
    "    # --- get total n \n",
    "    n = np.nansum(confusion_matrix.sum()) \n",
    "    \n",
    "    # --- get r,k (shape), where r = number of rows, k = number of columns \n",
    "    r,k = confusion_matrix.shape \n",
    "    \n",
    "    # --- get chi-2 statistic\n",
    "    chi2 = 0\n",
    "    row_sums = confusion_matrix.sum(axis=1) \n",
    "    col_sums = confusion_matrix.sum(axis=0) \n",
    "    for index, row in confusion_matrix.iterrows(): \n",
    "        # index will denote the row number \n",
    "        for col in confusion_matrix.columns: # iterate across rows \n",
    "            chi2+=((row[col]-(row_sums[index]*col_sums[col]/n))**2)/(row_sums[index]*col_sums[col]/n)\n",
    "    # --- get phi2 \n",
    "    phi2 = chi2/n \n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1)) \n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))\n",
    "\n",
    "all_categorical_columns = ['Var14','Var15','Var16','Var17','Var18','Var19','Var20','Var21','Var22','Var23','Var24','Var25','Var26','Var27','Var28','Var29','Var30','Var31','Var32','Var33','Var34','Var35','Var36','Var37','Var38','Var39']\n",
    "\n",
    "def calculate_adj_cramersV_allcolumns(columns, rdd_obj): \n",
    "    \"\"\"\n",
    "    This function will apply Cramer's value function (cramers_corrected_stat) onto the values of categorical columns in the RDD. \n",
    "    \"\"\"\n",
    "    cramers_df = []\n",
    "    for c in columns: \n",
    "        print(c)\n",
    "        # --- make contingency table \n",
    "        contingency = rdd_obj.map(lambda x: ((x['CTR'],x[c]),1)) \\\n",
    "            .reduceByKey(lambda x,y: x+y) \\\n",
    "            .map(lambda x: ((x[0][0],x[0][1]),x[1])).collect()\n",
    "        \n",
    "        # --- Unwrap contingency mapped output \n",
    "        unwrapped_df = pd.DataFrame([[contingency[i][0][0], contingency[i][0][1], contingency[i][1]] for i in range(0, len(contingency))], columns = ['ctr','category','count']).sort_values(by=['category','ctr']).reset_index(drop=True)\n",
    "        \n",
    "        # --- Make contingency table \n",
    "        matr_obj = pd.DataFrame(0, columns = unwrapped_df['category'].drop_duplicates().values, index = unwrapped_df['ctr'].drop_duplicates().values)\n",
    "        for index, row in unwrapped_df.iterrows(): \n",
    "            matr_obj.at[row['ctr'], row['category']]=row['count']\n",
    "        \n",
    "        # --- Calculate Cramer's V (adjusted) \n",
    "        cramersV_value = cramers_corrected_stat(matr_obj)\n",
    "        cramers_df.append({'column': c, 'cramersvalue': cramersV_value})\n",
    "    return(cramers_df)\n",
    "\n",
    "#############\n",
    "# In addition to the functions above, the follow lines were combined into a python file, and sent to GCP for faster processing. \n",
    "# These lines will not be run in this notebook, but have been provided as reference. \n",
    "# Output from GCP has been saved, and is read in to the Cramer's coefficient matrix. \n",
    "############# \n",
    "\n",
    "#all_categorical_columns = ['Var14','Var15','Var16','Var17','Var18','Var19','Var20',\n",
    "#                           'Var21','Var22','Var23','Var24','Var25','Var26','Var27',\n",
    "#                           'Var28','Var29','Var30','Var31','Var32','Var33','Var34',\n",
    "#                           'Var35','Var36','Var37','Var38','Var39']\n",
    "#cramers_results = pd.DataFrame(calculate_adj_cramersV_allcolumns(all_categorical_columns, data_rdd)).reset_index(drop=True)\n",
    "#cramers_results.to_csv('Categorical_CramersValue.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We therefore combine all of our summary statistics together. In table 3.3, for each categorical variable, we provide the \n",
    "* number of distinct values (`count_distinct`)\n",
    "* number of categorical values that cover 95% of the observations in each labelled group (CTR==0 in `top_freq_CTR0_count` and CTR==1 in `top_freq_CTR1_count`). \n",
    "* percentage of observations in the categorical column that are not null (`Coverage_nonNull`). \n",
    "* Cramer's Value between the categorical column and labelled CTR variable (`Cramersvalue`). \n",
    "\n",
    "When sorted, we note a few things: \n",
    "* In general, it looks like columns with a lower number of distinct values tend to also have lower Cramer's coefficient with our labelled CTR variable. On the opposite end, it seems like columns with a higher number of distinct values tend to have more association with the labelled CTR variable. \n",
    "* For almost all of the categorical columns, we can see that there are fewer features that cover the majority of observations for CTR = 1 than CTR = 0. \n",
    "    ** For example: For column Var25, we observe that there are 179614 categorical values (27% of all distinct values in Var25) that cover 95% or more of the observations that have a label of CTR = 1. In contrast, we see that there are 414817 categorical values (62% of all distinct values in Var25) that cover 95% or more of the observations that have a label of CTR = 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# Combine summary statistics together for all categorical data \n",
    "####### \n",
    "\n",
    "# (1) Merge distinct counts of values for each column against the cumulative summations \n",
    "ver1 = distinct_df.merge(summary_cumsum_df, how='left', on='Column')\n",
    "\n",
    "# (2) Merge output from (1) against percentage of non-null values for each categorical column. \n",
    "coverage_tomerge = pd.DataFrame([list(coverage_summary.index.values), list(coverage_summary['Coverage_nonNull'].values)]).T\n",
    "coverage_tomerge.columns=['Column','Coverage_nonNull']\n",
    "ver2 = ver1.merge(coverage_tomerge, how='left', on='Column')\n",
    "\n",
    "# (3) Merge output from (2) against the Cramer's coefficient results from \n",
    "cramers_results = pd.read_csv('Categorical_CramersValue.csv')\n",
    "categorical_combined_df = ver2.merge(cramers_results, how='left', on='Column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>count_distinct</th>\n",
       "      <th>top_freq_CTR0_count</th>\n",
       "      <th>top_freq_CTR1_count</th>\n",
       "      <th>Coverage_nonNull</th>\n",
       "      <th>Cramersvalue</th>\n",
       "      <th>pct_topfreq_CTR0</th>\n",
       "      <th>pct_topfreq_CTR1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Var25</td>\n",
       "      <td>661596</td>\n",
       "      <td>414817</td>\n",
       "      <td>179614</td>\n",
       "      <td>0.965857</td>\n",
       "      <td>0.283316</td>\n",
       "      <td>0.626994</td>\n",
       "      <td>0.271486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Var29</td>\n",
       "      <td>489035</td>\n",
       "      <td>288313</td>\n",
       "      <td>132526</td>\n",
       "      <td>0.965857</td>\n",
       "      <td>0.282840</td>\n",
       "      <td>0.589555</td>\n",
       "      <td>0.270995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Var34</td>\n",
       "      <td>588319</td>\n",
       "      <td>362959</td>\n",
       "      <td>158059</td>\n",
       "      <td>0.965857</td>\n",
       "      <td>0.282022</td>\n",
       "      <td>0.616943</td>\n",
       "      <td>0.268662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Var20</td>\n",
       "      <td>11741</td>\n",
       "      <td>5202</td>\n",
       "      <td>4407</td>\n",
       "      <td>1</td>\n",
       "      <td>0.279014</td>\n",
       "      <td>0.443063</td>\n",
       "      <td>0.375351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Var17</td>\n",
       "      <td>258094</td>\n",
       "      <td>120554</td>\n",
       "      <td>63302</td>\n",
       "      <td>0.965857</td>\n",
       "      <td>0.278732</td>\n",
       "      <td>0.467093</td>\n",
       "      <td>0.245267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Var16</td>\n",
       "      <td>753315</td>\n",
       "      <td>484485</td>\n",
       "      <td>201579</td>\n",
       "      <td>0.965857</td>\n",
       "      <td>0.278488</td>\n",
       "      <td>0.643137</td>\n",
       "      <td>0.267589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Var28</td>\n",
       "      <td>10943</td>\n",
       "      <td>2407</td>\n",
       "      <td>2333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.275850</td>\n",
       "      <td>0.219958</td>\n",
       "      <td>0.213196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Var24</td>\n",
       "      <td>5126</td>\n",
       "      <td>2193</td>\n",
       "      <td>1879</td>\n",
       "      <td>1</td>\n",
       "      <td>0.258099</td>\n",
       "      <td>0.427819</td>\n",
       "      <td>0.366563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Var26</td>\n",
       "      <td>3169</td>\n",
       "      <td>1640</td>\n",
       "      <td>1434</td>\n",
       "      <td>1</td>\n",
       "      <td>0.252592</td>\n",
       "      <td>0.517513</td>\n",
       "      <td>0.452509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Var37</td>\n",
       "      <td>69117</td>\n",
       "      <td>11359</td>\n",
       "      <td>8203</td>\n",
       "      <td>0.965857</td>\n",
       "      <td>0.247962</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>0.118683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Var31</td>\n",
       "      <td>4479</td>\n",
       "      <td>873</td>\n",
       "      <td>925</td>\n",
       "      <td>1</td>\n",
       "      <td>0.245074</td>\n",
       "      <td>0.194910</td>\n",
       "      <td>0.206519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Var39</td>\n",
       "      <td>47492</td>\n",
       "      <td>6065</td>\n",
       "      <td>4824</td>\n",
       "      <td>0.559533</td>\n",
       "      <td>0.206376</td>\n",
       "      <td>0.127706</td>\n",
       "      <td>0.101575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Var23</td>\n",
       "      <td>42422</td>\n",
       "      <td>9279</td>\n",
       "      <td>7720</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197278</td>\n",
       "      <td>0.218731</td>\n",
       "      <td>0.181981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Var15</td>\n",
       "      <td>555</td>\n",
       "      <td>193</td>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187614</td>\n",
       "      <td>0.347748</td>\n",
       "      <td>0.336937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Var30</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161455</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Var36</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133638</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Var27</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127012</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Var22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100331</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Var32</td>\n",
       "      <td>1959</td>\n",
       "      <td>179</td>\n",
       "      <td>176</td>\n",
       "      <td>0.559533</td>\n",
       "      <td>0.085757</td>\n",
       "      <td>0.091373</td>\n",
       "      <td>0.089842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Var38</td>\n",
       "      <td>83</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.559533</td>\n",
       "      <td>0.073740</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>0.120482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Var33</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.559533</td>\n",
       "      <td>0.049259</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Var19</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.878906</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Var35</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.237235</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Var14</td>\n",
       "      <td>1407</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.012793</td>\n",
       "      <td>0.012793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Var21</td>\n",
       "      <td>614</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.014658</td>\n",
       "      <td>0.013029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Var18</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column  count_distinct  top_freq_CTR0_count  top_freq_CTR1_count  \\\n",
       "11  Var25          661596               414817               179614   \n",
       "15  Var29          489035               288313               132526   \n",
       "20  Var34          588319               362959               158059   \n",
       "6   Var20           11741                 5202                 4407   \n",
       "3   Var17          258094               120554                63302   \n",
       "2   Var16          753315               484485               201579   \n",
       "14  Var28           10943                 2407                 2333   \n",
       "10  Var24            5126                 2193                 1879   \n",
       "12  Var26            3169                 1640                 1434   \n",
       "23  Var37           69117                11359                 8203   \n",
       "17  Var31            4479                  873                  925   \n",
       "25  Var39           47492                 6065                 4824   \n",
       "9   Var23           42422                 9279                 7720   \n",
       "1   Var15             555                  193                  187   \n",
       "16  Var30              10                    7                    6   \n",
       "22  Var36              15                    6                    6   \n",
       "13  Var27              26                    6                    5   \n",
       "8   Var22               3                    1                    0   \n",
       "18  Var32            1959                  179                  176   \n",
       "24  Var38              83                    9                   10   \n",
       "19  Var33               4                    3                    3   \n",
       "5   Var19              16                    4                    4   \n",
       "21  Var35              15                    2                    2   \n",
       "0   Var14            1407                   18                   18   \n",
       "7   Var21             614                    9                    8   \n",
       "4   Var18             300                    5                    5   \n",
       "\n",
       "   Coverage_nonNull  Cramersvalue  pct_topfreq_CTR0  pct_topfreq_CTR1  \n",
       "11         0.965857      0.283316          0.626994          0.271486  \n",
       "15         0.965857      0.282840          0.589555          0.270995  \n",
       "20         0.965857      0.282022          0.616943          0.268662  \n",
       "6                 1      0.279014          0.443063          0.375351  \n",
       "3          0.965857      0.278732          0.467093          0.245267  \n",
       "2          0.965857      0.278488          0.643137          0.267589  \n",
       "14                1      0.275850          0.219958          0.213196  \n",
       "10                1      0.258099          0.427819          0.366563  \n",
       "12                1      0.252592          0.517513          0.452509  \n",
       "23         0.965857      0.247962          0.164345          0.118683  \n",
       "17                1      0.245074          0.194910          0.206519  \n",
       "25         0.559533      0.206376          0.127706          0.101575  \n",
       "9                 1      0.197278          0.218731          0.181981  \n",
       "1                 1      0.187614          0.347748          0.336937  \n",
       "16                1      0.161455          0.700000          0.600000  \n",
       "22                1      0.133638          0.400000          0.400000  \n",
       "13                1      0.127012          0.230769          0.192308  \n",
       "8                 1      0.100331          0.333333          0.000000  \n",
       "18         0.559533      0.085757          0.091373          0.089842  \n",
       "24         0.559533      0.073740          0.108434          0.120482  \n",
       "19         0.559533      0.049259          0.750000          0.750000  \n",
       "5          0.878906      0.037500          0.250000          0.250000  \n",
       "21         0.237235      0.035937          0.133333          0.133333  \n",
       "0                 1      0.003616          0.012793          0.012793  \n",
       "7                 1      0.002163          0.014658          0.013029  \n",
       "4                 1      0.000000          0.016667          0.016667  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########\n",
    "# Table 3.3\n",
    "########\n",
    "\n",
    "categorical_combined_df['pct_topfreq_CTR0'] = categorical_combined_df['top_freq_CTR0_count']/categorical_combined_df['count_distinct']\n",
    "categorical_combined_df['pct_topfreq_CTR1'] = categorical_combined_df['top_freq_CTR1_count']/categorical_combined_df['count_distinct']\n",
    "\n",
    "categorical_combined_df.sort_values(by=['Cramersvalue','Coverage_nonNull'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Clean-up and transforming variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A couple options: \n",
    "\n",
    "# For numerical: we see 0's and also -2. \n",
    "# Option 1: Log will require non zero and non negative. We can perhaps do log(x+1) in which advantages are \n",
    "# (1) relatively easy; (2) x = 0 will map to a value of 0 even after transformation \n",
    "# Option 2: log(x)^2 only if the value itself > 2 (NTU paper here https://www.csie.ntu.edu.tw/~r01922136/kaggle-2014-criteo.pdf) \n",
    "\n",
    "# For categorical: \n",
    "# Things to consider: (A) Cramer's value (pick only features that hit X threshold of Cramer's value)? \n",
    "# Option 1: Take the features that cover 95% of class CTR==1 only, code everything else + Null as a \"lump all\" category. \n",
    "# Cons of Option 1: Can we treat 'null' and 'everything else' equally? \n",
    "# Option 2: If count of a specific distinct value is < 10, we ignore that value. \n",
    "# Cons of Option 2: Doesn't exactly reduce dimensionality, especially when we have distinct values that skyrocket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
